-- MySQL dump 10.13  Distrib 5.7.33, for Win64 (x86_64)
--
-- Host: 127.0.0.1    Database: sqlexam
-- ------------------------------------------------------
-- Server version	5.7.33

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `answer_set`
--

DROP TABLE IF EXISTS `answer_set`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `answer_set` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `main_id` int(11) DEFAULT NULL,
  `sub_id` int(11) DEFAULT NULL,
  `answer` text,
  `created_at` datetime DEFAULT NULL,
  `updated_at` datetime DEFAULT NULL,
  `state` tinyint(4) DEFAULT '0',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=93 DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `answer_set`
--

LOCK TABLES `answer_set` WRITE;
/*!40000 ALTER TABLE `answer_set` DISABLE KEYS */;
INSERT INTO `answer_set` VALUES (1,125,4,'select `name`,`amount` from blank_data where name=\'Tom\' or name=\'Jerry\';',NULL,NULL,0),(2,125,5,'select `name`,`address` from address_data where name=\'Tom\' or name=\'Jerry\';',NULL,NULL,0),(3,1,10,'select w.eno \nfrom works w\ngroup by w.eno\nhaving sum(hours) > 1000;',NULL,'2022-04-21 19:09:25',0),(4,1,11,'select e.eno\nfrom employees e\nwhere not exists (\n	select *\n	from relations r\n	where r.eno = e.eno\n);',NULL,NULL,0),(5,1,12,'select p.pno\nfrom projects p\nwhere not exists (\n    select * \n    from employees e\n    where not exists(\n        select *\n        from works w\n        where w.eno = e.eno and w.pno = p.pno\n    )\n)',NULL,NULL,0),(6,1,13,'select e1.dno,e1.eno, e1.salary\nfrom employees e1\nwhere e1.salary in (\n	select MAX(salary)\n	from employees e2\n	where e1.dno = e2.dno\n	group by dno\n)\norder by dno;',NULL,NULL,0),(7,2,14,'select s.sname from sailors s\nwhere s.age > 35 and not exists (\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid \n	where  \n	r.sid = s.sid and \n	b.color = \'RED\' and\n	(r.reserve_date between \'2020-09-01\' and \'2020-09-30\')\n);',NULL,NULL,0),(8,3,15,'select c.customer_id\nfrom customers c\nwhere not exists (\n    select * \n    from products p\n    where not exists (\n        select * \n        from orders o\n        where o.customer_id = c.customer_id and o.product_id = p.product_id\n    )\n);',NULL,NULL,0),(9,3,16,'select o.customer_id, count(distinct order_id) as order_num\nfrom orders o\nwhere o.order_date BETWEEN \'2020-08-01\' and \'2020-08-31\'\nGROUP BY o.customer_id\norder by order_num DESC, customer_id asc\nlimit 1;',NULL,NULL,0),(10,3,17,'SELECT\n	p.product_name AS product_name,\n	o.order_id,\n	o.order_date\nFROM\n	orders o,\n	customers c,\n	products p\nWHERE\n	o.customer_id = c.customer_id\nAND o.product_id = p.product_id\nAND (o.product_id, o.order_date) IN (\n	SELECT\n		product_id,\n		MAX(order_date)\n	FROM\n		orders\n	GROUP BY\n		product_id\n)\nORDER BY product_name;\n',NULL,NULL,0),(11,3,18,'SELECT c.name customer_name,o2.order_id,o2.order_date\nFROM orders o1,orders o2,customers c\nWHERE o1.customer_id=o2.customer_id AND c.customer_id=o2.customer_id\nGROUP BY c.name,o2.order_id,o2.customer_id,o2.order_date\nHAVING SUM(o1.order_date>=o2.order_date)<=3\nORDER BY c.name,o2.order_date desc;',NULL,NULL,0),(12,4,19,'select player_id, count(*) as match_num from \n(\n	select p.player_id \n	from players p join matches m\n	on p.player_id = m.first_player or p.player_id = m.second_player\n) tot_player\ngroup by player_id\nORDER BY match_num DESC,player_id asc\nlimit 1;',NULL,NULL,0),(13,4,20,'select group_id, count(match_id) as match_num\nfrom matches\ngroup by group_id;',NULL,NULL,0),(14,4,21,'select match_id, ABS(first_score - second_score) as sub\nfrom matches\norder by ABS(first_score - second_score) desc, match_id asc\nlimit 1;',NULL,NULL,0),(15,4,22,'select group_id,min(player_id) as player_id\nfrom\n    (select player,sum(score) as score\n    from\n        ((select first_player player,first_score score from matches)\n        union all\n        (select second_player player,second_score score from matches)) t\n    group by player) a\n    right join players p on a.player=p.player_id\nwhere (group_id,score) in\n(select group_id,max(score) as mx\nfrom \n    (select player,sum(score) as score\n    from\n        ((select first_player player,first_score score from matches)\n        union all\n        (select second_player player,second_score score from matches)) t\n    group by player) a\n    right join players p on a.player=p.player_id\ngroup by group_id)\ngroup by group_id\norder by group_id;',NULL,NULL,0),(16,5,23,'select order_date,count(*) as num\nfrom orders \ngroup by order_date\norder by num DESC,order_date asc\nlimit 1;',NULL,NULL,0),(17,5,24,'select u.user_id \nfrom users u\nwhere exists (\n	select * \n	from orders o LEFT JOIN items i\n	on o.item_id = i.item_id\n	where o.buyer_id = u.user_id and u.favorite_brand = i.item_brand\n);',NULL,NULL,0),(18,5,25,'select user_id, join_date, count(order_id) orders_in_2019\nfrom users left join orders\non user_id = buyer_id and year(order_date)=\'2019\'\ngroup by user_id\norder by user_id;',NULL,NULL,0),(19,5,26,'select user_id seller_id, if(favorite_brand = item_brand, \'yes\', \'no\') if_fav_brand\nfrom users left join (\n    select seller_id, item_brand\n    from (\n        select o1.seller_id, o1.item_id\n        from orders o1 join orders o2\n        on o1.seller_id = o2.seller_id\n        group by o1.order_id\n        having sum(o1.order_date > o2.order_date) = 1\n    ) o join items i\n    on o.item_id = i.item_id\n) tmp\non user_id = seller_id\norder by seller_id;',NULL,NULL,0),(20,6,27,'select round(\n    ifnull(\n    (select count(distinct requester_id ,accepter_id) from accepted_requests) / \n    (select count(distinct sender_id ,send_to_id) from friend_requests)\n    ,0)\n    ,2) as accept_rate ;',NULL,NULL,0),(21,6,28,'select distinct fr.sender_id user_id\nfrom friend_requests fr \nwhere exists (\n	select * from friend_requests fr2\n	where fr2.sender_id = fr.sender_id\n) and not exists (\n	select * from accepted_requests \n	where fr.sender_id = requester_id\n);',NULL,NULL,0),(22,6,29,'select t1.m1 as mon, t1.accept/t2.alla accept_rate from\n(select month(accept_date) m1, count(distinct concat(requester_id, accepter_id)) accept\nfrom accepted_requests \ngroup by month(accept_date)) t1\ninner join\n(select month(request_date) m2, count(distinct concat(sender_id, send_to_id)) alla\nfrom friend_requests \ngroup by month(request_date)) t2\non t1.m1=t2.m2\norder by mon;',NULL,NULL,0),(23,6,30,'select user_id, count(*) friend_num\nfrom \n((select requester_id user_id\nfrom accepted_requests\n)\nunion all\n(select accepter_id user_id\nfrom accepted_requests)) t3\ngroup by user_id\norder by friend_num desc,user_id asc\nlimit 1;',NULL,NULL,0),(24,7,31,'SELECT distinct author_id as id\nFROM views\nWHERE author_id = viewer_id\nORDER BY author_id;',NULL,NULL,0),(25,7,32,'select  distinct viewer_id from views \ngroup by viewer_id,view_date\nhaving count(distinct article_id) >= 2\norder by viewer_id;',NULL,NULL,0),(26,7,33,'select viewer_id , count(*) as article_num  from views \ngroup by viewer_id \norder by article_num desc, viewer_id asc\nlimit 1;',NULL,NULL,0),(27,7,34,'select distinct viewer_id as id\nfrom views v1  \nwhere exists(\n	select *\n	from views v2\n	where v2.viewer_id = v1.viewer_id and v2.author_id = 3\n				and (v2.view_date BETWEEN \'2020-08-01\' and \'2020-08-31\')\n)\norder by id;',NULL,NULL,0),(28,8,35,'SELECT user_id, MAX(login_date) as date FROM logins\nGROUP BY user_id\nORDER BY user_id;',NULL,NULL,0),(29,8,36,'select \ncount(distinct user_id)*1.0/(select count(distinct user_id) from logins) as rate\nfrom logins\nwhere (user_id,login_date)\nin (select user_id,DATE_ADD(min(login_date),INTERVAL 1 DAY) from logins group by user_id);',NULL,NULL,0),(30,8,37,'select l.mdate as login_date,count(user_id) as new_user_num\nfrom (\n    select user_id,min(login_date) as mdate\n    from logins\n    group by user_id) as l\ngroup by l.mdate \nhaving new_user_num >= 2\norder by login_date;',NULL,NULL,0),(31,8,38,'SELECT a.date, ROUND(COUNT(b.user_id) * 1.0/COUNT(a.user_id), 3) AS rate\nFROM (\n    SELECT user_id, MIN(login_date) AS date\n    FROM logins\n    GROUP BY user_id) a\nLEFT JOIN logins b\nON a.user_id = b.user_id\nAND b.login_date = DATE_ADD(a.date,INTERVAL 1 day)\nGROUP BY a.date\nUNION\nSELECT login_date date, 0.000 AS rate\nFROM logins\nWHERE login_date NOT IN (\n    SELECT MIN(login_date)\n    FROM logins\n    GROUP BY user_id)\nORDER BY date;',NULL,NULL,0),(32,9,39,'select job,round(sum(score)*1.0/count(user_id),3) as avg from grades\ngroup by job order by avg desc;',NULL,NULL,0),(33,9,40,'select grades.* from grades join \n(select job,round(sum(score)*1.0/count(user_id),3) as avg from grades\ngroup by job) as t\non grades.job=t.job\nwhere grades.score > t.avg\norder by user_id;',NULL,NULL,0),(34,9,41,'SELECT job,FLOOR((COUNT(*)+1)/2) AS `start`,FLOOR((COUNT(*)+1)/2)+if(COUNT(*) % 2=1,0,1) AS `end` \nfrom grades\nGROUP BY job \norder by job;',NULL,NULL,0),(35,9,42,'select B.* from\n(SELECT job,FLOOR((COUNT(*)+1)/2) AS `start`,FLOOR((COUNT(*)+1)/2)+if(COUNT(*) % 2=1,0,1) AS `end` \nFROM grades  GROUP BY job) A\nJOIN\n(select g1.*, (\n    select count(distinct g2.score) \n    from grades g2 \n    where g2.score>=g1.score and g1.job=g2.job) as t_rank\nfrom grades g1 ) B\non (A.job=B.job  and B.t_rank between A.start and A.end)\norder by B.user_id;',NULL,NULL,0),(36,10,43,'select d.department_name as department, AVG(e.salary) as avg_salary\nfrom employees e LEFT JOIN departments d\non e.department_id = d.department_id\nwhere d.department_name = \'Technology\'\ngroup by e.department_id;',NULL,NULL,0),(37,10,44,'select d.department_name department, MAX(salary)-MIN(salary) as sub\nfrom employees e LEFT JOIN departments d \non e.department_id = d.department_id\ngroup by e.department_id;',NULL,NULL,0),(38,10,45,'select d.department_name as department,t.name,t.salary from \ndepartments d join \n(select name,salary,department_id from employees e1 where 1 = \n(select count(distinct(salary)) from employees e2 \nwhere e1.department_id = e2.department_id \nand e1.salary < e2.salary)) t\non d.department_id = t.department_id\norder by department;',NULL,NULL,0),(39,10,46,'select d.department_name as department,e.name ,e.salary as salary\nfrom employees as e left join departments as d \non e.department_id = d.department_id\nwhere e.id in\n(\n    select e1.id\n    from employees as e1 left join employees as e2\n    on e1.department_id = e2.department_id and e1.salary < e2.salary\n    group by e1.id\n    having count(distinct e2.salary) <= 2\n)\nand e.department_id in (select department_id from departments)\norder by d.department_name asc,e.salary desc;',NULL,NULL,0),(40,2,47,'select s.sname from sailors s\nwhere not exists (\n	select * from boats b \n	where not exists (\n		select * from reserves r\n		where r.sid = s.sid and r.bid = b.bid\n	)\n);',NULL,NULL,0),(41,2,48,'select s.sname\nfrom sailors s\nwhere exists(\n	select *\n	from reserves r join boats b\n	on r.bid = b.bid\n	where b.color = \'GREEN\' and r.sid = s.sid and r.reserve_date between \'2020-05-01\' and \'2020-05-31\'\n)\norder by rating DESC\nlimit 1;',NULL,NULL,0),(42,2,49,'select s.sname\nfrom sailors s\nwhere s.age > 35 and exists(\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid\n	where r.sid = s.sid and b.color = \'GREEN\' and r.reserve_date between \'2020-08-01\' and \'2020-08-31\'\n) and exists (\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid\n	where r.sid = s.sid and b.color = \'RED\' and r.reserve_date between \'2020-08-01\' and \'2020-08-31\'\n);',NULL,NULL,0),(43,11,52,'select activity\nfrom friends\ngroup by activity\nhaving count(*)>any(\n    select count(*) from friends group by activity\n) and count(*)<any(\n    select count(*) from friends group by activity\n)',NULL,NULL,0),(44,11,53,'select name, friends.activity\nfrom activities,friends\nwhere activities.activity=friends.activity and (startDate between \'2020-02-20\' and \'2020-02-28\') and (endDate between \'2020-02-20\' and \'2020-02-28\')',NULL,NULL,0),(45,11,55,'select friends.name \nfrom friends,activities\nwhere friends.activity=activities.activity and friends.activity=\'eating\'',NULL,NULL,0),(46,12,56,'select title from \n(select m.title,avg(mr.rating) as rt from movie_rating mr\ninner join movies m\non m.movie_id = mr.movie_id \ninner join users u \non u.user_id = mr.user_id \nwhere mr.created_at between \'2020-02-01\' and \'2020-02-29\'\ngroup by m.movie_id\norder by rt desc,m.title asc\nlimit 1) b',NULL,NULL,0),(47,12,57,'(SELECT name\nFROM users AS U\nINNER JOIN movie_rating AS MR\nON U.user_id = MR.user_id\nGROUP BY U.user_id\nORDER BY COUNT(*) DESC, name\nLIMIT 1)\n',NULL,NULL,0),(48,12,58,'select movies.movie_id,title, avg(rating)as avg_rating, max(rating) as max_rating, min(rating) as min_rating\nfrom movies, movie_rating\nwhere movies.movie_id=movie_rating.movie_id\ngroup by movies.movie_id',NULL,NULL,0),(49,12,59,'select name, title,created_at\nfrom movie_rating,users,movies\nwhere movie_rating.created_at between \'2020-01-01\' and \'2020-01-31\' and movie_rating.movie_id=movies.movie_id and movie_rating.user_id=users.user_id',NULL,NULL,0),(50,12,60,'select movie_rating.user_id,name,title,rating\nfrom users,movie_rating,movies\nwhere movies.movie_id=movie_rating.movie_id and movie_rating.user_id=users.user_id and movie_rating.user_id=1',NULL,NULL,0),(51,13,61,'select invoice_id,price,invoices.user_id,customer_name\nfrom invoices,customers\nwhere invoices.user_id=customers.customer_id and price=(select max(price) from invoices)',NULL,NULL,0),(52,13,62,'select t.user_id,contact_name,contact_email\nfrom\n(\n    SELECT user_id,count(*) count_temp\n    FROM invoices\n    GROUP BY user_id  \n    HAVING count_temp>1\n)t, customers,contacts \nwhere t.user_id=customers.customer_id and customers.customer_id=contacts.user_id',NULL,NULL,0),(53,13,63,'select t.user_id,customer_name,email\nfrom\n(\n    SELECT user_id,count(*) count_temp\n    FROM invoices\n    GROUP BY user_id  \n    HAVING count_temp=1\n)t, customers\nwhere t.user_id=customers.customer_id',NULL,NULL,0),(54,13,64,'select customer_id,customer_name,contact_name\nfrom customers,contacts\nwhere customer_id=user_id',NULL,NULL,0),(55,14,65,'SELECT t.group_id, t.player_id\n\nFROM\n(SELECT p1.group_id, t4.scores, MIN(t4.player_id) AS player_id\nFROM\n(SELECT t3.player_id, SUM(t3.score) AS scores\nFROM\n((SELECT first_player AS player_id, SUM(first_score) AS score\nFROM matches\nGROUP BY first_player)\nUNION ALL\n(SELECT second_player AS player_id, SUM(second_score) AS score\nFROM matches\nGROUP BY second_player)) AS t3\n\nGROUP BY t3.player_id) AS t4\nINNER JOIN players AS p1\nON t4.player_id=p1.player_id\nGROUP BY p1.group_id, t4.scores) AS t\n\nWHERE (t.group_id, t.scores) IN\n(\nSELECT p.group_id, MAX(t2.scores)\nFROM\n(SELECT player_id, SUM(score) AS scores\nFROM\n((SELECT first_player AS player_id, SUM(first_score) AS score\nFROM matches\nGROUP BY first_player)\nUNION ALL\n(SELECT second_player AS player_id, SUM(second_score) AS score\nFROM matches\nGROUP BY second_player)) AS t1\nGROUP BY player_id) AS t2\nINNER JOIN\nplayers AS p\nON t2.player_id=p.player_id\nGROUP BY p.group_id\n)\n',NULL,NULL,0),(56,14,66,'select player_name, match_id, t.score\nfrom\n(\nselect player_name, match_id,second_score as score\nfrom players, matches\nwhere (players.player_id=matches.first_player or players.player_id=matches.second_player) and players.player_name=\'Aron\' \n\nunion\n\nselect player_name, match_id,first_score as score\nfrom players, matches\nwhere (players.player_id=matches.first_player or players.player_id=matches.second_player) and players.player_name=\'Aron\'\n) t\nwhere t.score<>0',NULL,NULL,0),(57,14,67,'select s1.gender,s1.day,sum(s2.score_points) as total from scores s1\ninner join scores s2\non s1.gender = s2.gender \nand s1.day >= s2.day \nand s1.gender=\'F\'\ngroup by s1.gender,s1.day  \norder by s1.gender,s1.day',NULL,NULL,0),(58,14,68,'select player_name,gender,score_points\nfrom scores\nwhere day between \'2020-01-01\' and \'2020-01-31\'',NULL,NULL,0),(59,14,69,'select players.player_name, player_id, score_points as score_points\nfrom scores,players\nwhere scores.player_name=players.player_name and score_points=(select min(score_points) from scores)',NULL,NULL,0),(60,15,70,'SELECT c.name as customer_name,o2.customer_id,o2.order_id,o2.order_date\nFROM orders o1,orders o2,customers c\nWHERE\n	o1.customer_id = o2.customer_id  and o2.customer_id = 1 and c.customer_id = o2.customer_id\nGROUP BY\n	c.name,\n	o2.order_id,\n	o2.customer_id,\n	o2.order_date\nHAVING\n	SUM(o1.order_date >= o2.order_date) <= 3\nORDER BY\n	c.name,\n	o2.customer_id,\n	o2.customer_id,\n	o2.order_date desc',NULL,NULL,0),(61,15,71,'select t2.customer_id,t3.product_id,p.product_name\nfrom\n(select t1.customer_id,max(t1.cnt) freq\nfrom\n(select customer_id,product_id,count(order_id) cnt\nfrom orders\ngroup by customer_id,product_id) t1\ngroup by t1.customer_id) t2 join (\nselect customer_id,product_id,count(order_id) cnt\nfrom orders\ngroup by customer_id,product_id\n) t3 on t2.freq=t3.cnt and t2.customer_id=t3.customer_id\njoin products p on p.product_id=t3.product_id\norder by customer_id, product_id\n',NULL,NULL,0),(62,15,72,'select product_name, o.product_id, order_id, order_date\nfrom orders o left join products p\nusing(product_id)\nwhere (product_id, order_date) in\n(\n    select product_id, max(order_date) order_date\n    from orders\n    group by product_id\n)\norder by product_name, product_id, order_id',NULL,NULL,0),(63,15,73,'SELECT product_name\nFROM products JOIN orders USING (product_id)\nWHERE order_date LIKE \"2020-08%\"\nGROUP BY product_name',NULL,NULL,0),(64,15,74,'SELECT\n    customer_id, name\nFROM\n    customers\nWHERE\n    customer_id NOT IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =3\n    ) AND customer_id IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =2\n    ) AND customer_id IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =1\n    )\nORDER BY customer_id',NULL,NULL,0),(65,16,75,'SELECT name,company,\n      (SELECT borrow_date FROM borrows WHERE reader_id =\n      (SELECT reader_id FROM readers WHERE name=\'???\') )   \n                  borrow_date\nFROM readers WHERE reader_id = (\n    SELECT reader_id FROM borrows WHERE  borrow_date = \n        (SELECT borrow_date FROM borrows WHERE reader_id =\n        (SELECT reader_id FROM readers WHERE name=\'???\') ) \n    AND reader_id != (SELECT reader_id FROM readers \n                                   WHERE name=\'???\') );',NULL,NULL,0),(66,16,76,'SELECT reader_id,name,company FROM readers \n    WHERE company=\'???\' and reader_id NOT IN\n            (SELECT reader_id FROM borrows \n             WHERE borrow_date>=\'2006-08-01\');',NULL,NULL,0),(67,16,77,'SELECT name,company FROM readers WHERE reader_id in\n       (SELECT distinct reader_id FROM borrows \n         GROUP BY reader_id having count(book_id)>=2);',NULL,NULL,0),(68,16,78,'SELECT writer,book_name,\n   (SELECT borrow_date FROM borrows WHERE book_id in\n      (SELECT book_id from books WHERE writer LIKE \'?%\')) as borrow_date\nFROM books WHERE writer LIKE \'?%\';',NULL,NULL,0),(69,16,79,'SELECT DISTINCT(book_name),price FROM books\n    WHERE output=\'???????\' \n    ORDER BY price DESC;',NULL,NULL,0),(70,17,80,'select period_state,min(date) start_date,max(date) end_date from (\nselect \n\"failed\" period_state,\nfail_date as date,\nif(datediff(@pre_date,@pre_date:=fail_date)=-1,@id,@id:=@id+1) id\nfrom failed,(select @id:=0,@pre_date:=NULL)tmp1\nunion\nselect \n\"succeeded\" period_state,\nsuccess_date as date,\nif(datediff(@pre_date,@pre_date:=success_date)=-1,@id,@id:=@id+1) id\nfrom succeeded,(select @id:=0,@pre_date:=NULL)tmp2\n) tmp\nwhere date BETWEEN \"2019-01-01\" AND \"2019-12-31\"\ngroup by id,period_state\nORDER BY start_date ASC\n',NULL,NULL,0),(71,17,81,'SELECT business_id\nFROM events AS e\nJOIN (\n    SELECT event_type, AVG(occurences) AS eventAvg\n    FROM events\n    GROUP BY event_type\n) AS e1 \nON e.event_type = e1.event_type\nWHERE e.occurences > e1.eventAvg\nGROUP BY business_id\nHAVING COUNT(*) >= 2',NULL,NULL,0),(72,17,82,'Select x.event_type as event_type , IFNULL(x.success_count, 0) as success_count, IFNULL(y.fail_count, 0) as fail_count \nfrom events e\nleft join \n(select count(success_date) as success_count, event_type from succeeded group by event_type) as x on e. event_type= x. event_type\nLeft join\n(select count(fail_date) as fail_count, event_type from failed group by event_type) as y on y. event_type= e. event_type\ngroup by event_type,success_count,fail_count',NULL,NULL,0),(73,17,83,'Select min(occurences) as occurences, e.event_type, IFNULL(t.fail_cnt, 0) as fail_count\nfrom events e \nleft join\n(select count(fail_date) as fail_cnt, event_type from failed \nwhere fail_date between  \'2018-12-01\' and \'2018-12-31\' and event_type=\'reviews\') as t\non t. event_type= e. event_type \nwhere t.event_type=\'reviews\'',NULL,NULL,0),(74,17,84,'select business_id\nfrom events\nwhere occurences=(select max(occurences)\n                   from events)\n',NULL,NULL,0),(75,18,85,'select s.* from \n    students s where s.s_id in(\n        select s_id from scores where s_id not in(\n            select a.s_id from scores a \n                join scores b on a.s_id = b.s_id and b.c_id=2\n                join scores c on a.s_id = c.s_id and c.c_id=3\n            where a.c_id=1))',NULL,NULL,0),(76,19,89,'SELECT\n	department.NAME AS department_name,\n	employee.NAME AS employee,\n	salary \nFROM\n	employee,\n	department \nWHERE\n	employee.DepartmentId = department.Id \n	AND ( employee.DepartmentId, Salary ) \n    IN (SELECT DepartmentId, max( Salary ) \n        FROM employee \n        GROUP BY DepartmentId )',NULL,NULL,0),(77,19,90,'SELECT\n    a.Name AS \'employee\'\nFROM\n    employee AS a,\n    employee AS b\nWHERE\n    a.ManagerId = b.Id\n        AND a.Salary > b.Salary\n;',NULL,NULL,0),(78,19,91,'SELECT\n    (SELECT DISTINCT\n            salary\n        FROM\n            employee\n        ORDER BY Salary DESC\n        LIMIT 1 OFFSET 1) AS SecondHighestSalary\n;',NULL,NULL,0),(79,20,92,'select * from emp \nwhere sal > ( select max(sal) from emp where deptno = 30);  ',NULL,NULL,0),(80,20,93,'select ename,sal from emp e ,salgrade s \nwhere e.sal >= s.losal and e.sal <= s.hisal \nand s.grade = 4; ',NULL,NULL,0),(81,20,94,'select ename ,dname ,sal ,losal,hisal from emp,dept,salgrade \nwhere emp.deptno = dept.deptno and grade = 2 \nand sal >= losal and sal < hisal; ',NULL,NULL,0),(82,20,95,'select e.* from emp e, salgrade s \nwhere e.mgr=7698 and s.hisal < e.sal and s.grade = \n  ( select grade from salgrade s ,emp e \nwhere s.losal < e.sal and s.hisal > e.sal and e.ename = \'smith\'); ',NULL,NULL,0),(83,20,96,'select ename, deptno,sal * 12 as ySalary \nfrom emp \nwhere deptno=20\norder by ySalary; ',NULL,NULL,0),(84,18,98,'  select d.*,c.??,c.s_score,c.c_id from (\n                select a.s_id,a.s_score,a.c_id,@i:=@i+1 as ?? from scores a,(select @i:=0)s where a.c_id=1    \n            )c\n            left join students d on c.s_id=d.s_id\n            where ?? BETWEEN 2 AND 3\n            UNION\n            select d.*,c.??,c.s_score,c.c_id from (\n                select a.s_id,a.s_score,a.c_id,@j:=@j+1 as ?? from scores a,(select @j:=0)s where a.c_id=2   \n            )c\n            left join students d on c.s_id=d.s_id\n            where ?? BETWEEN 2 AND 3',NULL,NULL,0),(85,18,99,'select a.c_id,b.c_name,MAX(s_score)as max_score,MIN(s_score) as min_score,\n    ROUND(SUM(case when a.s_score<60 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'????\',\n    ROUND(SUM(case when a.s_score>=60 and a.s_score<90 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'???\',\n    ROUND(SUM(case when a.s_score>=90 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'???\'\n    from scores a left join courses b on a.c_id = b.c_id GROUP BY a.c_id,b.c_name',NULL,NULL,0),(86,18,100,' select distinct f.c_name,a.c_id,b.`85-100`,b.percent,c.`70-85`,c.percent,d.`60-70`,d.percent,e.`0-60`,e.percent from scores a\n                left join (select c_id,SUM(case when s_score >85 and s_score <=100 then 1 else 0 end) as `85-100`,\n                                            ROUND(100*(SUM(case when s_score >85 and s_score <=100 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)b on a.c_id=b.c_id\n                left join (select c_id,SUM(case when s_score >70 and s_score <=85 then 1 else 0 end) as `70-85`,\n                                            ROUND(100*(SUM(case when s_score >70 and s_score <=85 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)c on a.c_id=c.c_id\n                left join (select c_id,SUM(case when s_score >60 and s_score <=70 then 1 else 0 end) as `60-70`,\n                                            ROUND(100*(SUM(case when s_score >60 and s_score <=70 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)d on a.c_id=d.c_id\n                left join (select c_id,SUM(case when s_score >=0 and s_score <=60 then 1 else 0 end) as `0-60`,\n                                            ROUND(100*(SUM(case when s_score >=0 and s_score <=60 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)e on a.c_id=e.c_id\n                left join courses f on a.c_id = f.c_id',NULL,NULL,0),(87,18,101,'select a.s_name from students a where a.s_id not in (\n    select s_id from scores where c_id = \n                (select c_id from courses where t_id =(\n                    select t_id from teachers where t_name = \'??\')) \n                group by s_id);\n',NULL,NULL,0),(88,13,103,'select i.invoice_id, c1.customer_name, i.price, \n    count(ct.contact_name) contacts_cnt ,\n    count(c2.customer_name) trusted_contacts_cnt \nfrom invoices i join customers c1 on i.user_id=c1.customer_id\n    left join contacts ct on i.user_id=ct.user_id\n    left join customers c2 on ct.contact_email=c2.email\ngroup by i.invoice_id\norder by i.invoice_id',NULL,NULL,0),(89,19,104,'select b.departmentId,b.salary\nfrom (\n    select DepartmentId,salary,\n    case @com when DepartmentId then @rk:=@rk+1 else @rk:=1 end rk,\n    @com:=DepartmentId\n    from employee,(select @rk:=0, @com:=\'\') a\n    order by DepartmentId,salary) b\nleft join \n    (\n    select DepartmentId,count(1)/2 cnt from employee group by DepartmentId) c\non b.DepartmentId=c.DepartmentId\nwhere b.rk in (cnt+0.5,cnt+1,cnt);',NULL,NULL,0),(90,11,105,'select count(activity) as cnt, activity\nfrom friends\nGROUP BY activity\nhaving cnt > 1\n',NULL,NULL,0),(91,175,881,'select p.FirstName,p.LastName,a.City,a.State\nfrom\nperson p left join address a\non\np.personid=a.personid',NULL,NULL,0),(92,176,882,'select max(Salary) SecondHighestSalary\nfrom employee\nwhere\nsalary<(select max(salary) from employee)',NULL,NULL,0);
/*!40000 ALTER TABLE `answer_set` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `batches`
--

DROP TABLE IF EXISTS batch;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `batches` (
  `id` varchar(255) NOT NULL,
  `batch_text` text NOT NULL,
  `user_id` varchar(255) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `exam_id` varchar(255) NOT NULL,
  `main_id` int(11) NOT NULL,
  `sub_id` int(11) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `batches`
--

LOCK TABLES batch WRITE;
/*!40000 ALTER TABLE batch DISABLE KEYS */;
INSERT INTO batch VALUES ('00311954-d52e-4aa2-9be1-4a93c1f051b3','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 01:55:17','2022-04-08 01:55:17','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('0153308b-4e20-4e28-b3df-1aa2e3a71519','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:45:13','2022-04-12 20:45:13','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('01ec0c31-766c-4e25-bb49-f2a4214bfb3c','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:50:16','2022-04-12 20:50:16','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('0286f604-5fcd-4159-b197-21af349840fb','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:36:55','2022-03-31 01:36:55','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('02bcb015-1191-4b35-aef1-b3e8980372ef','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:18:30','2022-04-12 19:18:30','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('04829750-e685-4398-9869-a631b3cd48e3','select e.Salary SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<(select max(e1.salary) from employee e1)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:30:53','2022-04-01 15:30:53','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('059278bc-b106-443a-a815-c9596a16ca7b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:32:27','2022-04-01 19:32:27','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('05cf508c-2cb4-4032-9a57-070aecf68017','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 20:33:22','2022-04-16 20:33:22','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('0628a578-8c42-47a8-a9dd-8be698a7367a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 01:42:37','2022-04-08 01:42:37','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('069d2a27-7421-45c3-83dc-6baf60288ada','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:49:46','2022-04-01 21:49:46','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('074a87e5-6324-4325-b650-f4bdd379d705','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:15:07','2022-04-01 22:15:07','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('07edd456-6bc5-4905-9d0e-ba98ff56f125','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:35:26','2022-04-01 20:35:26','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('098e4751-9d62-43af-b4d2-55563a0a6cc6','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-05-03 21:59:42','2022-05-03 21:59:42','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('09d66c10-f2d4-43f4-a924-168855805a87','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 22:45:39','2022-03-30 22:45:39','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('0c6e5f7a-9bba-43a0-90a5-0df91bfcfb42','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:39:07','2022-03-31 01:39:07','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('0e55ffcd-3e63-490c-8e6b-0085c34d640e','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:28:19','2022-04-01 15:28:19','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('0e9143c6-4b7f-4517-8c71-4c69425df569','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:23:02','2022-04-01 20:23:02','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('0ff7829f-ff13-4e79-a159-67d64314fe55','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:41:59','2022-04-01 21:41:59','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('124f704e-f607-43e2-aca3-e0b74363d874','select dno, eno from employees e\r\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\r\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:20:14','2022-03-29 01:20:14','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('12698360-981a-4359-876c-b537be2f8a47','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:06:26','2022-03-31 00:06:26','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('1285d4f7-6af7-4f08-9fd3-0ab2f7a5c4f5','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:39:41','2022-04-12 19:39:41','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('12d493e4-a010-433d-926b-af7b2e974738','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:25:19','2022-04-02 13:25:19','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('133f73b9-a6c9-44f2-b908-e29b473ff92a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:48:50','2022-04-12 22:48:50','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('134a0e96-fad3-4759-8318-09f57c2eaac3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:15:19','2022-04-01 20:15:19','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('13b02b36-d055-49e8-abbc-d143ee3021aa','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-06 19:30:25','2022-04-06 19:30:25','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('13f0c4a8-5297-45d4-9943-210c177ac93f','select p.FirstName,p.LastName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:30:00','2022-04-01 20:30:00','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('141b3430-2191-4d0f-b167-6e6dce86489a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:23:41','2022-04-12 19:23:41','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('1431d2ec-767a-4943-8385-12cae42a1232','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:37:04','2022-04-02 12:37:04','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('14461457-db18-44bb-92b3-8ed6a43f6e2e','select Salary SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 18:59:21','2022-04-01 18:59:21','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('14e20b76-49f4-4fdf-b77c-36d05badd674','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:02:13','2022-04-01 22:02:13','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('15e8ea20-d2fa-4a88-ab51-d2494617f30a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:20:12','2022-04-02 13:20:12','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('16019ef0-ccae-4efb-8033-ab42d2eb27f3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:07:24','2022-04-02 02:07:24','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('16bca85d-0895-4543-843a-cb4bd6e0194f','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 18:07:51','2022-03-29 18:07:51','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('17a22c8b-ce07-431b-8e26-98066237e98b','select * from ','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:41:31','2022-04-01 21:41:31','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('17a8fe0c-26db-4fba-b822-689f2590d3db','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 23:01:11','2022-04-12 23:01:11','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('18d8e499-48a1-43ec-9057-79f21404e626','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:12:03','2022-04-01 20:12:03','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('1b1f377f-2b2f-4d75-ab3e-02d11ffdb86a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 23:01:29','2022-04-12 23:01:29','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('1b5ebfed-6a3a-45b4-b793-7cb5d9964f4d','select * from ','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:44:54','2022-03-29 01:44:54','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,11),('1b624ccd-a664-470c-995d-1c1b8ade76a7','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:28:31','2022-04-02 02:28:31','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('1baf5b94-8d90-4329-93a2-bf8217d624d0','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:16:07','2022-04-12 22:16:07','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('1e2e5986-1feb-4a17-a6af-96712f5f18a5','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:16:10','2022-04-01 22:16:10','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('1e6d0164-5ed0-4978-96e1-90229a526628','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 14:51:40','2022-04-02 14:51:40','c270f300-b9d9-4585-9d25-d20065c22ab5',176,882),('1f64fe6e-9d52-4b2c-9825-4a03f26518c2','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:15:24','2022-04-01 21:15:24','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('20bec7c4-3696-4971-99db-0b52ee6f866e','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:09:10','2022-04-12 20:09:10','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('21a4040e-82ff-45f1-b566-f7f25fcecd60','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:51:32','2022-04-01 20:51:32','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('238b21af-1b10-4ebf-86f7-e078d21eb2b9','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:16:25','2022-04-12 19:16:25','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('263f53f9-cf0f-44e7-b037-66c6724f6a32','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:51:30','2022-03-31 00:51:30','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('26e0431a-8877-440a-81b0-f046b4a85d84','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:45:34','2022-04-12 21:45:34','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('270255d4-8961-4590-ba72-df6a2efa0ee3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:04:49','2022-04-01 20:04:49','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('287801ba-268c-44b7-815c-cf42398ebaaf','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:26:26','2022-04-01 15:26:26','2b53c435-d7fa-42f9-adfb-03d1b244b367',175,881),('2bf28515-da58-4041-8c7f-169c9f055c1a','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:06:50','2022-03-31 01:06:50','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('2d6c284d-123b-4d50-a851-aeeb7deb33be','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:43:03','2022-04-12 19:43:03','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('3012b053-626e-4b4c-939b-a53364ba5677','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:18:10','2022-04-01 20:18:10','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('3186605f-4678-493d-9890-10cd88ae9941','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:26:09','2022-04-01 21:26:09','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('32308756-8322-445b-a80d-b0012f940fa0','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:08:59','2022-04-16 22:08:59','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('328fb612-9186-4e9c-b4e9-33cdd483293c','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 14:14:41','2022-03-31 14:14:41','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('33204817-826f-42ec-95ed-c82622005bba','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:54:42','2022-04-12 21:54:42','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('33ac970b-a11b-40d5-85e7-8f21ab67524b','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:15:45','2022-04-01 21:15:45','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('36e32e25-bafd-4ca0-8f7a-1a3e3d2b3166','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:09:39','2022-04-02 02:09:39','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('3747ba46-c97c-4d12-bb07-f1a8a0eab9b9','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:23:50','2022-04-12 21:23:50','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('38041b3c-b126-409b-82a3-d3ff2c56a4b8','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:28:50','2022-04-01 15:28:50','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('389061dc-24ce-40b5-a930-47486850dad5','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:29:33','2022-04-01 15:29:33','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('38b98b86-5638-41b8-baf1-fff2dc4a3a9f','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:04:02','2022-04-02 13:04:02','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('38ecc738-2d25-4297-a4a9-aad0eb777d38','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:17:16','2022-03-31 01:17:16','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('39bc96f1-3ebc-4972-a133-e6c9e81b9a0b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:21:05','2022-04-12 21:21:05','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('39f390c6-eeb4-4755-80ff-e285ef916fb3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:09:45','2022-04-12 20:09:45','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('39ff9cdf-4f0a-4ca0-8028-8884119d87b5','select dno, eno, salary from employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:33:10','2022-03-29 01:33:10','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('3a328c25-1cb0-4128-9852-6f1285ef7576','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:11:06','2022-04-01 22:11:06','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('3a534241-d58e-4a49-841f-51fd6612cba4','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:49:35','2022-04-12 22:49:35','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('3a738c9a-b655-41ff-8c78-58b027005118','select * from employees','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 23:49:24','2022-03-30 23:49:24','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('3bcdb4b1-a7cd-4eb1-ac77-6009e5f76816','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 23:34:38','2022-03-30 23:34:38','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('3d65ca93-6387-4083-98bc-498b311bfdfd','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:25:21','2022-04-01 19:25:21','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('3f29d555-3820-4d3f-a6de-fa6a527c94ec','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-06 20:07:01','2022-04-06 20:07:01','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('425b7ac8-db54-483e-9016-acd32b15256b','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:51:21','2022-03-31 00:51:21','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('44071086-c068-45b4-b6f9-8b9c9c79382a','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:49:55','2022-04-01 21:49:55','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('45341ae6-260e-493c-81f4-7000be379bcc','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000;','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:21:57','2022-03-30 00:21:57','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('45c32007-68db-419f-be34-b17a106d8139','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:47:12','2022-04-12 20:47:12','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('46d8903a-ecd2-4848-b07f-2bf37e8c0000','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:24:20','2022-03-30 00:24:20','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('470c8e6b-ae29-4fb3-995e-0abf53c5d7a6','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:47:23','2022-04-12 20:47:23','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('4882ef0e-d9f8-42c1-9b23-094754d18c44','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:03:36','2022-04-01 22:03:36','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('4899490d-caea-4571-953a-937bb87ab919','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:28:57','2022-04-01 19:28:57','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('48df4d66-2490-476d-a415-cd07b06978cb','select e.Salary SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<all(select max(e1.salary) from employee e1)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:38:23','2022-04-01 15:38:23','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('49d930fc-c9db-4a62-a929-77838b6164cb','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:21:22','2022-04-02 02:21:22','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('4a80d8f0-3013-474a-afae-c1fff17d533a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:27:30','2022-04-01 19:27:30','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('4be8ea30-2d7a-4982-8cf2-5fa3ddede2a7','select dno, eno, salary from employees e\r\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\r\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:20:26','2022-03-29 01:20:26','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('5037aaac-e81f-4b14-8492-42893adf53bf','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:54:15','2022-03-31 00:54:15','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('50416d89-537f-4a3d-869e-36b3e8ad7429','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:28:17','2022-04-01 20:28:17','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('512ba096-3fde-4dea-ba89-043a85073ae2','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:31:35','2022-04-02 02:31:35','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('52ca7b9a-a878-4bd3-9bf4-51da2a1f06bb','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:25:34','2022-04-12 21:25:34','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('52e20b4c-d5ab-4bf4-96a7-27ad26270ce3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:13:39','2022-04-12 22:13:39','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5304b36e-1f38-4756-b726-e855efd895b1','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-04 16:02:38','2022-04-04 16:02:38','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5327edcf-34f4-4a3c-8e16-128a6317baef','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:24:01','2022-03-30 00:24:01','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('5410c6c9-5563-47a8-bfe8-9f28dbd85bbe','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:03:48','2022-04-02 02:03:48','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('542583a9-eb9a-49f8-aa10-ebc28dbbcc15','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:11:06','2022-04-01 21:11:06','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('557b5f35-4c60-411b-bf58-707c06a7059c','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:20:24','2022-04-02 13:20:24','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('574302f8-b78a-4f53-9f91-caa7d37a9590','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 22:33:46','2022-03-30 22:33:46','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('57e9ed21-44d7-4fb7-95db-ece8ea367c7a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:42:18','2022-04-12 21:42:18','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('58168fc0-2c20-46d9-b326-81f075afb736','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:55:55','2022-03-31 01:55:55','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('5828e69b-5bc2-43f5-870d-3dbef6d4bc6c','select e.Salary SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:30:23','2022-04-01 15:30:23','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('58c2fae3-a401-4b4d-8009-e0680d84e8bb','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:45:31','2022-04-12 19:45:31','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('58c8c19b-38a0-4fb0-9394-b7fb9adeda3f','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-05-05 20:33:49','2022-05-05 20:33:49','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5917bd05-a703-44c2-ae57-d6a6615cc29e','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 13:27:10','2022-03-31 13:27:10','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('597895b8-8216-4af5-82fc-5f14cde0d7fc','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:43:38','2022-04-01 19:43:38','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('59927a51-b07f-4f76-a404-a4402184d9bc','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:25:40','2022-04-12 21:25:40','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5a26c006-e5a3-466c-97a6-ba3087de2307','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:13:31','2022-04-12 22:13:31','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5a4226f8-d4d1-404e-a4d5-218ea5a9b760','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:24:05','2022-04-02 13:24:05','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('5aafb75f-24b6-4c4a-9bd5-268099705c43','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:45:37','2022-04-12 22:45:37','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5b2a209d-5e42-434c-a8e0-aab05a96f5cc','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:07:51','2022-04-16 22:07:51','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5cd8c652-45d7-42a3-a237-b38e2a814faa','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:23:44','2022-04-01 20:23:44','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('5da76ac3-1ce5-4fbb-bd59-1c47ecc41a2a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:20:50','2022-04-12 22:20:50','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5dd12812-6947-437e-b7ec-c512226efe5f','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:38:44','2022-04-12 19:38:44','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('5ee793cd-3467-44fe-bfb7-85aafb3a6608','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:15:01','2022-04-12 20:15:01','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('601ce2d5-3eb5-40d3-b91b-787c72f2e809','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:21:45','2022-04-12 22:21:45','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('604cde5a-56ea-457d-a6f8-75a25d24743f','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 02:04:48','2022-03-31 02:04:48','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('604fac74-15f8-4e49-bede-56f96c8924cf','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:30:00','2022-04-02 02:30:00','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('608c47c8-e60b-4742-8034-72335ac22fad','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:28:46','2022-04-01 21:28:46','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('60be68a5-36c3-4f88-b4fc-7946bf415e82','select dno, eno, salary from employees e\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:25:58','2022-03-29 01:25:58','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('612b47e0-7b33-4997-bb62-c41f3a8f996c','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 22:34:02','2022-03-30 22:34:02','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('614d573b-87f7-4876-9669-2d8a8af4a562','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:43:09','2022-04-12 20:43:09','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('628c421b-b5f9-4ceb-b6f3-1ea2247e56e4','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:56:33','2022-03-31 01:56:33','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('6325ae29-ad80-451d-89fc-f807288313f4','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000;','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 23:55:53','2022-03-30 23:55:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('63b8804a-5329-4da3-9b64-0c75ad9e1821','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:08:13','2022-04-01 20:08:13','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('63d449ba-9cfe-4d90-9749-03cba255742a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:10:35','2022-04-12 20:10:35','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('64706fd1-ccc1-4c03-8860-673d35c830ac','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-06 20:06:46','2022-04-06 20:06:46','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('64e6748c-11b9-43f4-a484-09782db4b5e8','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:14:20','2022-04-01 19:14:20','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('66447ba0-05db-4be4-bc35-518932080045','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:34:01','2022-04-01 19:34:01','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('6652a765-43b5-4251-acae-2a391d57f638','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:42:06','2022-04-12 21:42:06','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('6726d944-28d0-4b43-a1c6-93284b04a9f2','select dno, eno, salary from employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 13:56:07','2022-03-29 13:56:07','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('677790eb-31f6-4cf0-88fc-2337122c3f4b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:30:35','2022-04-12 19:30:35','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('689f6563-242b-4cfb-94b0-8450b8d1b758','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:39:29','2022-04-12 21:39:29','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('6a8f993b-0693-42ac-8343-c039a3276601','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:00:18','2022-04-02 02:00:18','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('6ab48f84-2238-4592-9f51-46147d8a5858','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:56:07','2022-04-01 21:56:07','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('6e2a18db-3834-497a-a088-7c1dabc08c43','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:16:04','2022-04-12 22:16:04','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('6e30d3d7-f51d-4444-bc7a-1e300f8c6f57','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:26:18','2022-03-31 00:26:18','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('700ee24d-1b2a-4927-be8e-896dd1d19a27','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:39:17','2022-04-12 19:39:17','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('720b88f3-91fe-4603-b9ec-dbcca49e199c','select dno, eno, salary from employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:33:51','2022-03-29 01:33:51','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('726f97ba-ecca-4e3c-bb92-cd0bdd132cfc','select Salary SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:13:46','2022-04-01 19:13:46','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('73a81f38-fd9c-4483-a05a-3142031346b7','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:16:34','2022-04-02 02:16:34','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('73dc950e-44cb-40bb-8785-0de29b8c365e','select * from ','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:41:23','2022-04-01 21:41:23','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('74b48bd2-8173-4d02-9ea0-d76283363d73','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:56:03','2022-04-12 22:56:03','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('7558c75c-e350-4bd0-805c-e85ac7ee797f','select dno, eno, salary from employees e\r\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\r\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:22:38','2022-03-29 01:22:38','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('763d3927-37ab-4dea-856c-b3c741aa7fda','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:20:17','2022-04-12 19:20:17','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('76b18dec-1f53-4d34-8090-d3d375deda59','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 23:42:08','2022-04-01 23:42:08','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('779746bc-6376-44f4-b666-b9e098bd82e7','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:18:55','2022-04-12 19:18:55','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('77d05bfc-d10b-4b44-bb2b-18853222973b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:44:15','2022-04-01 19:44:15','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('77d77a01-9e07-4430-b883-7d942028f0cf','select Salary SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 14:52:53','2022-04-02 14:52:53','c270f300-b9d9-4585-9d25-d20065c22ab5',176,882),('78bcc37f-89ea-41ae-9b8e-bca7bfc5ddf3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:25:41','2022-04-12 19:25:41','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('7b118d7a-f655-48e2-8000-a77b9fdb5c79','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:17:05','2022-04-12 22:17:05','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('7d8cfe83-7172-4dd6-a334-06cac495af31','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:14:49','2022-04-12 22:14:49','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('7ebc0ebd-435c-4f53-830c-667097ee5394','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:07:34','2022-04-01 21:07:34','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('7f03f2cd-7886-4316-b35b-8c4951259f35','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100;','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:24:15','2022-03-30 00:24:15','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('81c06f4e-c25e-40be-95c7-9e726a42b3ed','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 22:30:39','2022-03-29 22:30:39','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('81ee73ad-e04d-4b7d-8f26-92e78056085c','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-06 20:06:01','2022-04-06 20:06:01','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('82164ce5-d4f5-4f08-bfd6-4d9f98ea2625','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:51:53','2022-03-31 00:51:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('8228803f-e223-455d-8d9a-59f16dda2b1b','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:10:07','2022-03-31 00:10:07','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('82aecf86-010b-4fc2-91df-336b29420e52','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:17:44','2022-04-01 19:17:44','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('841681fd-c904-42e6-a339-dc64a5c76046','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:14:44','2022-04-01 22:14:44','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('8543f22d-1a8b-4518-8053-241619a6bbd0','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:56:06','2022-03-31 01:56:06','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('86adb0fb-954d-441c-bd87-6f814da8ad88','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:39:35','2022-04-12 21:39:35','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('86d73b3d-6c29-43bc-9ff2-aef203c3b93e','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:52:29','2022-04-12 19:52:29','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('872c615e-f138-4159-bb23-5f1ea7555659','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 20','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:01:09','2022-03-31 00:01:09','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('88e15197-0ded-4f27-b7be-a4b0528fb9b3','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:21:20','2022-03-31 00:21:20','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('89d6db25-51bf-416c-ae60-fd05eeaa072b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:06:01','2022-04-02 02:06:01','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('8a8e63b4-06d6-4ba7-8dd5-009dfd614d40','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:27:24','2022-04-12 21:27:24','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('8a977a0f-5dc9-44b3-a8ce-ccfbf835df34','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:16:50','2022-04-02 13:16:50','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('8ad1c221-f48f-408e-8eca-d6e6caed4d9b','select dno, eno, salary from employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 14:06:09','2022-03-29 14:06:09','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('8af9048a-7489-46bd-b28a-4fb305d37779','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 14:54:19','2022-04-02 14:54:19','c270f300-b9d9-4585-9d25-d20065c22ab5',175,881),('8b98e19e-ca9c-44f6-8725-2b8599d552e7','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:18:59','2022-03-31 01:18:59','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('8bd7295b-da3e-426d-beb2-a7685e12e227','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:44:30','2022-04-02 12:44:30','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('8dbc1b91-a71b-4aff-9e75-74c9cbf7ba91','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:12:24','2022-04-02 13:12:24','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('8eea88df-2465-496c-a5cd-e4132e7ccba4','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 01:06:14','2022-04-08 01:06:14','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('8f94b487-bf3f-4af9-82b0-ffb3250f4ede','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:02:31','2022-04-01 22:02:31','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('8ff3600b-afcc-4743-a1f3-e1ab25c94994','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:17:19','2022-04-01 19:17:19','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('91da6c60-b850-4bdd-b897-d1bc9b2e2c2d','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:08:33','2022-03-31 01:08:33','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('940e0ea1-85c1-41b5-b07a-eababc502f1b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:26:11','2022-04-02 02:26:11','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('94d65ded-a3ba-429a-b764-74446f006eab','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:41:07','2022-04-16 22:41:07','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('9527b64e-6daf-415f-a481-ee3c99f05b25','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:55:07','2022-03-31 00:55:07','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('96264081-34a6-4335-be2b-9c7da00030b7','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:07:33','2022-03-31 01:07:33','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('989e8a2c-0556-4ecf-abfa-4494cb70bb84','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:37:43','2022-04-02 12:37:43','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('9bf9ee00-ce9b-484e-9c83-cb749799f241','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:14:00','2022-04-12 21:14:00','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('9c849c72-4ac2-4ae5-a05c-2a9b1a2710d7','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 14:55:28','2022-04-02 14:55:28','c270f300-b9d9-4585-9d25-d20065c22ab5',176,882),('9d4c795e-2df8-4d5e-82b4-82abf6aad9cb','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:14:43','2022-04-12 20:14:43','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('9d723aa9-58e5-4d7d-a5f2-1af8f2cb3e96','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:29:04','2022-04-01 15:29:04','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('9eed98d9-d4a5-4dda-8328-df543e189d40','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:22:13','2022-04-12 21:22:13','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('9f44ca35-19e5-4772-9d4c-ee67a81618c5','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:22:52','2022-04-02 12:22:52','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('a029a65a-ee87-417e-91b2-871561436aa3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:27:31','2022-04-12 21:27:31','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a0872020-d503-46d2-ae87-c08c10d7138a','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 13:26:35','2022-03-31 13:26:35','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a1ba8cff-2de6-44e0-8009-4ccac04349ac','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 23:49:54','2022-03-30 23:49:54','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a266ea47-36e8-4bab-a9c4-2b5e78766515','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:46:37','2022-04-12 20:46:37','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a2a320e5-4124-4491-aa02-ba40dbdf899f','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 02:03:38','2022-03-31 02:03:38','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a2e70d76-aa3a-46f7-abbb-ccd372495166','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 18:49:21','2022-04-01 18:49:21','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('a30cbf2e-d566-4088-b4e0-114eec8069bd','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:56:45','2022-03-31 01:56:45','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a384ec88-f28f-4a0f-b1c4-f7be9808dbdc','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 23:48:54','2022-03-29 23:48:54','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a38bc671-e7e7-487a-be9a-af72509e6a85','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:27:50','2022-03-31 00:27:50','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a41092a7-0368-4143-9967-02852464c7d0','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 13:26:44','2022-03-31 13:26:44','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a52ad8d7-7fed-47a4-8684-007c496b7a4e','select * from ','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:39:17','2022-03-29 01:39:17','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,11),('a6331390-afa1-4f72-9b8a-aaab887be898','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 19:42:59','2022-03-30 19:42:59','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a712643d-d8b6-433d-96de-d07c2f131082','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:45:24','2022-04-12 21:45:24','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a72aee9e-51c0-4426-a5c3-b618cec17215','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:28:20','2022-04-12 20:28:20','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a75f606f-c721-4e7a-98a7-8f3826cb4e1d','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:52:47','2022-04-12 22:52:47','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a858b6a3-f3b1-424c-95da-b5cbe41ee609','select dno, eno, salary from employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:31:51','2022-03-29 01:31:51','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a8d029cd-6a5f-4e99-88a2-634a49ea97e4','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100;','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:22:47','2022-03-30 00:22:47','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a93dccdf-3f92-4539-9027-77b520b5574e','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:18:19','2022-04-12 19:18:19','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('a93e2e63-308c-451d-a412-987d9268e20d','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 22:34:04','2022-03-29 22:34:04','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('a98f0e81-00ed-4406-96c9-e4c95b097514','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 16:11:31','2022-03-31 16:11:31','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('ab1667e6-ce1f-499e-899d-c36b9156e330','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:06:39','2022-03-31 01:06:39','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('abb39ebd-a7db-469f-8c84-551c1ce14c6a','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:02:01','2022-04-01 22:02:01','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('ad36f4c0-ab90-4f79-ad5c-fef01b9e25e4','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:23:58','2022-04-12 21:23:58','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('ad612a32-0d47-4148-a0c6-c9fdd8303f19','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:43:26','2022-04-02 12:43:26','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('af9fc935-8fe7-4a02-99b8-cc959d20ec53','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:04:23','2022-04-12 20:04:23','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b00012a7-2e8f-42a7-a526-7c95eeb2bc4c','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:43:28','2022-04-12 20:43:28','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b065c9c4-5602-4968-ba41-0313131a7f8b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:51:58','2022-04-12 22:51:58','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b0e7f0bd-aa01-4161-b2d1-32b50703b674','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 02:00:34','2022-04-08 02:00:34','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b26ec7ab-d4b5-498d-a076-e3eb65f77cb9','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:48:43','2022-04-12 22:48:43','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b27f13a2-5603-4203-8c99-81b1f2bb2d24','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:31:41','2022-04-12 19:31:41','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b30910bd-ae04-4eee-be13-5f528fb7e6cd','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:59:19','2022-04-01 19:59:19','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('b39741cb-e48e-4a89-8a48-6d78e9e124cc','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:12:34','2022-04-16 22:12:34','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('b404bce7-aec1-4034-8d2f-0a5ee259f933','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:27:41','2022-04-02 12:27:41','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('b42e6f60-fa19-4227-8911-f8836d20bb15','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:57:14','2022-03-31 01:57:14','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('b52375d2-f28e-4def-a15e-2b0087e84611','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 00:24:25','2022-03-30 00:24:25','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('b68e31b8-404f-42e0-a588-0f96a07b0fa3','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:03:50','2022-03-31 00:03:50','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('b9f266dd-95ab-4e6a-9cf3-b2505af0ad39','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:12:52','2022-04-02 02:12:52','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('ba362acc-87b7-4ad2-af33-9bb42cc9326f','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:12:45','2022-04-12 19:12:45','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('bcd07c3c-14f1-4d71-aeb1-e0b76096db8c','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:51:35','2022-04-01 19:51:35','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('bd55d61b-985a-44b0-981e-b92a76e698d6','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:57:01','2022-04-12 22:57:01','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('bd9911c8-7711-4685-b3ab-fbbc130fc095','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 12:39:54','2022-04-02 12:39:54','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('be2af93f-055d-4744-8759-276e2ee3b6f9','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 23:02:09','2022-04-12 23:02:09','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('bfc0ae5d-a9bc-4fa7-87d1-652f8c6b8dfc','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:28:33','2022-04-12 20:28:33','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('c51e9f28-84c4-48da-93b7-2d1574b23f5f','select e.Salary SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<all(select max(e1.salary) from employee e1)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:37:40','2022-04-01 15:37:40','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('c5880761-187e-47a1-bab0-75c6ee98f3f6','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:08:23','2022-03-31 01:08:23','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('c7330128-a257-4841-b23f-ec6cb80c1d2a','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:24:34','2022-03-31 01:24:34','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('c744724e-a5e2-4e5d-be90-6f3251c97c3d','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:22:26','2022-04-12 21:22:26','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('c75a5d23-8132-456e-9306-8f057b625870','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 20:33:05','2022-04-16 20:33:05','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('c7ccd1b0-16c7-4d1b-90e5-2ab185c01e3c','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 14:53:43','2022-04-02 14:53:43','c270f300-b9d9-4585-9d25-d20065c22ab5',175,881),('c896ff58-10c1-4444-b404-1e1d3f271e6e','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-04 16:02:02','2022-04-04 16:02:02','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('c9295b7a-9f9d-4574-b34a-b9b51597a72d','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 20:50:54','2022-04-16 20:50:54','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('c99d19ee-0393-43f3-b58e-70ff567e8354','select max(e.Salary) SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<all(select max(e1.salary) from employee e1)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:36:26','2022-04-01 15:36:26','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('cb74b3c9-b1dc-4272-bee6-16f2f864139c','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:19:34','2022-04-01 21:19:34','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('cc4aadd5-8646-433a-89d3-1da68eefae6b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-06 20:06:19','2022-04-06 20:06:19','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('cf4b0e2b-7c7b-4990-8760-2eb41295c559','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 02:07:16','2022-04-08 02:07:16','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('cf76fd78-43ac-46c6-8406-de9bb02529ce','select dno, eno, salary from employees e\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:29:35','2022-03-29 01:29:35','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('cf95ada2-1dd0-4b1e-a801-8072aad3e444','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:44:28','2022-04-12 19:44:28','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d02924f5-5002-446d-bb59-fcb25ec5ffe9','select max(e.Salary) SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<(select max(e1.salary) from employee e1)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:31:37','2022-04-01 15:31:37','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('d0b71468-6534-4ab7-bac6-77d790bfe1f8','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:38:33','2022-04-12 21:38:33','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d0eb388b-437e-497c-910c-6aa38ba12d19','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:28:32','2022-04-01 21:28:32','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('d151d611-f2e0-4b0c-aef1-96a9db1e6331','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:25:30','2022-03-31 01:25:30','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('d23174e1-b156-47ae-8466-087d263e6b91','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:51:04','2022-04-12 20:51:04','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d27506b4-12d2-42a1-9486-23fdfcb98335','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:23:18','2022-04-02 02:23:18','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('d40398e1-16f7-45c5-9a8a-ceec820fc3d2','select e.Salary SecondHighestSalary\r\nfrom employee e\r\nwhere\r\nsalary<(select max(e.salary) from employee e)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 15:30:41','2022-04-01 15:30:41','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882),('d426c2c9-eb95-4373-a5cf-cfb209c3cc2b','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:38:14','2022-04-12 21:38:14','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d46cfe52-ae56-4942-9179-542bec938a98','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:08:40','2022-04-02 02:08:40','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('d6bd419c-bf89-462b-b62a-e1050d03e96a','select Salary SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:43:17','2022-04-01 19:43:17','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('d6c4409b-7e61-4a27-9e50-e2f98d998c92','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:36:28','2022-04-01 19:36:28','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('d6cb360a-e89c-4ad3-beec-598be22aec43','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 23:52:53','2022-03-29 23:52:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('d785009c-f81e-4918-92e8-1cf220a785b8','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:26:41','2022-04-02 13:26:41','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('d83f24df-33ad-4b13-94d8-49447bc53940','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:42:06','2022-04-02 02:42:06','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('d87b97e2-2beb-4f55-a2f4-1e7abfccc65f','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:42:42','2022-04-16 22:42:42','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d8c5ff1b-9203-4e92-bdd2-7c0fbdfacda8','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:00:33','2022-04-12 20:00:33','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('d8e8399f-bc4b-4ce9-9431-1338d3f5879c','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:32:10','2022-04-02 02:32:10','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('d9e3f8e3-bc25-4e60-8980-80966426fe63','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:52:54','2022-04-12 22:52:54','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('daf44ccc-46bb-4e97-8aba-174a80d8ca90','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:16:26','2022-04-12 21:16:26','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('dc40b61b-6b41-454a-8d12-34bf0db28e56','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:10:24','2022-04-02 13:10:24','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('dd0db62a-14a6-4f90-9326-0d8edc8b4ab4','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-05-25 20:54:41','2022-05-25 20:54:41','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('defa3440-67d1-4def-b144-23b3d0028798','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:08:13','2022-04-02 13:08:13','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('dfd5ada2-e02f-42e0-9b30-1b1fbc631872','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:07:43','2022-04-12 20:07:43','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('dff4f4eb-8e49-4422-a1b3-3390a8125c35','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 20:30:44','2022-04-16 20:30:44','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('e09dc0f1-2adc-4df4-a232-768cb2f61a7d','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 14:58:45','2022-04-01 14:58:45','7f578d03-d1a4-4a1d-8ce5-82d3071805a2',175,881),('e188862e-684d-43aa-b781-3d8452312642','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 10','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:15:30','2022-03-31 00:15:30','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('e2a8a2e0-d767-4a52-9e53-bb39dba3c640','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:22:04','2022-04-12 22:22:04','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('e2b79f89-2969-4099-be37-fa2cf261a909','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:20:38','2022-04-12 21:20:38','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('e4a1d8d0-23b1-4fcb-9be6-10016aaef822','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 100','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 00:25:53','2022-03-31 00:25:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('e4e224c3-65a8-45c7-817f-f2608eea9fe4','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 19:18:00','2022-04-12 19:18:00','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('e6cdb25c-a583-4a44-afdf-0f9a7fa0fddb','select\n  dno,\n  eno,\n  salary\nfrom\n  employees e\nwhere\n  salary >= all (\n    select\n      e1.salary\n    from\n      employees e1\n    where\n      e1.dno = e.dno\n  )\norder by\n  dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:22:53','2022-03-29 01:22:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('e6f873f9-b494-4bc5-8ccf-de2a3c44e200','select min(Salary)\r\nfrom employee e\r\nwhere\r\nsalary>(select min(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-16 22:24:35','2022-04-16 22:24:35','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('e76bfc70-1e28-4db3-9a3e-eaca2de64ae1','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:11:13','2022-04-01 21:11:13','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('ea7398b7-4873-4424-97ee-ef501254e36a','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 19:15:57','2022-04-01 19:15:57','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('eac67899-b161-4c82-8801-d17463035a11','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\nhaving sum(hours) > 1000','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-30 19:40:12','2022-03-30 19:40:12','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('eaf63639-052c-4d43-ae78-b3781fe38eee','select dno, eno, salary from employees e\r\nwhere salary >= all (select e1.salary from employees e1 where e1.dno=e.dno)\r\norder by dno asc','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-29 01:20:48','2022-03-29 01:20:48','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('edcc010a-3f5a-4573-adc9-66ad7cde4dbf','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 02:04:16','2022-03-31 02:04:16','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('efb39599-008b-4bbb-b631-ba62d5645d73','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 13:27:53','2022-03-31 13:27:53','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('efe15876-b56f-4fc6-aa18-6fc02376d49f','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:19:17','2022-04-01 21:19:17','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('f091cce7-16a3-4857-b8c8-6d6de075f5bd','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 13:06:35','2022-04-02 13:06:35','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('f158a906-ece1-4b0f-a287-c6e9103021b1','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 21:24:36','2022-04-12 21:24:36','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('f3d1cc34-546a-4a37-9f8e-129cea7d9ddd','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:14:40','2022-04-12 22:14:40','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('f44ce803-3b76-4ed1-8656-5b469b6dd8b0','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:11:47','2022-04-01 21:11:47','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('f48363f8-f550-4c71-987a-40e28e3f0367','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 22:51:36','2022-04-12 22:51:36','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('f5b2f87b-e9ac-468b-909b-ff19ab0d50a4','select p.FirstName\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 22:14:50','2022-04-01 22:14:50','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('f83dddc5-ba07-4fc8-81dc-d7bf7aa18560','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:30:55','2022-04-01 21:30:55','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('f8d50fc4-2388-461d-ba98-c9a87d7be4e0','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:31:07','2022-04-01 20:31:07','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('f9602b24-72db-4ad5-be5e-d16c98b83664','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:40:06','2022-04-01 21:40:06','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881),('fa64add8-8c29-4f99-b9de-5c4eaad4ca5b','select max(Salary) SecondHighestSalary\r\nfrom employee','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-08 02:07:11','2022-04-08 02:07:11','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('fc4fa3e4-d12c-45d7-90cd-baf11848c7f1','select w.eno \r\nfrom works w\r\ngroup by w.eno','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:18:36','2022-03-31 01:18:36','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('fc8b3f05-4809-4348-9395-dc3c81002f70','select w.eno \r\nfrom works w\r\ngroup by w.eno\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-03-31 01:19:24','2022-03-31 01:19:24','c2031523-510e-47ec-a2e7-0ff400eae1e0',1,10),('fddd5cd5-c656-46fe-a4c6-90ce8d31ea96','select p.FirstName,p.LastName,a.City,a.State\r\nfrom\r\nperson p left join address a\r\non\r\np.personid=a.personid','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 21:41:50','2022-04-01 21:41:50','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('fe7cad68-9b35-4608-a90b-87e4e71113c6','select max(Salary) SecondHighestSalary\r\nfrom employee\r\n','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-12 20:49:22','2022-04-12 20:49:22','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882),('ffaad50b-9303-4f10-a6f8-cca192529731','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-02 02:04:36','2022-04-02 02:04:36','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882),('ffba0d81-6abe-4377-b6a8-4668507a4ea3','select max(Salary) SecondHighestSalary\r\nfrom employee\r\nwhere\r\nsalary<all(select max(salary) from employee)','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2022-04-01 20:24:27','2022-04-01 20:24:27','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882);
/*!40000 ALTER TABLE batch ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `cache`
--

DROP TABLE IF EXISTS `cache`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `cache` (
  `id` varchar(255) NOT NULL,
  `name` varchar(255) NOT NULL,
  `data` json DEFAULT NULL,
  `expiry_date` datetime NOT NULL,
  `created_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `cache_expiry_date` (`expiry_date`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `cache`
--

LOCK TABLES `cache` WRITE;
/*!40000 ALTER TABLE `cache` DISABLE KEYS */;
INSERT INTO `cache` VALUES ('11111111111','textMessageCode','\"1392\"','2021-11-10 13:16:27','2021-11-10 13:11:27'),('13235210595','textMessageCode','\"1499\"','2021-11-14 19:22:52','2021-11-10 12:55:31'),('18839040927','textMessageCode','\"9951\"','2021-11-11 22:12:25','2021-11-10 13:16:26');
/*!40000 ALTER TABLE `cache` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `courses`
--

DROP TABLE IF EXISTS `courses`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `courses` (
  `id` varchar(255) NOT NULL,
  `teacher_id` varchar(255) NOT NULL,
  `name` varchar(255) NOT NULL,
  `deleted` tinyint(4) DEFAULT '0',
  `code` varchar(255) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `courses`
--

LOCK TABLES `courses` WRITE;
/*!40000 ALTER TABLE `courses` DISABLE KEYS */;
INSERT INTO `courses` VALUES ('7266d31b-c2df-456b-b338-dc331f5c000c','0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18','',1,'0C05UwW1','2021-11-14 19:20:06','2021-11-14 19:20:17'),('9bf60d9c-8250-4351-8626-7313d26e132c','0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18','test',0,'Hs782gMq','2021-11-14 19:20:57','2021-11-14 19:23:48');
/*!40000 ALTER TABLE `courses` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `courses_students`
--

DROP TABLE IF EXISTS `courses_students`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `courses_students` (
  `course_id` varchar(255) NOT NULL,
  `student_id` varchar(255) NOT NULL,
  `deleted` tinyint(4) DEFAULT '0',
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`course_id`,`student_id`),
  KEY `courses_students_student_id_key` (`student_id`),
  CONSTRAINT `courses_students_course_id_key` FOREIGN KEY (`course_id`) REFERENCES `courses` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `courses_students_student_id_key` FOREIGN KEY (`student_id`) REFERENCES `students` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `courses_students`
--

LOCK TABLES `courses_students` WRITE;
/*!40000 ALTER TABLE `courses_students` DISABLE KEYS */;
INSERT INTO `courses_students` VALUES ('9bf60d9c-8250-4351-8626-7313d26e132c','3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92',0,'2021-11-14 19:22:16','2021-11-14 19:22:16');
/*!40000 ALTER TABLE `courses_students` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `exams`
--

DROP TABLE IF EXISTS `exams`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `exams` (
  `id` varchar(255) NOT NULL,
  `exam_name` varchar(255) NOT NULL,
  `start_time` datetime DEFAULT NULL,
  `end_time` datetime DEFAULT NULL,
  `course_id` varchar(255) DEFAULT NULL,
  `questions` text,
  `notice` varchar(255) DEFAULT NULL,
  `notice_created_at` datetime DEFAULT NULL,
  `creating_status` tinyint(4) NOT NULL DEFAULT '1',
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  KEY `exams_creating_status` (`creating_status`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `exams`
--

LOCK TABLES `exams` WRITE;
/*!40000 ALTER TABLE `exams` DISABLE KEYS */;
INSERT INTO `exams` VALUES ('67fa9751-c0aa-49a9-b0fd-54fc4431c2bd','lalala','2022-04-04 14:59:34','2022-06-30 14:59:42','9bf60d9c-8250-4351-8626-7313d26e132c','[{\"mainQuestion\":\"176\",\"subQuestions\":[{\"id\":882,\"point\":10}]},{\"mainQuestion\":\"175\",\"subQuestions\":[{\"id\":881,\"point\":10}]}]','','2022-04-04 14:59:51',3,'2022-04-04 14:59:52','2022-05-25 20:51:43'),('c270f300-b9d9-4585-9d25-d20065c22ab5','haha','2022-04-02 14:50:03','2022-06-30 14:50:09','9bf60d9c-8250-4351-8626-7313d26e132c','[{\"mainQuestion\":\"176\",\"subQuestions\":[{\"id\":882,\"point\":10}]},{\"mainQuestion\":\"175\",\"subQuestions\":[{\"id\":881,\"point\":10}]}]','','2022-04-02 14:50:20',3,'2022-04-02 14:50:21','2022-05-25 20:51:43');
/*!40000 ALTER TABLE `exams` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `exams_status`
--

DROP TABLE IF EXISTS `exams_status`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `exams_status` (
  `student_id` varchar(255) NOT NULL,
  `exam_id` varchar(255) NOT NULL,
  `status` tinyint(4) DEFAULT '1',
  `point` int(11) DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`student_id`,`exam_id`),
  KEY `exams_status_exam_id_key` (`exam_id`),
  CONSTRAINT `exams_status_exam_id_key` FOREIGN KEY (`exam_id`) REFERENCES `exams` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  CONSTRAINT `exams_status_student_id_key` FOREIGN KEY (`student_id`) REFERENCES `students` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `exams_status`
--

LOCK TABLES `exams_status` WRITE;
/*!40000 ALTER TABLE `exams_status` DISABLE KEYS */;
INSERT INTO `exams_status` VALUES ('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',1,NULL,'2022-04-04 14:59:52','2022-04-04 14:59:52'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','c270f300-b9d9-4585-9d25-d20065c22ab5',2,20,'2022-04-02 14:50:21','2022-04-02 14:56:51');
/*!40000 ALTER TABLE `exams_status` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `main_questions`
--
--
-- DROP TABLE IF EXISTS `main_questions`;
-- /*!40101 SET @saved_cs_client     = @@character_set_client */;
-- /*!40101 SET character_set_client = utf8 */;
-- CREATE TABLE `main_questions` (
--   `id` int(11) NOT NULL AUTO_INCREMENT,
--   `teacher_id` varchar(255) DEFAULT NULL,
--   `title` varchar(40) NOT NULL,
--   `desc` text NOT NULL,
--   `db_path` varchar(255) NOT NULL,
--   `created_at` datetime NOT NULL,
--   `updated_at` datetime NOT NULL,
--   `file_name` varchar(255) DEFAULT NULL,
--   `total_difficulty` int(11) NOT NULL DEFAULT '0',
--   `sub_count` int(11) NOT NULL DEFAULT '0',
--   `state` tinyint(4) NOT NULL DEFAULT '0',
--   PRIMARY KEY (`id`)
-- ) ENGINE=InnoDB AUTO_INCREMENT=2099 DEFAULT CHARSET=utf8;
-- /*!40101 SET character_set_client = @saved_cs_client */;
--
-- --
-- -- Dumping data for table `main_questions`
-- --
--
-- LOCK TABLES `main_questions` WRITE;
-- /*!40000 ALTER TABLE `main_questions` DISABLE KEYS */;
-- INSERT INTO `main_questions` VALUES (1,'fc05133a-9c8e-4199-be7d-9c863df1fa33','公司职员','设有一个公司内部信息管理数据库，表结构如下：\n\n有`employees`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  eno         | int     |\n|  ename       | varchar |\n|  salary      | int     |\n|  dno         | int     |\n+--------------+---------+\neno为该表主键。\n该表包含员工的工号，姓名，工资，部门编号等信息\n```\n\n有`projects`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  pno         | int     |\n|  pname       | varchar |\n|  city        | varchar |\n|  dno         | int     |\n+--------------+---------+\npno为该表主键。\n该表包含项目的项目编号，项目名称，所在城市，负责部门编号等信息。\n```\n\n有`works`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  eno         | int     |\n|  pno         | int     |\n|  hours       | int     |\n+--------------+---------+\n(eno,pno)为该表主键。\n该表包含员工的工号，参与的项目，在项目上工作的时间等信息\n```\n\n有`relations`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  eno         | int     |\n|  rname       | varchar |\n|  sex         | varchar |\n+--------------+---------+\n(eno,name)为该表主键。\n该表包含员工的工号，家属姓名，家属性别等信息\n```\n\n表的示例如下：\n\n`employees`表：\n```\n+-----+-------+--------+-----+\n| eno | ename | salary | dno |\n+-----+-------+--------+-----|\n|  1  |  Tom  | 128500 |  1  |\n|  2  | Jerry | 184300 |  2  |\n+-----+-------+--------+-----+\n```\n`projects`表：\n```\n+-----+-------+----------+-----+\n| pno | pname |   city   | dno |\n+-----+-------+----------+-----+\n|  1  | Java  | Beijing  |  1  |\n|  2  | C++   | Shanghai |  2  |\n+-----+-------+----------+-----+\n```\n`works`表：\n```\n+-----+-------+-------+\n| eno | pname | hours |\n+-----+-------+-------+\n|  1  | Java  | 400   |\n|  2  | C++   | 650   |\n+-----+-------+-------+\n```\n`relations`表：\n```\n+-----+-------+-----+\n| eno | rname | sex |\n+-----+-------+-----+\n|  1  | Bob   | 男  |\n|  2  | Alice | 女  |\n+-----+-------+-----+\n```\n','examDataFiles/upload_43ce1f7120ff71473174188ce1cc5bff.sql','2020-11-25 12:48:02','2022-04-21 20:31:48','tt1.sql',5,4,0),(2,'fc05133a-9c8e-4199-be7d-9c863df1fa33','船只租赁','设有一个船员租赁船只系统，表结构如下：\n\n有`sailors`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  sid         | int     |\n|  sname       | varchar |\n|  rating      | int     |\n|  age         | int     |\n+--------------+---------+\nsid为该表主键。\n该表包含船员的编号，姓名，等级和年龄\n```\n\n有`boats`表，\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n|  bid         | int     |\n|  bname       | varchar |\n|  color       | varchar |\n+--------------+---------+\nbid为该表主键。\n该表包含船只编号，船只名称和船只颜色\n```\n\n\n有`reserves`表，\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n|  sid          | int     |\n|  bid          | int     |\n|  reserve_date | date    |\n+---------------+---------+\n(sid,bid)为该表主键。\n该表包含船员编号，船员预定的船只编号，船员预定船只的日期\n```\n\n表的示例如下：\n\n`sailors`表：\n```\n+-----+-------+--------+-----+\n| sid | sname | rating | age |\n+-----+-------+--------+-----+\n| 1   | Tom   |  5     | 26  |\n| 2   | Rodje |  7     | 34  |\n+-----+-------+--------+-----+\n```\n`boats`表：\n```\n+-----+----------------+-------+\n| bid |     bname      | color |\n+-----+----------------+-------+\n| 1   |   BlackPearl   | BLACK |\n| 2   | FlyingDutchman | YELLOW|\n+-----+----------------+-------+\n```\n\n`reserves`表：\n```\n+-----+-----+------------+\n| sid | bid |reserve_date|\n+-----+-----+------------+\n| 1   | 1   | 2020-10-09 |\n| 2   | 2   | 2020-11-11 |\n+-----+-----+------------+\n```\n','examDataFiles/upload_05ad4609a85bdd74bfaeae9e010ff971.sql','2020-11-25 13:11:05','2021-04-13 15:59:04','tt2.sql',6,4,0),(3,'fc05133a-9c8e-4199-be7d-9c863df1fa33','顾客与商品','对于顾客购买产品，系统中有以下表结构：\n\n表: `customers`\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n+---------------+---------+\ncustomer_id 是该表主键。\n该表包含消费者的id和姓名.\n```\n\n表: `orders`\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| customer_id   | int     |\n| product_id    | int     |\n+---------------+---------+\norder_id 是该表主键。\n该表包含消费者产生的订单编号，订单日期，顾客id和商品id。\n不会有商品被相同的用户在一天内下单超过一次。\n```\n\n表: `products`\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| product_name  | varchar |\n| price         | int     |\n+---------------+---------+\nproduct_id 是该表主键。\n该表包含所有商品id，商品名称和商品价格.\n```\n\n表的示例如下:\n\n`customers`\n```\n+-------------+-----------+\n| customer_id | name      |\n+-------------+-----------+\n| 1           | Winston   |\n| 2           | Jonathan  |\n| 3           | Annabelle |\n| 4           | Marwan    |\n| 5           | Khaled    |\n+-------------+-----------+\n```\n`orders`\n```\n+----------+------------+-------------+------------+\n| order_id | order_date | customer_id | product_id |\n+----------+------------+-------------+------------+\n| 1        | 2020-07-31 | 1           | 1          |\n| 2        | 2020-07-30 | 2           | 2          |\n| 3        | 2020-08-29 | 3           | 3          |\n| 4        | 2020-07-29 | 4           | 1          |\n| 5        | 2020-06-10 | 1           | 2          |\n| 6        | 2020-08-01 | 2           | 1          |\n| 7        | 2020-08-01 | 3           | 1          |\n| 8        | 2020-08-03 | 1           | 2          |\n| 9        | 2020-08-07 | 2           | 3          |\n| 10       | 2020-07-15 | 1           | 2          |\n+----------+------------+-------------+------------+\n```\n\n`products`\n```\n+------------+--------------+-------+\n| product_id | product_name | price |\n+------------+--------------+-------+\n| 1          | keyboard     | 120   |\n| 2          | mouse        | 80    |\n| 3          | screen       | 600   |\n| 4          | hard disk    | 450   |\n+------------+--------------+-------+\n```','examDataFiles/upload_71966b752a7434908be2df37451b05ac.sql','2020-11-25 14:57:09','2021-04-27 11:48:27','title3.sql',7,4,0),(4,'fc05133a-9c8e-4199-be7d-9c863df1fa33','选手与比赛','在一场赛事中，选手经过分组后参加比赛，有以下表结构，\n`players `玩家表\n```\n+-------------+-------+\n| Column Name | Type  |\n+-------------+-------+\n| player_id   | int   |\n| group_id    | int   |\n+-------------+-------+\nplayer_id是此表的主键。\n该表包含选手id以及所在的组别\n```\n`matches` 赛事表\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| match_id      | int     |\n| first_player  | int     |\n| second_player | int     | \n| first_score   | int     |\n| second_score  | int     |\n| group_id      | int     |\n+---------------+---------+\nmatch_id 是此表的主键。\n该表包含一场比赛的比赛id，参与比赛的第一位选手和第二位选手，第一位选手的分数和第二位选手的分数以及两位选手所处的组别。\n```\n\n表的示例如下：\n\n`players` 表:\n```\n+-----------+------------+\n| player_id | group_id   |\n+-----------+------------+\n| 15        | 1          |\n| 25        | 1          |\n| 30        | 1          |\n| 45        | 1          |\n| 10        | 2          |\n| 35        | 2          |\n| 50        | 2          |\n| 20        | 3          |\n| 40        | 3          |\n+-----------+------------+\n```\n\n`matches` 表:\n```\n+------------+--------------+---------------+-------------+--------------+----------+\n| match_id   | first_player | second_player | first_score | second_score | group_id |\n+------------+--------------+---------------+-------------+--------------+----------+\n| 1          | 15           | 45            | 3           | 0            | 1        |\n| 2          | 30           | 25            | 1           | 2            | 1        |\n| 3          | 30           | 15            | 2           | 0            | 1        |\n| 4          | 40           | 20            | 5           | 2            | 3        |\n| 5          | 35           | 50            | 1           | 1            | 2        |\n+------------+--------------+---------------+-------------+--------------+----------|\n```','examDataFiles/upload_76d9037c6ac2cc5a85f5d37f1882ea48.sql','2020-11-25 15:26:47','2021-03-30 22:29:39','tt4.sql',8,4,0),(5,'fc05133a-9c8e-4199-be7d-9c863df1fa33','顾客与商品2','一位用户，既可以作为卖家也可以作为买家参与一场交易，以下为相关的表结构，\n\n表: `users`\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+ \n| user_id        | int     |\n| join_date      | date    |\n| favorite_brand | varchar |\n+----------------+---------+\nuser_id 是该表的主键\n表中包含一位某网站用户的个人id，注册时间和最喜欢的品牌。\n```\n\n表: `orders`\n```\n---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| item_id       | int     |\n| buyer_id      | int     |\n| seller_id     | int     |\n+---------------+---------+\norder_id 是该表的主键\n该表包含订单的id，日期，商品id，买方id和卖方id\n```\n\n表: `items`\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| item_id       | int     |\n| item_brand    | varchar |\n+---------------+---------+\nitem_id 是该表的主键\n该表包含商品id和商品品牌\n```\n\n表的示例如下：\n\n`users` 表:\n```\n+---------+------------+----------------+\n| user_id | join_date  | favorite_brand |\n+---------+------------+----------------+\n| 1       | 2019-01-01 | Lenovo         |\n| 2       | 2019-02-09 | Samsung        |\n| 3       | 2019-01-19 | LG             |\n| 4       | 2019-05-21 | HP             |\n+---------+------------+----------------+\n```\n\n`orders` 表:\n```\n+----------+------------+---------+----------+-----------+\n| order_id | order_date | item_id | buyer_id | seller_id |\n+----------+------------+---------+----------+-----------+\n| 1        | 2019-08-01 | 4       | 1        | 2         |\n| 2        | 2019-08-02 | 2       | 1        | 3         |\n| 3        | 2019-08-03 | 3       | 2        | 3         |\n| 4        | 2019-08-04 | 1       | 4        | 2         |\n| 5        | 2019-08-04 | 1       | 3        | 4         |\n| 6        | 2019-08-05 | 2       | 2        | 4         |\n+----------+------------+---------+----------+-----------+\n```\n\n`items` 表:\n```\n+---------+------------+\n| item_id | item_brand |\n+---------+------------+\n| 1       | Samsung    |\n| 2       | Lenovo     |\n| 3       | LG         |\n| 4       | HP         |\n+---------+------------+\n```\n','examDataFiles/upload_f875a1fd9a382b3ee6aee0bb476b58c6.sql','2020-11-25 15:40:42','2021-04-14 00:12:51','tt5.sql',8,4,0),(6,'fc05133a-9c8e-4199-be7d-9c863df1fa33','好友申请','在 Facebook 或者 Twitter 这样的社交应用中，人们经常会发好友申请也会收到其他人的好友申请。现在给如下两个表：\n\n表: `friend_requests`\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+ \n| sender_id      | int     |\n| send_to_id     | int     |\n| request_date   | date    |\n+----------------+---------+\n(sender_id,send_to_id,request_date) 是该表的主键\n一个人可能会向另一个人发送多条申请\n```\n\n表: `accepted_requests`\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+ \n| requester_id   | int     |\n| accepter__id   | int     |\n| accept_date    | date    |\n+----------------+---------+\n(request_id,accepter_id,accept_date) 是该表的主键\n一个人可能会多次同意其他人的申请\n```\n\n表的示例如下：\n\n`friend_requests`表：\n```\n| sender_id | send_to_id |request_date|\n|-----------|------------|------------|\n| 1         | 2          | 2016_06-01 |\n| 1         | 3          | 2016_06-01 |\n| 1         | 4          | 2016_06-01 |\n| 2         | 3          | 2016_06-02 |\n| 3         | 4          | 2016-06-09 |\n```\n\n\n`accepted_requests`表： \n\n```\n| requester_id | accepter_id |accept_date |\n|--------------|-------------|------------|\n| 1            | 2           | 2016_06-03 |\n| 1            | 3           | 2016-06-08 |\n| 2            | 3           | 2016-06-08 |\n| 3            | 4           | 2016-06-09 |\n| 3            | 4           | 2016-06-10 |\n```\n\n','examDataFiles/upload_b283494b294bc356f2ea79a5128e02fb.sql','2020-11-25 16:29:09','2021-04-10 21:29:14','title6.sql',8,4,0),(7,'fc05133a-9c8e-4199-be7d-9c863df1fa33','阅读记录','用户经常在网站上阅读文章，以下为记录阅读记录的表，\n\n`views` 表：\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| article_id    | int     |\n| author_id     | int     |\n| viewer_id     | int     |\n| view_date     | date    |\n+---------------+---------+\n此表无主键，因此可能会存在重复行。\n此表包含读者的id，阅读的文章id，文章作者的id和阅读的日期。\n请注意，同一人的 author_id 和 viewer_id 是相同的。\n```\n\n表的示例如下：\n\n`views` 表：\n```\n+------------+-----------+-----------+------------+\n| article_id | author_id | viewer_id | view_date  |\n+------------+-----------+-----------+------------+\n| 1          | 3         | 5         | 2019-08-01 |\n| 1          | 3         | 6         | 2019-08-02 |\n| 2          | 7         | 7         | 2019-08-01 |\n| 2          | 7         | 6         | 2019-08-02 |\n| 4          | 7         | 1         | 2019-07-22 |\n| 3          | 4         | 4         | 2019-07-21 |\n| 3          | 4         | 4         | 2019-07-21 |\n+------------+-----------+-----------+------------+\n```','examDataFiles/upload_b6c8ef6c90114b2d9c0d5df68bbf0479.sql','2020-11-25 16:42:10','2021-04-07 11:16:15','title7.sql',7,4,0),(8,'fc05133a-9c8e-4199-be7d-9c863df1fa33','网吧登录','用户在网吧使用机子时，会产生如下表，\n\n`logins` 表：\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| user_id       | int     |\n| client_id     | int     |\n| login_date    | date    |\n+---------------+---------+\nid是该表的主键。\n该表包含了该次登录的id号，登录用户的id，登录设备的id以及登录日期。\n```\n\n表的示例如下：\n\n`logins` 表：\n```\n+--------+-----------+-----------+------------+\n| id     |  user_id  | client_id | login_date |\n+--------+-----------+-----------+------------+\n| 1      | 1         | 2         | 2019-08-01 |\n| 2      | 2         | 1         | 2019-08-02 |\n| 3      | 3         | 3         | 2019-08-01 |\n| 4      | 1         | 1         | 2019-08-02 |\n| 5      | 5         | 2         | 2019-07-22 |\n| 6      | 4         | 2         | 2019-07-21 |\n| 7      | 4         | 4         | 2019-07-21 |\n+--------+-----------+-----------+------------+\n```','examDataFiles/upload_1a1059a102b4f59752d0fe0e0f972a84.sql','2020-11-25 16:52:34','2021-04-12 11:04:12','tt8.sql',9,4,0),(9,'fc05133a-9c8e-4199-be7d-9c863df1fa33','岗位成绩','一个公司的各个岗位，组织了考试让人参与，得到的表如下，\n\n`grades` 表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n|  user_id      | int     |\n|  job          | varchar |\n|  score        | int     |\n+---------------+---------+\nuser_id是该表的主键。\n该表包含人员id，参与的岗位名称以及成绩\n```\n\n表的示例如下：\n\n`grades` 表：\n```\n+-----------+-----------+------------+\n|  user_id  |   job     |  score     |\n+-----------+-----------+------------+\n|  1        |   C++     |  99        |\n|  2        |   C++     |  84        |\n|  3        |   Java    |  74        |\n|  4        |   Python  |  85        |\n|  5        |   Java    |  94        |\n+-----------+-----------+------------+\n```','examDataFiles/upload_1fe0d9609c0ad2305155981062c73072.sql','2020-11-25 18:50:52','2021-04-07 00:07:37','tt9.sql',7,4,0),(10,'fc05133a-9c8e-4199-be7d-9c863df1fa33','公司职员2','公司员工信息和部门信息包含在以下两张表中，\n\n有`employees`表，\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n| salary        | int     |\n| department_id | int     |\n+---------------+---------+\neno为该表主键。\n该表包含员工的工号，姓名，工资，部门编号等信息\n```\n\n有`departments`表，\n```\n+-----------------+---------+\n| Column Name     | Type    |\n+-----------------+---------+\n| department_id   | int     |\n| departmant_name | varchar |\n+-----------------+---------+\ndepartment_id为该表主键。\n该表包含部门编号，部门名称等信息。\n```\n\n表的示例如下：\n\n`employees` 表\n```\n+----+-------+--------+--------------+\n| id | name  | salary | department_id|\n+----+-------+--------+--------------+\n| 1  | Joe   | 84000  | 1            |\n| 2  | Henry | 80000  | 2            |\n| 3  | Sam   | 60000  | 2            |\n| 4  | Max   | 90000  | 1            |\n| 5  | Janet | 69000  | 1            |\n| 6  | Randy | 85000  | 1            |\n| 7  | Will  | 70000  | 1            |\n+----+-------+--------+--------------+\n```\n\n`departments` 表\n```\n+---------------+------------------+\n| department_id | department_name  |\n+---------------+------------------+\n|       1       |       IT         |\n|       2       |      Sales       |\n+---------------+------------------+\n```\n','examDataFiles/upload_e0015c5a7cb2bc9ac8f200623c5485ea.sql','2020-11-25 19:10:23','2021-03-30 23:07:16','tt10.sql',9,4,0),(11,'fc05133a-9c8e-4199-be7d-9c863df1fa33','参加活动情景','表: friends。\nid 是朋友的 id 和该表的主键。name 是朋友的名字。activity 是朋友参加的活动的名字\n\n```\nfriends 表:\n+------+--------------+---------------+\n| id   | name         | activity      |\n+------+--------------+---------------+\n| 1    | Jonathan D   | eating        |\n| 2    | Jade W       | singing       |\n| 3    | Victor J     | singing       |\n| 4    | Elvis Q      | singing       |\n| 5    | Daniel A     | horse riding  |\n| 6    | Bob B        | horse riding  |\n+------+--------------+---------------+\n```\n\n\n\n表: activities。id 是该表的主键。name 是活动的名字。\n\n```\nactivities 表:\n+------------+--------------+-------------+-------------+\n| ID         | activity     | startDate   | endDate     |\n+------------+--------------+-------------+-------------+\n| 1          | eating       | 2020-02-12  | 2020-02-20  |\n| 2          | singing      | 2020-02-21  | 2020-02-23  |\n| 3          | horse riding | 2020-02-24  | 2020-02-28  |\n+------------+--------------+-------------+-------------+\n\n```\n','examDataFiles/upload_7799bab2300280fcf98079020f1984b7.sql','2020-11-26 11:21:22','2021-04-14 00:16:17','useractivityscenario.sql',7,4,0),(12,'fc05133a-9c8e-4199-be7d-9c863df1fa33','电影相关情景','电影相关情景：\n\n\n\n表：users。user_id 是表的主键。\n\n```\n+-------------+--------------+\n| user_id     |  name        |\n+-------------+--------------+\n| 1           | Daniel       |\n| 2           | Monica       |\n| 3           | Maria        |\n+-------------+--------------+\n```\n\n\n\n\n\n表：movies。movie_id 是这个表的主键。title 是电影的名字。\n\n```\n+-------------+--------------+\n| movie_id    |  title       |\n+-------------+--------------+\n| 1           | Avengers     |\n| 2           | Frozen 2     |\n| 3           | Joker        |\n+-------------+--------------+\n```\n\n\n\n\n\n表：movie_rating。(movie_id, user_id) 是这个表的主键。这个表包含用户在其评论中对电影的评分 rating 。\ncreated_at 是用户的点评日期。 \n\n```\n+-------------+--------------+--------------+-------------+\n| movie_id    | user_id      | rating       | created_at  |\n+-------------+--------------+--------------+-------------+\n| 1           | 1            | 3            | 2020-01-12  |\n| 1           | 2            | 4            | 2020-02-11  |\n| 1           | 3            | 2            | 2020-02-12  |\n| 2           | 1            | 5            | 2020-02-17  | \n| 2           | 3            | 2            | 2020-03-01  |\n| 3           | 1            | 3            | 2020-02-22  | \n+-------------+--------------+--------------+-------------+\n```\n\n','examDataFiles/upload_6438b3862666484781e9bc5505196afe.sql','2020-11-26 11:32:57','2021-04-12 10:35:12','movierelatedscenario.sql',11,5,0),(13,'fc05133a-9c8e-4199-be7d-9c863df1fa33','发票相关情景','发票相关场景\n\n\n\n顾客表：customers。customer_id 是这张表的主键。此表的每一行包含了某在线商店顾客的姓名和电子邮件。\n\n```\ncustomers table:\n+-------------+---------------+------------------------+\n| customer_id | customer_name | email                  |\n+-------------+---------------+------------------------+\n| 1           | Alice         | alice@smail.nju.edu.cn |\n| 2           | Alex          | bob@smail.nju.edu.cn   |\n| 13          | Bob           | john@smail.nju.edu.cn  |\n| 6           | John          | alex@smail.nju.edu.cn  |\n+-------------+---------------+------------------------+\n```\n\n\n\n联系方式表：contacts。(user_id, contact_email) 是这张表的主键。此表的每一行表示编号为 user_id 的顾客的某位联系人的姓名和电子邮件。此表包含每位顾客的联系人信息，但顾客的联系人不一定存在于顾客表中。\n\n```\ncontacts table:\n+-------------+--------------+------------------------+\n| user_id     | contact_name | contact_email          |\n+-------------+--------------+------------------------+\n| 1           | Jal          | jal@smail.nju.edu.cn   |\n| 2           | Omar         | omar@smail.nju.edu.cn  |\n| 2           | Meir         | meir@smail.nju.edu.cn  |\n| 6           | Alice        | alice@smail.nju.edu.cn |\n+-------------+--------------+------------------------+\n\n```\n\n\n\n发票表：invoices。invoice_id 是这张表的主键。此表的每一行分别表示编号为 user_id 的顾客拥有有一张编号为 invoice_id、价格为 price 的发票。\n\n```\ninvoices table:\n+------------+-------+---------+\n| invoice_id | price | user_id |\n+------------+-------+---------+\n| 77         | 100   | 1       |\n| 88         | 200   | 1       |\n| 99         | 300   | 2       |\n| 44         | 60    | 6       |\n+------------+-------+---------+\n```\n\n注意：小题中可能涉及到的一些字段解释：\ncustomer_name：与发票相关的顾客名称。\nprice：发票的价格。\ncontacts_cnt：该顾客的联系人数量。\ntrusted_contacts_cnt：可信联系人的数量：既是该顾客的联系人又是商店顾客的联系人数量（即：可信联系人的电子邮件存在于客户表中）。\n\n','examDataFiles/upload_4c5a71e0dfb67c98128d189502457a91.sql','2020-11-26 11:38:29','2021-04-12 10:56:02','invoicerelatedscenarios.sql',10,5,0),(14,'fc05133a-9c8e-4199-be7d-9c863df1fa33','锦标赛情景','训练赛情景：\n\nplayers 训练赛玩家表。玩家 ID 是此表的主键。此表的每一行表示每个玩家的组。注：每个组中可能既有男性又有女性。\n\n```\nplayers 表:\n+-----------+------------+------------+\n| player_id | player_name|  group_id  |\n+-----------+------------+------------+\n| 15        |   Joe      |      2     |\n| 25        |  Alice     |      1     |   \n| 30        |  Bajrang   |      1     |\n| 45        |  Khali     |      1     |\n| 10        |  Slaman    |      3     |\n| 35        |  Aron      |      2     |\n| 50        |  Priya     |      2     |\n| 20        |   Jose     |      3     |\n+-----------+------------+------------+\n\n```\n\n\n\nmatches 训练赛赛事表。match_id 是此表的主键。\n每一行是一场比赛的记录，第一名和第二名球员包含每场比赛的球员 ID。\n第一个玩家和第二个玩家的分数分别包含第一个玩家和第二个玩家的分数。\n你可以假设，在每一场比赛中，球员都属于同一组。\n\n```\nmatches 表:\n+------------+--------------+---------------+-------------+--------------+\n| match_id   | first_player | second_player | first_score | second_score |\n+------------+--------------+---------------+-------------+--------------+\n| 1          | 30           | 45            | 3           | 0            |\n| 2          | 50           | 15            | 1           | 2            |\n| 3          | 30           | 25            | 2           | 0            |\n| 4          | 35           | 15            | 1           | 1            |\n+------------+--------------+---------------+-------------+--------------+\n```\n\n\n\n表: scores。(gender, day)是该表的主键。该表独立于Matches表。是另一场模拟训练赛的比赛分数。\n该表的每一行表示一个名叫 (player_name) 性别为 (gender) 的参赛者在某一天获得了 (score_points) 的分数\n如果参赛者是女性，那么 gender 列为 \'F\'，如果参赛者是男性，那么 gender 列为 \'M\'\n\n```\nscores表:\n+-------------+--------+------------+--------------+\n| player_name | gender | day        | score_points |\n+-------------+--------+------------+--------------+\n| Aron        | F      | 2020-01-01 | 17           |\n| Alice       | F      | 2020-01-07 | 23           |\n| Bajrang     | M      | 2020-01-07 | 7            |\n| Khali       | M      | 2019-12-25 | 11           |\n| Slaman      | M      | 2019-12-30 | 13           |\n| Joe         | M      | 2019-12-31 | 3            |\n| Jose        | M      | 2019-12-18 | 2            |\n| Priya       | F      | 2019-12-31 | 23           |\n+-------------+--------+------------+--------------+\n```\n\n','examDataFiles/upload_2cd196144f39eb1dbd5a8e70635bc764.sql','2020-11-26 11:55:08','2021-02-24 13:47:44','championshipscenario.sql',10,5,0),(15,'fc05133a-9c8e-4199-be7d-9c863df1fa33','商品订单情景','### 商品订单信息场景：\n\n\n\n表：customers。customer_id 是该表主键，该表包含消费者的信息。\n\n```html\n+-------------+-----------+\n| customer_id | name      |\n+-------------+-----------+\n| 1           | Marwan    |\n| 2           | John      |\n| 3           | Anna      |\n| 4           | Winston   |\n+-------------+-----------+\n\n```\n\n\n\n表：orders。order_id 是该表主键，该表包含id为customer_id的消费者的订单信息。\n\n每一个消费者 每天一笔订单，且没有顾客会在一天内订购相同的商品 **多于一次**。\n\n```html\norders\n+----------+------------+-------------+------------+\n| order_id | order_date | customer_id | product_id |  \n+----------+------------+-------------+------------+\n| 1        | 2020-07-31 | 1           | 1          |    \n| 2        | 2020-07-30 | 2           | 2          |    \n| 3        | 2020-08-29 | 3           | 3          |    \n| 4        | 2020-07-29 | 4           | 1          |    \n| 5        | 2020-06-10 | 1           | 2          |    \n| 6        | 2020-08-01 | 2           | 1          |      \n+----------+------------+-------------+------------+\n\n```\n\n\n\n\n\n表: products。product_id 是该表主键，该表包含所有商品的信息。\n\n```HTML\nproducts\n+------------+--------------+-------+\n| product_id | product_name | price |\n+------------+--------------+-------+\n| 1          | keyboard     | 600   |\n| 2          |  screen      | 800   |\n| 3          |  mouse       | 200   |\n| 4          | hard disk    | 450   |\n+------------+--------------+-------+\n```\n\n\n\n','examDataFiles/upload_6a7c4b7de2e8748e1c97dccc5da63ab5.sql','2020-11-26 14:13:33','2021-04-10 12:03:32','commodityorderscenario.sql',11,5,0),(16,'fc05133a-9c8e-4199-be7d-9c863df1fa33','图书借阅情景','图书借阅情景：\n\n表：books。存放图书相关信息。book_id是主键，代表图书号。sort是图书分类编号。output是出版社信息。\n\n```\n+------------+--------+--------------+----------+--------------+----------+\n|  book_id   | sort   |  book_name   |  writer  | output       |  price   |\n+------------+--------+--------------+----------+--------------+----------+\n| 112266     | TP3/12 |   FoxBase    | 李三      | 电子工业出版社 |  23.600  |\n| 113388     | TR7/90 |   大学英语    | 胡玲      | 清华大学出版社 |  12.500  |\n| 114455     | TR9/12 |   线性代数    | 孙业      | 北京大学出版社 |  20.800  |\n| 118801     | TP4/15 |   计算机网络  | 黄力钧     | 高等教育出版社 |  21.800  |\n| 118802     | TP4/15 |   计算机网络  | 黄力钧     | 高等教育出版社 |  21.800  |\n| 332211     | TP5/10 |   计算机基础  | 李伟       | 高等教育出版社 |  18.000  |\n| 445501     | TP3/12 |   数据库导论  | 王强       | 科学出版社    |  17.900  |\n| 445502     | TP3/12 |   数据库导论  | 王强       | 科学出版社    |  17.900  |\n| 445503     | TP3/12 |   数据库导论  | 王强       | 科学出版社    |  17.900  |\n| 446601     | TP4/13 |   数据库基础  | 马凌云     | 人民邮电出版社 |  22.500  |\n| 665544     | TS7/21 |   高等数学    | 刘明      | 高等教育出版社  | 20.000  |\n+------------+--------+------ -------+----------+---------------+---------+\n\n```\n\n\n\n\n表：readers。reader_id是主键。存放读者信息。其中company是读者的系，grade是读职称，addr是读者地址。\n\n```\n+------------+--------------+---------------+------+----------+----------+\n| reader_id  | company      | name          | sex  |  grade   |  addr    |\n+------------+--------------+---------------+-------------+--------------+\n| 111        | 信息系        | 赵正义         |  女    |   教授   | 1号楼424 |\n| 112        | 财会系        | 李丽           |  女    |   副教授 | 2号楼316 |\n| 113        | 经济系        | 张三           |  男    |   讲师   | 3号楼105 |\n| 114        | 信息系        | 周华发         |  男    |   讲师   |1号楼316  |\n| 115        | 信息系        | 王小花         |  女    |   工程师 | 1号楼224 |\n| 116        | 信息系        | 李明           |  男    |   副教授 | 1号楼318 |\n| 117        | 计算机系      | 李小峰         |  男    |   助教   | 1号楼214 |\n| 118        | 计算机系      | 许鹏飞         |  男    |   助工   | 1号楼216 |\n| 119        | 计算机系      | 刘大龙         |  男    |   教授   | 1号楼318 |\n+------------+--------------+---------------+-------------+---------------+\n```\n\n\n\n表：borrows。存放借阅信息。（reader_id, book_id）是主键。\n\n```\n+----------+------------+-------------+\n|reader_id | book_id    | borrow_date |\n+----------+------------+-------------+\n| 111      | 445503     | 2006-08-21  |\n| 111      | 112266     | 2006-03-14  |\n| 112      | 445501     | 2006-03-09  |\n| 112      | 449901     | 2006-10-23  |\n| 112      | 665544     | 2006-10-21  |\n| 115      | 449902     | 2006-08-21  |\n| 118      | 118801     | 2006-09-10  |\n+----------+-------------+------------+\n```','examDataFiles/upload_5efadfb8a1fb320750c816839c41bcdf.sql','2020-11-26 14:23:50','2021-04-10 12:02:58','bookborrowingscenario.sql',9,5,0),(17,'fc05133a-9c8e-4199-be7d-9c863df1fa33','系统状态情景','系统状态情景：系统 **每天** 运行一个任务。每个任务都独立于先前的任务。任务的状态可以是失败或是成功。\n\n表: failed。该表主键为 fail_date。该表包含任务失败的日期.\n\n```\nfailed table:\n+-------------------+----------------+\n| fail_date         |  event_type    |\n+-------------------+----------------+\n| 2018-12-28        |   reviews      |\n| 2018-12-29        |   ads          |\n| 2019-01-04        |   ads          |\n| 2019-01-05        |   reviews      |\n+-------------------+----------------+\n```\n\n表: succeeded。该表主键为 success_date。该表包含任务成功的日期.\n\n```\nsucceeded table:\n+-------------------+---------------+\n| success_date      |   event_type   |\n+-------------------+---------------+\n| 2018-12-30        |   page views  |\n| 2018-12-31        |   page views  |\n| 2019-01-01        |   ads         |\n| 2019-01-02        |   ads         |\n| 2019-01-03        |   reviews     |\n| 2019-01-06        |   reviews     |\n+-------------------+---------------+\n\n```\n\n\n\n事件表：events。该表是一个独立于前两个表的表。此表的主键是 (business_id, event_type)。表中的每一行记录了某种类型的事件在某些业务中多次发生的信息。\n\n```\nevents table:\n+-------------+------------+------------+\n| business_id | event_type | occurences |\n+-------------+------------+------------+\n| 1           | page views | 7          |\n| 1           | reviews    | 3          |\n| 2           | ads        | 11         |\n| 2           | reviews    | 3          |\n| 3           | page views | 12         |\n+-------------+------------+------------+\n```\n\n注：和小题相关的一个解释：\n如果一个业务的某个事件类型的发生次数（字段occurences）大于此事件类型在所有业务中的平均发生次数，并且该业务至少有两个这样的事件类型，那么该业务就可被看做是活跃业务。\n\n','examDataFiles/upload_8694f32bd8609308b96ca63e10d89ac7.sql','2020-11-26 14:27:58','2021-04-14 00:38:37','systemstatescenario.sql',12,5,0),(18,'fc05133a-9c8e-4199-be7d-9c863df1fa33','学生选课情景','学生选课情景：\n\n\n\n学生表：students。s_id是主键。\n\n```\n+-------------+--------+------------+--------------+\n| s_id        | s_name |  s_birthday| s_sex        |\n+-------------+--------+------------+--------------+\n| 1           | 赵雷    | 1990-01-01 | 男           |\n| 2           | 钱电    | 1990-12-21 | 男           |\n| 3           | 孙风    | 1990-05-20 | 男           |\n| 4           | 李云    | 1990-08-06 | 男           |\n| 5           | 周梅    | 1991-12-01 | 女           |\n| 6           | 吴兰    | 1992-03-01 | 女           |\n+-------------+--------+------------+--------------+\n\n```\n\n\n\n课程表：courses.。c_id是主键。\n\n```\n+--------+------------+---------+\n| c_id   |  c_name    |   t_id  |\n+--------+------------+---------+\n| 1      | 英语        |    2    |\n| 2      | 数学        |    1    |\n| 3      | 语文        |    3    |\n+--------+-------------+--------+\n```\n\n\n\n教师表：teachers。t_id是主键。\n\n```\n+--------+------------+\n| t_id   |  t_name    | \n+--------+------------+\n| 1      | 张三        | \n| 2      | 李四        | \n| 3      | 王五        | \n+--------+------------+\n```\n\n\n\n\n\n成绩表scores。（s_id, c_id）是主键。\n\n```\n+--------+------------+---------+\n|  s_id  |   c_id     | s_score |\n+--------+------------+---------+\n| 1      | 1          | 80      |\n| 1      | 2          | 90      |\n| 1      | 3          | 99      |\n| 2      | 1          | 70      |\n| 2      | 3          | 60      |\n| 3      | 2          | 80      |\n| 3      | 3          | 80      |\n| 4      | 1          | 50      |\n| 4      | 2          | 30      |\n| 4      | 3          | 20      |\n| 5      | 1          | 76      |\n| 6      | 1          | 31      |\n| 6      | 3          | 34      |\n+--------+------------+---------+\n```\n\n','examDataFiles/upload_847104b940b08871137eeaeccd5bba73.sql','2020-11-26 14:41:59','2021-04-14 11:16:16','studentsandcoursesscenario.sql',11,5,0),(19,'fc05133a-9c8e-4199-be7d-9c863df1fa33','公司部门职员情景','`employee` 表包含所有员工信息，每个员工有其对应的工号 `Id`，姓名 `Name`，工资 `Salary` 和部门编号 `DepartmentId` 。他们的经理也属于员工。每个员工还有一列对应员工的经理的 Id。\n\nemployee：\n\n```HTML\n+----+-------+--------+--------------+-------------+\n| Id | Name  | Salary | DepartmentId |  ManagerId  |\n+----+-------+--------+--------------+-------------+\n| 1  | Joe   | 84000  | 1            |    4        |  \n| 2  | Henry | 80000  | 2            |    8        |   \n| 3  | Sam   | 60000  | 2            |    8        |\n| 4  | Max   | 120000 | 1            |    null     |\n| 5  | Janet | 69000  | 2            |    8        |\n| 6  | Randy | 85000  | 1            |    4        |\n| 7  | Will  | 70000  | 1            |    4        |\n| 8  | Jim   | 131000 | 2            |    null     |\n+----+-------+--------+--------------+-------------+\n\n\n```\n\n\n\n`department` 表包含公司所有部门的信息。\n\n```html\n+----+----------+\n| Id | Name     |\n+----+----------+\n| 1  | IT       |\n| 2  | Sales    |\n+----+----------+\n\n```\n\n','examDataFiles/upload_52a983a01f9fd601031afb0f8db3ae76.sql','2020-11-26 15:01:37','2021-04-10 12:01:42','employeesalary.sql',8,4,0),(20,'fc05133a-9c8e-4199-be7d-9c863df1fa33','薪资等级情景','表：dept。deptno是主键，dname是部门名称，loc是部门地址。\n\n```\n+--------+------------+---------+\n| deptno |  dname     |  loc    |\n+--------+------------+---------+\n| 10     | Accounting | new york|\n| 20     | Research   | dallas  |\n| 30     | Sales      | chicago |\n| 40     | Operations | boston  |\n+--------+-------------+--------+\n```\n\n\n\n表：emp。job是员工工作，mgr是员工直属领导编号，可以为空。hiredate员工入职时间。sal是员工月薪工资，comm是奖金。\n\n```\n+----------+--------------+---------------+-------+-------------+-------+-----+---------+\n| empno    | ename        | job           | mgr   | hiredate    | sal   | comm | deptno |\n+----------+--------------+---------------+-------+-------------+-------+------+--------+\n| 7369     | smith        | CLERK         | 7902  | 1980-12-17  | 800   | NULL | 20     |\n| 7566     | jones        | manager       | 7839  | 1981-04-02  | 2975  | NULL | 20     |\n| 7654     | martin       | salesman      | 7698  | 1981-09-28  | 1250  | 1400 | 30     |\n| 7698     | blake        | manager       | 7839  | 1981-05-01  | 2850  | NULL | 30     |\n| 7782     | clark        | manager       | 7839  | 1981-06-09  | 2450  | NULL | 10     |\n| 7839     | king         | president     | null  | 1981-11-17  | 5000  | 2000 | 10     |\n| 7844     | turner       | salesman      | 7698  | 1981-09-08  | 1500  | 800  | 30     |\n| 7900     | james        | CLERK         | 7698  | 1981-12-03  | 950   | NULL | 30     |\n| 7902     | ford         | analyst       | 7566  | 1981-12-03  | 3000  | NULL | 20     |\n| 7934     | miller       | CLERK         | 7782  | 1981-01-23  | 1300  | NULL | 10     |\n+----------+--------------+---------------+-------+-------------+-------+------+--------+\n```\n\n\n\n表：salGrade。 grade是等级，losal是最低工资，hisal是最高工资 。\n\n```\n+--------+------------+---------+\n| grade  |  losal     |  hisal  |\n+--------+------------+---------+\n| 1      |  700       |  1000   |\n| 2      |  1001      |  1400   |\n| 3      |  1401      |  2000   |\n| 4      |  2001      |  4000   |\n| 5      |  4001      |  9999   |\n+--------+-------------+--------+\n```\n\n','examDataFiles/upload_43e10a0317b933f8dcf733086108c315.sql','2020-11-26 15:24:33','2021-04-13 22:12:56','salarylevelscenario.sql',9,5,0),(125,'cc305c61-59db-4153-ae68-f79c41188a14','Tom 和 Jerry 的存款','有如下表：\n\n`blank_data`表：\n\n``` \n+----+-------+--------+\n| id | name  | amount |\n+----+-------+--------+\n| 1  | Tom   | ?      |\n| 2  | Jerry | ?      |\n+----+-------+--------+\n```\n\n`address_data`表：\n\n```\n+-------+---------+\n| name  | address |\n+-------+--------+\n| Tom   | ?       |\n| Jerry | ?       |\n+-------+---------+\n```','examDataFiles/upload_c6f362fb0a5733a6aa292736ab8cb34a.sql','2020-11-16 07:15:24','2020-12-29 15:49:16','sqlexamexec.sql',2,2,0),(175,'0','组合两个表','表1: Person\n\n```\n+-------------+---------+\n| 列名         | 类型     |\n+-------------+---------+\n| PersonId    | int     |\n| FirstName   | varchar |\n| LastName    | varchar |\n+-------------+---------+\n```\n\nPersonId 是上表主键\n\n表2: Address\n\n```\n+-------------+---------+\n| 列名         | 类型    |\n+-------------+---------+\n| AddressId   | int     |\n| PersonId    | int     |\n| City        | varchar |\n| State       | varchar |\n+-------------+---------+\n```\n\nAddressId 是上表主键\n\n\n','examDataFiles/auto_upload_175_1637126775641.sql','2021-11-17 13:26:15','2021-11-30 20:41:48','auto_upload_175_1637126775641.sql',1,1,0),(176,'0','第二高的薪水','Employee表\n\n```\n+----+--------+\n| Id | Salary |\n+----+--------+\n| 1  | 100    |\n| 2  | 200    |\n| 3  | 300    |\n+----+--------+\n```\n\n例如上述Employee表，SQL查询应该返回200 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 null。\n\n```\n+---------------------+\n| SecondHighestSalary |\n+---------------------+\n| 200                 |\n+---------------------+\n```\n\n','examDataFiles/auto_upload_176_1637126775641.sql','2021-11-17 13:26:15','2021-11-30 21:05:13','auto_upload_176_1637126775641.sql',2,1,0),(177,'0','第N高的薪水','编写一个 SQL 查询，获取 Employee 表中第n高的薪水（Salary）。\n\n```\n+----+--------+\n| Id | Salary |\n+----+--------+\n| 1  | 100    |\n| 2  | 200    |\n| 3  | 300    |\n+----+--------+\n```\n\n例如上述Employee表，n = 2时，应返回第二高的薪水200。如果不存在第n高的薪水，那么查询应返回null。\n\n```\n+------------------------+\n| getNthHighestSalary(2) |\n+------------------------+\n| 200                    |\n+------------------------+\n```\n\n','examDataFiles/auto_upload_177_1637126775641.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_177_1637126775641.sql',2,1,0),(178,'0','分数排名','编写一个 SQL 查询来实现分数排名。\n\n如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。\n\n```\n+----+-------+\n| Id | Score |\n+----+-------+\n| 1  | 3.50  |\n| 2  | 3.65  |\n| 3  | 4.00  |\n| 4  | 3.85  |\n| 5  | 4.00  |\n| 6  | 3.65  |\n+----+-------+\n```\n\n例如，根据上述给定的Scores 表，你的查询应该返回（按分数从高到低排列）：\n\n```\n+-------+------+\n| Score | Rank |\n+-------+------+\n| 4.00  | 1    |\n| 4.00  | 1    |\n| 3.85  | 2    |\n|3.65  | 3    |\n| 3.65  | 3    |\n| 3.50  | 4    |\n+-------+------+\n```\n\n重要提示：对于 MySQL 解决方案，如果要转义用作列名的保留字，可以在关键字之前和之后使用撇号。例如 `Rank`\n\n','examDataFiles/auto_upload_178_1637126775641.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_178_1637126775641.sql',2,1,0),(180,'0','连续出现的数字','表：Logs\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| id          | int     |\n| num         | varchar |\n+-------------+---------+\n```\n\nid 是这个表的主键。\n\n编写一个 SQL 查询，查找所有至少连续出现三次的数字。\n\n返回的结果表中的数据可以按 任意顺序 排列。\n\n查询结果格式如下面的例子所示：\n\nLogs 表：\n\n```\n+----+-----+\n| Id | Num |\n+----+-----+\n| 1  | 1   |\n| 2  | 1   |\n| 3  | 1   |\n| 4  | 2   |\n| 5  | 1   |\n| 6  | 2   |\n| 7  | 2   |\n+----+-----+\n```\n\nResult 表：\n\n```\n+-----------------+\n| ConsecutiveNums |\n+-----------------+\n| 1               |\n+-----------------+\n```\n\n1 是唯一连续出现至少三次的数字。\n\n','examDataFiles/auto_upload_180_1637126775641.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_180_1637126775641.sql',2,1,0),(181,'0','超过经理收入的员工','Employee表包含所有员工，他们的经理也属于员工。每个员工都有一个 Id，此外还有一列对应员工的经理的 Id。\n\n```\n+----+-------+--------+-----------+\n| Id | Name  | Salary | ManagerId |\n+----+-------+--------+-----------+\n| 1  | Joe   | 70000  | 3         |\n| 2  | Henry | 80000  | 4         |\n| 3  | Sam   | 60000  | NULL      |\n| 4  | Max   | 90000  | NULL      |\n+----+-------+--------+-----------+\n```\n\n给定Employee表，编写一个 SQL 查询，该查询可以获取收入超过他们经理的员工的姓名。在上面的表格中，Joe 是唯一一个收入超过他的经理的员工。\n\n```\n+----------+\n| Employee |\n+----------+\n| Joe      |\n+----------+\n```\n\n','examDataFiles/auto_upload_181_1637126775641.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_181_1637126775641.sql',1,1,0),(182,'0','查找重复的电子邮箱','编写一个 SQL 查询，查找Person 表中所有重复的电子邮箱。\n\n示例：\n\n```\n+----+---------+\n| Id | Email   |\n+----+---------+\n| 1  | a@b.com |\n| 2  | c@d.com |\n| 3  | a@b.com |\n+----+---------+\n```\n\n根据以上输入，你的查询应返回以下结果：\n\n```\n+---------+\n| Email   |\n+---------+\n| a@b.com |\n+---------+\n```\n\n说明：所有电子邮箱都是小写字母。\n\n','examDataFiles/auto_upload_182_1637126775641.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_182_1637126775641.sql',1,1,0),(183,'0','从不订购的客户','某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。\n\nCustomers 表：\n\n```\n+----+-------+\n| Id | Name  |\n+----+-------+\n| 1  | Joe   |\n| 2  | Henry |\n| 3  | Sam   |\n| 4  | Max   |\n+----+-------+\n```\n\nOrders 表：\n\n```\n+----+------------+\n| Id | CustomerId |\n+----+------------+\n| 1  | 3          |\n| 2  | 1          |\n+----+------------+\n```\n\n例如给定上述表格，你的查询应返回：\n\n```\n+-----------+\n| Customers |\n+-----------+\n| Henry     |\n| Max       |\n+-----------+\n```\n\n','examDataFiles/auto_upload_183_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_183_1637126775642.sql',1,1,0),(184,'0','部门工资最高的员工','Employee 表包含所有员工信息，每个员工有其对应的Id, salary 和 department Id。\n\n```\n+----+-------+--------+--------------+\n| Id | Name  | Salary | DepartmentId |\n+----+-------+--------+--------------+\n| 1  | Joe   | 70000  | 1            |\n| 2 | Jim  | 90000 | 1      |\n| 3  | Henry | 80000  | 2            |\n| 4  | Sam   | 60000  | 2            |\n| 5  | Max   | 90000  | 1            |\n+----+-------+--------+--------------+\n```\n\nDepartment表包含公司所有部门的信息。\n\n```\n+----+----------+\n| Id | Name     |\n+----+----------+\n| 1  | IT       |\n| 2  | Sales    |\n+----+----------+\n```\n\n编写一个 SQL 查询，找出每个部门工资最高的员工。对于上述表，您的 SQL 查询应返回以下行（行的顺序无关紧要）。\n\n```\n+------------+----------+--------+\n| Department | Employee | Salary |\n+------------+----------+--------+\n| IT         | Max      | 90000  |\n| IT     | Jim   | 90000 |\n| Sales      | Henry    | 80000  |\n+------------+----------+--------+\n```\n\n解释：\n\nMax 和 Jim 在 IT 部门的工资都是最高的，Henry 在销售部的工资最高。\n\n','examDataFiles/auto_upload_184_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_184_1637126775642.sql',2,1,0),(185,'0','部门工资前三高的所有员工','Employee 表包含所有员工信息，每个员工有其对应的工号Id，姓名 Name，工资 Salary 和部门编号 DepartmentId 。\n\n```\n+----+-------+--------+--------------+\n| Id | Name  | Salary | DepartmentId |\n+----+-------+--------+--------------+\n| 1  | Joe   | 85000  | 1            |\n| 2  | Henry | 80000  | 2            |\n| 3  | Sam   | 60000  | 2            |\n| 4  | Max   | 90000  | 1            |\n| 5  | Janet | 69000  | 1            |\n| 6  | Randy | 85000  | 1            |\n| 7  | Will  | 70000  | 1            |\n+----+-------+--------+--------------+\n```\n\nDepartment 表包含公司所有部门的信息。\n\n```\n+----+----------+\n| Id | Name     |\n+----+----------+\n| 1  | IT       |\n| 2  | Sales    |\n+----+----------+\n```\n\n编写一个SQL 查询，找出每个部门获得前三高工资的所有员工。例如，根据上述给定的表，查询结果应返回：\n\n```\n+------------+----------+--------+\n| Department | Employee | Salary |\n+------------+----------+--------+\n| IT         | Max      | 90000  |\n| IT         | Randy    | 85000  |\n| IT         | Joe      | 85000  |\n| IT         | Will     | 70000  |\n| Sales      | Henry    | 80000  |\n| Sales      | Sam      | 60000  |\n+------------+----------+--------+\n```\n\n解释：\n\nIT 部门中，Max 获得了最高的工资，Randy 和 Joe 都拿到了第二高的工资，Will 的工资排第三。销售部门（Sales）只有两名员工，Henry 的工资最高，Sam 的工资排第二。\n\n','examDataFiles/auto_upload_185_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_185_1637126775642.sql',3,1,0),(196,'0','删除重复的电子邮箱','编写一个 SQL 查询，来删除Person表中所有重复的电子邮箱，重复的邮箱里只保留Id最小的那个。\n\n```\n+----+------------------+\n| Id | Email            |\n+----+------------------+\n| 1  | john@example.com |\n| 2  | bob@example.com  |\n| 3  | john@example.com |\n+----+------------------+\n```\n\nId 是这个表的主键。\n\n例如，在运行你的查询语句之后，上面的 Person 表应返回以下几行:\n\n```\n+----+------------------+\n| Id | Email            |\n+----+------------------+\n| 1  | john@example.com |\n| 2  | bob@example.com  |\n+----+------------------+\n```\n\n提示：\n\n执行 SQL 之后，输出是整个 Person表。\n\n使用 delete 语句。\n\n','examDataFiles/auto_upload_196_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_196_1637126775642.sql',1,1,0),(197,'0','上升的温度','表 Weather\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| recordDate    | date    |\n| temperature   | int     |\n+---------------+---------+\n```\n\nid 是这个表的主键\n\n该表包含特定日期的温度信息\n\n编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 id 。\n\n返回结果 不要求顺序 。\n\n查询结果格式如下例：\n\nWeather\n\n```\n+----+------------+-------------+\n| id | recordDate | Temperature |\n+----+------------+-------------+\n| 1  | 2015-01-01 | 10          |\n| 2  | 2015-01-02 | 25          |\n| 3  | 2015-01-03 | 20          |\n| 4  | 2015-01-04 | 30          |\n+----+------------+-------------+\n```\n\nResult table:\n\n```\n+----+\n| id |\n+----+\n| 2  |\n| 4  |\n+----+\n```\n\n2015-01-02 的温度比前一天高（10 -> 25）\n\n2015-01-04 的温度比前一天高（20 -> 30）\n\n','examDataFiles/auto_upload_197_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_197_1637126775642.sql',1,1,0),(262,'0','行程和用户','表：Trips\n\n```\n+-------------+----------+\n| Column Name | Type     |\n+-------------+----------+\n| Id          | int      |\n| Client_Id   | int      |\n| Driver_Id   | int      |\n| City_Id     | int      |\n| Status      | enum     |\n| Request_at  | date     |     \n+-------------+----------+\n```\n\nId 是这张表的主键。\n\n这张表中存所有出租车的行程信息。每段行程有唯一 Id ，其中 Client_Id 和 Driver_Id 是 Users 表中 Users_Id 的外键。\n\nStatus 是一个表示行程状态的枚举类型，枚举成员为(‘completed’, ‘cancelled_by_driver’, ‘cancelled_by_client’) 。\n\n表：Users\n\n```\n+-------------+----------+\n| Column Name | Type     |\n+-------------+----------+\n| Users_Id    | int      |\n| Banned      | enum     |\n| Role        | enum     |\n+-------------+----------+\n```\n\nUsers_Id 是这张表的主键。\n\n这张表中存所有用户，每个用户都有一个唯一的 Users_Id ，Role 是一个表示用户身份的枚举类型，枚举成员为 (‘client’, ‘driver’, ‘partner’) 。\n\nBanned 是一个表示用户是否被禁止的枚举类型，枚举成员为 (‘Yes’, ‘No’) 。\n\n写一段 SQL 语句查出\"2013-10-01\"至\"2013-10-03\"期间非禁止用户（乘客和司机都必须未被禁止）的取消率。非禁止用户即 Banned 为 No 的用户，禁止用户即 Banned 为 Yes 的用户。\n\n取消率 的计算方式如下：(被司机或乘客取消的非禁止用户生成的订单数量) / (非禁止用户生成的订单总数)。\n\n返回结果表中的数据可以按任意顺序组织。其中取消率 Cancellation Rate 需要四舍五入保留 两位小数 。\n\n查询结果格式如下例所示：\n\nTrips 表：\n\n```\n+----+-----------+-----------+---------+---------------------+------------+\n| Id | Client_Id | Driver_Id | City_Id | Status              | Request_at |\n+----+-----------+-----------+---------+---------------------+------------+\n| 1  | 1         | 10        | 1       | completed           | 2013-10-01 |\n| 2  | 2         | 11        | 1       | cancelled_by_driver | 2013-10-01 |\n| 3  | 3         | 12        | 6       | completed           | 2013-10-01 |\n| 4  | 4         | 13        | 6       | cancelled_by_client | 2013-10-01 |\n| 5  | 1         | 10        | 1       | completed           | 2013-10-02 |\n| 6  | 2         | 11        | 6       | completed           | 2013-10-02 |\n| 7  | 3         | 12        | 6       | completed           | 2013-10-02 |\n| 8  | 2         | 12        | 12      | completed           | 2013-10-03 |\n| 9  | 3         | 10        | 12      | completed           | 2013-10-03 |\n| 10 | 4         | 13        | 12      | cancelled_by_driver | 2013-10-03 |\n+----+-----------+-----------+---------+---------------------+------------+\n```\n\nUsers 表：\n\n```\n+----------+--------+--------+\n| Users_Id | Banned | Role   |\n+----------+--------+--------+\n| 1        | No     | client |\n| 2        | Yes    | client |\n| 3        | No     | client |\n| 4        | No     | client |\n| 10       | No     | driver |\n| 11       | No     | driver |\n| 12       | No     | driver |\n| 13       | No     | driver |\n+----------+--------+--------+\n```\n\nResult 表：\n\n```\n+------------+-------------------+\n| Day        | Cancellation Rate |\n+------------+-------------------+\n| 2013-10-01 | 0.33              |\n| 2013-10-02 | 0.00              |\n| 2013-10-03 | 0.50              |\n+------------+-------------------+\n```\n\n2013-10-01：\n\n  - 共有 4 条请求，其中 2 条取消。\n\n  - 然而，Id=2 的请求是由禁止用户（User_Id=2）发出的，所以计算时应当忽略它。\n\n  - 因此，总共有 3 条非禁止请求参与计算，其中 1 条取消。\n\n  - 取消率为 (1 / 3) = 0.33\n\n2013-10-02：\n\n  - 共有 3 条请求，其中 0 条取消。\n\n  - 然而，Id=6 的请求是由禁止用户发出的，所以计算时应当忽略它。\n\n  - 因此，总共有 2 条非禁止请求参与计算，其中 0 条取消。\n\n  - 取消率为 (0 / 2) = 0.00\n\n2013-10-03：\n\n  - 共有 3 条请求，其中 1 条取消。\n\n  - 然而，Id=8 的请求是由禁止用户发出的，所以计算时应当忽略它。\n\n  - 因此，总共有 2 条非禁止请求参与计算，其中 1 条取消。\n\n  - 取消率为 (1 / 2) = 0.50\n\n','examDataFiles/auto_upload_262_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_262_1637126775642.sql',3,1,0),(569,'0','员工薪水中位数','Employee 表包含所有员工。Employee 表有三列：员工Id，公司名和薪水。\n\n```\n+-----+------------+--------+\n|Id   | Company    | Salary |\n+-----+------------+--------+\n|1    | A          | 2341   |\n|2    | A          | 341    |\n|3    | A          | 15     |\n|4    | A          | 15314  |\n|5    | A          | 451    |\n|6    | A          | 513    |\n|7    | B          | 15     |\n|8    | B          | 13     |\n|9    | B          | 1154   |\n|10   | B          | 1345   |\n|11   | B          | 1221   |\n|12   | B          | 234    |\n|13   | C          | 2345   |\n|14   | C          | 2645   |\n|15   | C          | 2645   |\n|16   | C          | 2652   |\n|17   | C          | 65     |\n+-----+------------+--------+\n```\n\n请编写SQL查询来查找每个公司的薪水中位数。挑战点：你是否可以在不使用任何内置的SQL函数的情况下解决此问题。\n\n```\n+-----+------------+--------+\n|Id   | Company    | Salary |\n+-----+------------+--------+\n|5    | A          | 451    |\n|6    | A          | 513    |\n|12   | B          | 234    |\n|9    | B          | 1154   |\n|14   | C          | 2645   |\n+-----+------------+--------+\n```\n\n','examDataFiles/auto_upload_569_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_569_1637126775642.sql',3,1,0),(570,'0','至少有5名直接下属的经理','Employee 表包含所有员工和他们的经理。每个员工都有一个 Id，并且还有一列是经理的 Id。\n\n```\n+------+----------+-----------+----------+\n|Id    |Name 	  |Department |ManagerId |\n+------+----------+-----------+----------+\n|101   |John 	  |A 	      |null      |\n|102   |Dan 	  |A 	      |101       |\n|103   |James 	  |A 	      |101       |\n|104   |Amy 	  |A 	      |101       |\n|105   |Anne 	  |A 	      |101       |\n|106   |Ron 	  |B 	      |101       |\n+------+----------+-----------+----------+\n```\n\n给定 Employee 表，请编写一个SQL查询来查找至少有5名直接下属的经理。对于上表，您的SQL查询应该返回：\n\n```\n+-------+\n| Name  |\n+-------+\n| John  |\n+-------+\n```\n\n注意:\n\n没有人是自己的下属。\n\n','examDataFiles/auto_upload_570_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_570_1637126775642.sql',2,1,0),(571,'0','给定数字的频率查询中位数','Numbers 表保存数字的值及其频率。\n\n```\n+----------+-------------+\n|  Number  |  Frequency  |\n+----------+-------------|\n|  0       |  7          |\n|  1       |  1          |\n|  2       |  3          |\n|  3       |  1          |\n+----------+-------------+\n```\n\n在此表中，数字为 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 3，所以中位数是 (0 + 0) / 2 = 0。\n\n```\n+--------+\n| median |\n+--------|\n| 0.0000 |\n+--------+\n```\n\n请编写一个查询来查找所有数字的中位数并将结果命名为 median 。\n\n','examDataFiles/auto_upload_571_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_571_1637126775642.sql',3,1,0),(574,'0','当选者','表: Candidate\n\n```\n+-----+---------+\n| id  | Name    |\n+-----+---------+\n| 1   | A       |\n| 2   | B       |\n| 3   | C       |\n| 4   | D       |\n| 5   | E       |\n+-----+---------+  \n```\n\n表: Vote\n\n```\n+-----+--------------+\n| id  | CandidateId  |\n+-----+--------------+\n| 1   |     2        |\n| 2   |     4        |\n| 3   |     3        |\n| 4   |     2        |\n| 5   |     5        |\n+-----+--------------+\n```\n\nid 是自动递增的主键，\n\nCandidateId 是 Candidate 表中的 id.\n\n请编写 sql 语句来找到当选者的名字，上面的例子将返回当选者 B.\n\n```\n+------+\n| Name |\n+------+\n| B    |\n+------+\n```\n\n注意:\n\n你可以假设没有平局，换言之，最多只有一位当选者。\n\n','examDataFiles/auto_upload_574_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_574_1637126775642.sql',2,1,0),(577,'0','员工奖金','选出所有 bonus < 1000 的员工的 name 及其 bonus。\n\nEmployee 表单\n\n```\n+-------+--------+-----------+--------+\n| empId |  name  | supervisor| salary |\n+-------+--------+-----------+--------+\n|   1   | John   |  3        | 1000   |\n|   2   | Dan    |  3        | 2000   |\n|   3   | Brad   |  null     | 4000   |\n|   4   | Thomas |  3        | 4000   |\n+-------+--------+-----------+--------+\n```\n\nempId 是这张表单的主关键字\n\nBonus 表单\n\n```\n+-------+-------+\n| empId | bonus |\n+-------+-------+\n| 2     | 500   |\n| 4     | 2000  |\n+-------+-------+\n```\n\nempId 是这张表单的主关键字\n\n输出示例：\n\n```\n+-------+-------+\n| name  | bonus |\n+-------+-------+\n| John  | null  |\n| Dan   | 500   |\n| Brad  | null  |\n+-------+-------+\n```\n\n','examDataFiles/auto_upload_577_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_577_1637126775642.sql',1,1,0),(578,'0','查询回答率最高的问题','从 survey_log 表中获得回答率最高的问题，survey_log 表包含这些列：id, action, question_id, answer_id, q_num, timestamp。\n\nid 表示用户 id；action 有以下几种值：\"show\"，\"answer\"，\"skip\"；当 action 值为 \"answer\" 时 answer_id 非空，而 action 值为 \"show\" 或者 \"skip\" 时 answer_id 为空；q_num 表示当前会话中问题的编号。\n\n请编写 SQL 查询来找到具有最高回答率的问题。\n\n示例：\n\n输入：\n\n```\n+------+-----------+--------------+------------+-----------+------------+\n| id   | action    | question_id  | answer_id  | q_num     | timestamp  |\n+------+-----------+--------------+------------+-----------+------------+\n| 5    | show      | 285          | null       | 1         | 123        |\n| 5    | answer    | 285          | 124124     | 1         | 124        |\n| 5    | show      | 369          | null       | 2         | 125        |\n| 5    | skip      | 369          | null       | 2         | 126        |\n+------+-----------+--------------+------------+-----------+------------+\n```\n\n输出：\n\n```\n+-------------+\n| survey_log  |\n+-------------+\n|    285      |\n+-------------+\n```\n\n解释：\n\n问题 285 的回答率为 1/1，而问题 369 回答率为 0/1，因此输出 285 。\n\n提示：回答率最高的含义是：同一问题编号中回答数占显示数的比例最高。\n\n','examDataFiles/auto_upload_578_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_578_1637126775642.sql',2,1,0),(579,'0','查询员工的累计薪水','Employee 表保存了一年内的薪水信息。\n\n请你编写 SQL 语句，对于每个员工，查询他除最近一个月（即最大月）之外，剩下每个月的近三个月的累计薪水（不足三个月也要计算）。\n\n结果请按 Id 升序，然后按 Month 降序显示。\n\n示例：\n\n输入：\n\n| Id | Month | Salary |\n\n|----|-------|--------|\n\n| 1  | 1     | 20     |\n\n| 2  | 1     | 20     |\n\n| 1  | 2     | 30     |\n\n| 2  | 2     | 30     |\n\n| 3  | 2     | 40     |\n\n| 1  | 3     | 40     |\n\n| 3  | 3     | 60     |\n\n| 1  | 4     | 60     |\n\n| 3  | 4     | 70     |\n\n输出：\n\n| Id | Month | Salary |\n\n|----|-------|--------|\n\n| 1  | 3     | 90     |\n\n| 1  | 2     | 50     |\n\n| 1  | 1     | 20     |\n\n| 2  | 1     | 20     |\n\n| 3  | 3     | 100    |\n\n| 3  | 2     | 40     |\n\n解释：\n\n员工 \'1\'除去最近一个月（月份 \'4\'），有三个月的薪水记录：月份 \'3\'薪水为40，月份 \'2\'薪水为 30，月份 \'1\'薪水为 20。\n\n所以近 3 个月的薪水累计分别为(40 + 30 + 20) =90，(30 + 20) = 50 和 20。\n\n| Id | Month | Salary |\n\n|----|-------|--------|\n\n| 1  | 3     | 90     |\n\n| 1  | 2     | 50     |\n\n| 1  | 1     | 20     |\n\n员工 \'2\' 除去最近的一个月（月份 \'2\'）的话，只有月份 \'1\' 这一个月的薪水记录。\n\n| Id | Month | Salary |\n\n|----|-------|--------|\n\n| 2  | 1     | 20     |\n\n员工 \'3\' 除去最近一个月（月份 \'4\'）后有两个月，分别为：月份 \'3\' 薪水为 60 和 月份 \'2\' 薪水为 40。所以各月的累计情况如下：\n\n| Id | Month | Salary |\n\n|----|-------|--------|\n\n| 3  | 3     | 100    |\n\n| 3  | 2     | 40     |\n\n','examDataFiles/auto_upload_579_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_579_1637126775642.sql',3,1,0),(580,'0','统计各专业学生人数','一所大学有 2 个数据表，分别是student和department，这两个表保存着每个专业的学生数据和院系数据。\n\n写一个查询语句，查询department表中每个专业的学生人数 （即使没有学生的专业也需列出）。\n\n将你的查询结果按照学生人数降序排列。 如果有两个或两个以上专业有相同的学生数目，将这些部门按照部门名字的字典序从小到大排列。\n\nstudent 表格如下：\n\n| Column Name  | Type      |\n\n|--------------|-----------|\n\n| student_id   | Integer   |\n\n| student_name | String    |\n\n| gender       | Character |\n\n| dept_id      | Integer   |\n\n其中， student_id 是学生的学号， student_name 是学生的姓名， gender 是学生的性别， dept_id 是学生所属专业的专业编号。\n\ndepartment 表格如下：\n\n| Column Name | Type    |\n\n|-------------|---------|\n\n| dept_id     | Integer |\n\n| dept_name   | String  |\n\ndept_id 是专业编号， dept_name 是专业名字。\n\n这里是一个示例输入：\n\nstudent表格：\n\n| student_id | student_name | gender | dept_id |\n\n|------------|--------------|--------|---------|\n\n| 1          | Jack         | M      | 1       |\n\n| 2          | Jane         | F      | 1       |\n\n| 3          | Mark         | M      | 2       |\n\ndepartment 表格：\n\n| dept_id | dept_name   |\n\n|---------|-------------|\n\n| 1       | Engineering |\n\n| 2       | Science     |\n\n| 3       | Law         |\n\n示例输出为：\n\n| dept_name   | student_number |\n\n|-------------|----------------|\n\n| Engineering | 2              |\n\n| Science     | 1              |\n\n| Law         | 0              |\n\n','examDataFiles/auto_upload_580_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_580_1637126775642.sql',2,1,0),(584,'0','寻找用户推荐人','给定表customer，里面保存了所有客户信息和他们的推荐人。\n\n```\n+------+------+-----------+\n| id   | name | referee_id|\n+------+------+-----------+\n|    1 | Will |      NULL |\n|    2 | Jane |      NULL |\n|    3 | Alex |         2 |\n|    4 | Bill |      NULL |\n|    5 | Zack |         1 |\n|    6 | Mark |         2 |\n+------+------+-----------+\n```\n\n写一个查询语句，返回一个客户列表，列表中客户的推荐人的编号都不是 2。\n\n对于上面的示例数据，结果为：\n\n```\n+------+\n| name |\n+------+\n| Will |\n| Jane |\n| Bill |\n| Zack |\n+------+\n```\n\n','examDataFiles/auto_upload_584_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_584_1637126775642.sql',1,1,0),(585,'0','2016年的投资','写一个查询语句，将2016 年 (TIV_2016) 所有成功投资的金额加起来，保留 2 位小数。\n\n对于一个投保人，他在 2016 年成功投资的条件是：\n\n他在 2015 年的投保额(TIV_2015) 至少跟一个其他投保人在 2015 年的投保额相同。\n\n他所在的城市必须与其他投保人都不同（也就是说维度和经度不能跟其他任何一个投保人完全相同）。\n\n输入格式:\n\n表insurance 格式如下：\n\n| Column Name | Type          |\n\n|-------------|---------------|\n\n| PID         | INTEGER(11)   |\n\n| TIV_2015    | NUMERIC(15,2) |\n\n| TIV_2016    | NUMERIC(15,2) |\n\n| LAT         | NUMERIC(5,2)  |\n\n| LON         | NUMERIC(5,2)  |\n\nPID字段是投保人的投保编号，TIV_2015 是该投保人在2015年的总投保金额，TIV_2016 是该投保人在2016年的投保金额，LAT 是投保人所在城市的维度，LON是投保人所在城市的经度。\n\n样例输入\n\n| PID | TIV_2015 | TIV_2016 | LAT | LON |\n\n|-----|----------|----------|-----|-----|\n\n| 1   | 10       | 5        | 10  | 10  |\n\n| 2   | 20       | 20       | 20  | 20  |\n\n| 3   | 10       | 30       | 20  | 20  |\n\n| 4   | 10       | 40       | 40  | 40  |\n\n样例输出\n\n| TIV_2016 |\n\n|----------|\n\n| 45.00    |\n\n解释\n\n就如最后一个投保人，第一个投保人同时满足两个条件：\n\n1. 他在 2015 年的投保金额 TIV_2015 为 \'10\' ，与第三个和第四个投保人在 2015 年的投保金额相同。\n\n2. 他所在城市的经纬度是独一无二的。\n\n第二个投保人两个条件都不满足。他在 2015 年的投资 TIV_2015 与其他任何投保人都不相同。\n\n且他所在城市的经纬度与第三个投保人相同。基于同样的原因，第三个投保人投资失败。\n\n所以返回的结果是第一个投保人和最后一个投保人的 TIV_2016 之和，结果是 45 。\n\n','examDataFiles/auto_upload_585_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_585_1637126775642.sql',2,1,0),(586,'0','订单最多的客户','在表orders中找到订单数最多客户对应的customer_number。\n\n数据保证订单数最多的顾客恰好只有一位。\n\n表orders 定义如下：\n\n| Column            | Type      |\n\n|-------------------|-----------|\n\n| order_number (PK) | int       |\n\n| customer_number   | int       |\n\n| order_date        | date      |\n\n| required_date     | date      |\n\n| shipped_date      | date      |\n\n| status            | char(15)  |\n\n| comment           | char(200) |\n\n样例输入\n\n| order_number | customer_number | order_date | required_date | shipped_date | status | comment |\n\n|--------------|-----------------|------------|---------------|--------------|--------|---------|\n\n| 1            | 1               | 2017-04-09 | 2017-04-13    | 2017-04-12   | Closed |         |\n\n| 2            | 2               | 2017-04-15 | 2017-04-20    | 2017-04-18   | Closed |         |\n\n| 3            | 3               | 2017-04-16 | 2017-04-25    | 2017-04-20   | Closed |         |\n\n| 4            | 3               | 2017-04-18 | 2017-04-28    | 2017-04-25   | Closed |         |\n\n样例输出\n\n| customer_number |\n\n|-----------------|\n\n| 3               |\n\n解释\n\ncustomer_number 为 \'3\' 的顾客有两个订单，比顾客 \'1\' 或者 \'2\' 都要多，因为他们只有一个订单\n\n所以结果是该顾客的 customer_number ，也就是 3 。\n\n进阶： 如果有多位顾客订单数并列最多，你能找到他们所有的 customer_number 吗？\n\n','examDataFiles/auto_upload_586_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_586_1637126775642.sql',1,1,0),(595,'0','大的国家','这里有张World 表\n\n```\n+-----------------+------------+------------+--------------+---------------+\n| name            | continent  | area       | population   | gdp           |\n+-----------------+------------+------------+--------------+---------------+\n| Afghanistan     | Asia       | 652230     | 25500100     | 20343000      |\n| Albania         | Europe     | 28748      | 2831741      | 12960000      |\n| Algeria         | Africa     | 2381741    | 37100000     | 188681000     |\n| Andorra         | Europe     | 468        | 78115        | 3712000       |\n| Angola          | Africa     | 1246700    | 20609294     | 100990000     |\n+-----------------+------------+------------+--------------+---------------+\n```\n\n如果一个国家的面积超过 300 万平方公里，或者人口超过 2500 万，那么这个国家就是大国家。\n\n编写一个 SQL 查询，输出表中所有大国家的名称、人口和面积。\n\n例如，根据上表，我们应该输出:\n\n```\n+--------------+-------------+--------------+\n| name         | population  | area         |\n+--------------+-------------+--------------+\n| Afghanistan  | 25500100    | 652230       |\n| Algeria      | 37100000    | 2381741      |\n+--------------+-------------+--------------+\n```\n\n','examDataFiles/auto_upload_595_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_595_1637126775642.sql',1,1,0),(596,'0','超过5名学生的课','有一个courses 表 ，有: student(学生) 和 class (课程)。\n\n请列出所有超过或等于5名学生的课。\n\n例如，表：\n\n```\n+---------+------------+\n| student | class      |\n+---------+------------+\n| A       | Math       |\n| B       | English    |\n| C       | Math       |\n| D       | Biology    |\n| E       | Math       |\n| F       | Computer   |\n| G       | Math       |\n| H       | Math       |\n| I       | Math       |\n+---------+------------+\n```\n\n应该输出:\n\n```\n+---------+\n| class   |\n+---------+\n| Math    |\n+---------+\n```\n\n提示：\n\n学生在每个课中不应被重复计算。\n\n','examDataFiles/auto_upload_596_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_596_1637126775642.sql',1,1,0),(597,'0','好友申请 I：总体通过率','在 Facebook 或者 Twitter 这样的社交应用中，人们经常会发好友申请也会收到其他人的好友申请。\n\n表：FriendRequest\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| sender_id      | int     |\n| send_to_id     | int     |\n| request_date   | date    |\n+----------------+---------+\n```\n\n此表没有主键，它可能包含重复项。\n\n该表包含发送请求的用户的 ID ，接受请求的用户的 ID 以及请求的日期。\n\n表：RequestAccepted\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| requester_id   | int     |\n| accepter_id    | int     |\n| accept_date    | date    |\n+----------------+---------+\n```\n\n此表没有主键，它可能包含重复项。\n\n该表包含发送请求的用户的 ID ，接受请求的用户的 ID 以及请求通过的日期。\n\n写一个查询语句，求出好友申请的通过率，用 2 位小数表示。通过率由接受好友申请的数目除以申请总数。\n\n提示：\n\n通过的好友申请不一定都在表friend_request中。你只需要统计总的被通过的申请数（不管它们在不在表FriendRequest中），并将它除以申请总数，得到通过率\n\n一个好友申请发送者有可能会给接受者发几条好友申请，也有可能一个好友申请会被通过好几次。这种情况下，重复的好友申请只统计一次。\n\n如果一个好友申请都没有，通过率为 0.00 。\n\n查询结果应该如下例所示：\n\nFriendRequest 表：\n\n```\n+-----------+------------+--------------+\n| sender_id | send_to_id | request_date |\n+-----------+------------+--------------+\n| 1         | 2          | 2016/06/01   |\n| 1         | 3          | 2016/06/01   |\n| 1         | 4          | 2016/06/01   |\n| 2         | 3          | 2016/06/02   |\n| 3         | 4          | 2016/06/09   |\n+-----------+------------+--------------+\n```\n\nRequestAccepted 表：\n\n```\n+--------------+-------------+-------------+\n| requester_id | accepter_id | accept_date |\n+--------------+-------------+-------------+\n| 1            | 2           | 2016/06/03  |\n| 1            | 3           | 2016/06/08  |\n| 2            | 3           | 2016/06/08  |\n| 3            | 4           | 2016/06/09  |\n| 3            | 4           | 2016/06/10  |\n+--------------+-------------+-------------+\n```\n\nResult 表：\n\n```\n+-------------+\n| accept_rate |\n+-------------+\n| 0.8         |\n+-------------+\n```\n\n总共有 5 个请求，有 4 个不同的通过请求，所以通过率是 0.80\n\n进阶:\n\n你能写一个查询语句得到每个月的通过率吗？\n\n你能求出每一天的累计通过率吗？\n\n','examDataFiles/auto_upload_597_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_597_1637126775642.sql',1,1,0),(601,'0','体育馆的人流量','表：Stadium\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| visit_date    | date    |\n| people        | int     |\n+---------------+---------+\n```\n\nvisit_date 是表的主键\n\n每日人流量信息被记录在这三列信息中：序号 (id)、日期 (visit_date)、人流量 (people)\n\n每天只有一行记录，日期随着 id 的增加而增加\n\n编写一个 SQL 查询以找出每行的人数大于或等于 100 且 id 连续的三行或更多行记录。\n\n返回按 visit_date 升序排列的结果表。\n\n查询结果格式如下所示。\n\nStadium table:\n\n```\n+------+------------+-----------+\n| id   | visit_date | people    |\n+------+------------+-----------+\n| 1    | 2017-01-01 | 10        |\n| 2    | 2017-01-02 | 109       |\n| 3    | 2017-01-03 | 150       |\n| 4    | 2017-01-04 | 99        |\n| 5    | 2017-01-05 | 145       |\n| 6    | 2017-01-06 | 1455      |\n| 7    | 2017-01-07 | 199       |\n| 8    | 2017-01-09 | 188       |\n+------+------------+-----------+\n```\n\nResult table:\n\n```\n+------+------------+-----------+\n| id   | visit_date | people    |\n+------+------------+-----------+\n| 5    | 2017-01-05 | 145       |\n| 6    | 2017-01-06 | 1455      |\n| 7    | 2017-01-07 | 199       |\n| 8    | 2017-01-09 | 188       |\n+------+------------+-----------+\n```\n\nid 为 5、6、7、8 的四行 id 连续，并且每行都有 >= 100 的人数记录。\n\n请注意，即使第 7 行和第 8 行的 visit_date 不是连续的，输出也应当包含第 8 行，因为我们只需要考虑 id 连续的记录。\n\n不输出 id 为 2 和 3 的行，因为至少需要三条 id 连续的记录。\n\n','examDataFiles/auto_upload_601_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_601_1637126775642.sql',3,1,0),(602,'0','好友申请 II ：谁有最多的好友','在 Facebook 或者 Twitter 这样的社交应用中，人们经常会发好友申请也会收到其他人的好友申请。\n\n表request_accepted存储了所有好友申请通过的数据记录，其中， requester_id和 accepter_id都是用户的编号。\n\n| requester_id | accepter_id | accept_date|\n\n|--------------|-------------|------------|\n\n| 1            | 2           | 2016_06-03 |\n\n| 1            | 3           | 2016-06-08 |\n\n| 2            | 3           | 2016-06-08 |\n\n| 3            | 4           | 2016-06-09 |\n\n写一个查询语句，求出谁拥有最多的好友和他拥有的好友数目。对于上面的样例数据，结果为：\n\n| id | num |\n\n|----|-----|\n\n| 3  | 3   |\n\n注意：\n\n保证拥有最多好友数目的只有 1 个人。\n\n好友申请只会被接受一次，所以不会有requester_id和accepter_id值都相同的重复记录。\n\n解释：\n\n编号为 \'3\' 的人是编号为 \'1\'，\'2\' 和 \'4\' 的好友，所以他总共有 3 个好友，比其他人都多。\n\n进阶：\n\n在真实世界里，可能会有多个人拥有好友数相同且最多，你能找到所有这些人吗？\n\n','examDataFiles/auto_upload_602_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_602_1637126775642.sql',2,1,0),(603,'0','连续空余座位','几个朋友来到电影院的售票处，准备预约连续空余座位。\n\n你能利用表cinema，帮他们写一个查询语句，获取所有空余座位，并将它们按照 seat_id 排序后返回吗？\n\n| seat_id | free |\n\n|---------|------|\n\n| 1       | 1    |\n\n| 2       | 0    |\n\n| 3       | 1    |\n\n| 4       | 1    |\n\n| 5       | 1    |\n\n对于如上样例，你的查询语句应该返回如下结果。\n\n| seat_id |\n\n|---------|\n\n| 3       |\n\n| 4       |\n\n| 5       |\n\n注意：\n\nseat_id 字段是一个自增的整数，free 字段是布尔类型（\'1\' 表示空余， \'0\' 表示已被占据）。\n\n连续空余座位的定义是大于等于 2 个连续空余的座位。\n\n','examDataFiles/auto_upload_603_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_603_1637126775642.sql',1,1,0),(607,'0','销售员','描述\n\n给定 3 个表：salesperson，company，orders。\n\n输出所有表salesperson中，没有向公司 \'RED\' 销售任何东西的销售员。\n\n示例：\n\n输入\n\n表：salesperson\n\n```\n+----------+------+--------+-----------------+-----------+\n| sales_id | name | salary | commission_rate | hire_date |\n+----------+------+--------+-----------------+-----------+\n|   1      | John | 100000 |     6           | 4/1/2006  |\n|   2      | Amy  | 120000 |     5           | 5/1/2010  |\n|   3      | Mark | 65000  |     12          | 12/25/2008|\n|   4      | Pam  | 25000  |     25          | 1/1/2005  |\n|   5      | Alex | 50000  |     10          | 2/3/2007  |\n+----------+------+--------+-----------------+-----------+\n```\n\n表salesperson 存储了所有销售员的信息。每个销售员都有一个销售员编号sales_id 和他的名字name。\n\n表：company\n\n```\n+---------+--------+------------+\n| com_id  |  name  |    city    |\n+---------+--------+------------+\n|   1     |  RED   |   Boston   |\n|   2     | ORANGE |   New York |\n|   3     | YELLOW |   Boston   |\n|   4     | GREEN  |   Austin   |\n+---------+--------+------------+\n```\n\n表company存储了所有公司的信息。每个公司都有一个公司编号com_id和它的名字 name。\n\n表：orders\n\n```\n+----------+------------+---------+----------+--------+\n| order_id | order_date | com_id  | sales_id | amount |\n+----------+------------+---------+----------+--------+\n| 1        |   1/1/2014 |    3    |    4     | 100000 |\n| 2        |   2/1/2014 |    4    |    5     | 5000   |\n| 3        |   3/1/2014 |    1    |    1     | 50000  |\n| 4        |   4/1/2014 |    1    |    4     | 25000  |\n+----------+----------+---------+----------+--------+\n```\n\n表orders存储了所有的销售数据，包括销售员编号 sales_id 和公司编号 com_id。\n\n输出\n\n```\n+------+\n| name | \n+------+\n| Amy  | \n| Mark | \n| Alex |\n+------+\n```\n\n解释\n\n根据表orders中的订单 \'3\' 和 \'4\' ，容易看出只有 \'John\' 和 \'Pam\' 两个销售员曾经向公司 \'RED\' 销售过。\n\n所以我们需要输出表salesperson中所有其他人的名字。\n\n','examDataFiles/auto_upload_607_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_607_1637126775642.sql',1,1,0),(608,'0','树节点','给定一个表tree，id 是树节点的编号，p_id是它父节点的id 。\n\n```\n+----+------+\n| id | p_id |\n+----+------+\n| 1  | null |\n| 2  | 1    |\n| 3  | 1    |\n| 4  | 2    |\n| 5  | 2    |\n+----+------+\n```\n\n树中每个节点属于以下三种类型之一：\n\n叶子：如果这个节点没有任何孩子节点。\n\n根：如果这个节点是整棵树的根，即没有父节点。\n\n内部节点：如果这个节点既不是叶子节点也不是根节点。\n\n写一个查询语句，输出所有节点的编号和节点的类型，并将结果按照节点编号排序。上面样例的结果为：\n\n```\n+----+------+\n| id | Type |\n+----+------+\n| 1  | Root |\n| 2  | Inner|\n| 3  | Leaf |\n| 4  | Leaf |\n| 5  | Leaf |\n+----+------+\n```\n\n解释\n\n节点 \'1\' 是根节点，因为它的父节点是 NULL ，同时它有孩子节点 \'2\' 和 \'3\' 。\n\n节点 \'2\' 是内部节点，因为它有父节点 \'1\' ，也有孩子节点 \'4\' 和 \'5\' 。\n\n节点 \'3\', \'4\' 和 \'5\' 都是叶子节点，因为它们都有父节点同时没有孩子节点。\n\n样例中树的形态如下：\n\n	\n\n			  1\n\n			/   \\\n\n                      2       3\n\n                    /   \\\n\n                  4       5\n\n注意\n\n如果树中只有一个节点，你只需要输出它的根属性。\n\n','examDataFiles/auto_upload_608_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_608_1637126775642.sql',2,1,0),(612,'0','平面上的最近距离','表point_2d保存了所有点（多于 2 个点）的坐标 (x,y) ，这些点在平面上两两不重合。\n\n写一个查询语句找到两点之间的最近距离，保留 2 位小数。\n\n| x  | y  |\n\n|----|----|\n\n| -1 | -1 |\n\n| 0  | 0  |\n\n| -1 | -2 |\n\n最近距离在点 (-1,-1) 和(-1,2) 之间，距离为 1.00 。所以输出应该为：\n\n| shortest |\n\n|----------|\n\n| 1.00     |\n\n注意：任意点之间的最远距离小于 10000 。\n\n','examDataFiles/auto_upload_612_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_612_1637126775642.sql',2,1,0),(613,'0','直线上的最近距离','表point保存了一些点在 x 轴上的坐标，这些坐标都是整数。\n\n写一个查询语句，找到这些点中最近两个点之间的距离。\n\n| x   |\n\n|-----|\n\n| -1  |\n\n| 0   |\n\n| 2   |\n\n最近距离显然是 \'1\' ，是点 \'-1\' 和 \'0\' 之间的距离。所以输出应该如下：\n\n| shortest|\n\n|---------|\n\n| 1       |\n\n注意：每个点都与其他点坐标不同，表table不会有重复坐标出现。\n\n进阶：如果这些点在 x 轴上从左到右都有一个编号，输出结果时需要输出最近点对的编号呢？\n\n','examDataFiles/auto_upload_613_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_613_1637126775642.sql',1,1,0),(614,'0','二级关注者','在 facebook 中，表follow会有 2 个字段： followee, follower，分别表示被关注者和关注者。\n\n请写一个 sql 查询语句，对每一个关注者，查询关注他的关注者的数目。\n\n比方说：\n\n```\n+-------------+------------+\n| followee    | follower   |\n+-------------+------------+\n|     A       |     B      |\n|     B       |     C      |\n|     B       |     D      |\n|     D       |     E      |\n+-------------+------------+\n```\n\n应该输出：\n\n```\n+-------------+------------+\n| follower    | num        |\n+-------------+------------+\n|     B       |  2         |\n|     D       |  1         |\n+-------------+------------+\n```\n\n解释：\n\nB 和 D 都在在follower字段中出现，作为被关注者，B 被 C 和 D 关注，D 被 E 关注。A 不在 follower字段内，所以A不在输出列表中。\n\n注意：\n\n被关注者永远不会被他 / 她自己关注。\n\n将结果按照字典序返回。\n\n','examDataFiles/auto_upload_614_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_614_1637126775642.sql',2,1,0),(618,'0','学生地理信息报告','一所美国大学有来自亚洲、欧洲和美洲的学生，他们的地理信息存放在如下student 表中。\n\n| name   | continent |\n\n|--------|-----------|\n\n| Jack   | America   |\n\n| Pascal | Europe    |\n\n| Xi     | Asia      |\n\n| Jane   | America   |\n\n写一个查询语句实现对大洲（continent）列的透视表 操作，使得每个学生按照姓名的字母顺序依次排列在对应的大洲下面。输出的标题应依次为美洲（America）、亚洲（Asia）和欧洲（Europe）。\n\n对于样例输入，它的对应输出是：\n\n| America | Asia | Europe |\n\n|---------|------|--------|\n\n| Jack    | Xi   | Pascal |\n\n| Jane    |      |        |\n\n进阶：如果不能确定哪个大洲的学生数最多，你可以写出一个查询去生成上述学生报告吗？\n\n','examDataFiles/auto_upload_618_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_618_1637126775642.sql',3,1,0),(619,'0','只出现一次的最大数字','表my_numbers的 num字段包含很多数字，其中包括很多重复的数字。\n\n你能写一个 SQL 查询语句，找到只出现过一次的数字中，最大的一个数字吗？\n\n```\n+---+\n|num|\n+---+\n| 8 |\n| 8 |\n| 3 |\n| 3 |\n| 1 |\n| 4 |\n| 5 |\n| 6 | \n对于上面给出的样例数据，你的查询语句应该返回如下结果：\n+---+\n|num|\n+---+\n| 6 |\n注意：\n如果没有只出现一次的数字，输出null。\n','examDataFiles/auto_upload_619_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_619_1637126775642.sql',1,1,0),(620,'0','有趣的电影','某城市开了一家新的电影院，吸引了很多人过来看电影。该电影院特别注意用户体验，专门有个 LED显示板做电影推荐，上面公布着影评和相关电影描述。\n\n作为该电影院的信息部主管，您需要编写一个 SQL查询，找出所有影片描述为非boring(不无聊)的并且 id 为奇数的影片，结果请按等级 rating 排列。\n\n例如，下表 cinema:\n\n```\n+---------+-----------+--------------+-----------+\n|   id    | movie     |  description |  rating   |\n+---------+-----------+--------------+-----------+\n|   1     | War       |   great 3D   |   8.9     |\n|   2     | Science   |   fiction    |   8.5     |\n|   3     | irish     |   boring     |   6.2     |\n|   4     | Ice song  |   Fantacy    |   8.6     |\n|   5     | House card|   Interesting|   9.1     |\n+---------+-----------+--------------+-----------+\n```\n\n对于上面的例子，则正确的输出是为：\n\n```\n+---------+-----------+--------------+-----------+\n|   id    | movie     |  description |  rating   |\n+---------+-----------+--------------+-----------+\n|   5     | House card|   Interesting|   9.1     |\n|   1     | War       |   great 3D   |   8.9     |\n+---------+-----------+--------------+-----------+\n```\n\n','examDataFiles/auto_upload_620_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_620_1637126775642.sql',1,1,0),(626,'0','换座位','小美是一所中学的信息科技老师，她有一张 seat座位表，平时用来储存学生名字和与他们相对应的座位 id。\n\n其中纵列的id是连续递增的\n\n小美想改变相邻俩学生的座位。\n\n你能不能帮她写一个 SQL query来输出小美想要的结果呢？\n\n示例：\n\n```\n+---------+---------+\n|    id   | student |\n+---------+---------+\n|    1    | Abbot   |\n|    2    | Doris   |\n|    3    | Emerson |\n|    4    | Green   |\n|    5    | Jeames  |\n+---------+---------+\n```\n\n假如数据输入的是上表，则输出结果如下：\n\n```\n+---------+---------+\n|    id   | student |\n+---------+---------+\n|    1    | Doris   |\n|    2    | Abbot   |\n|    3    | Green   |\n|    4    | Emerson |\n|    5    | Jeames  |\n+---------+---------+\n```\n\n注意：\n\n如果学生人数是奇数，则不需要改变最后一个同学的座位。\n\n','examDataFiles/auto_upload_626_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_626_1637126775642.sql',2,1,0),(627,'0','变更性别','给定一个salary表，如下所示，有 m = 男性 和 f = 女性 的值。交换所有的 f 和 m 值（例如，将所有 f 值更改为 m，反之亦然）。要求只使用一个更新（Update）语句，并且没有中间的临时表。\n\n注意，您必只能写一个 Update 语句，请不要编写任何 Select 语句。\n\n例如：\n\n| id | name | sex | salary |\n\n|----|------|-----|--------|\n\n| 1  | A    | m   | 2500   |\n\n| 2  | B    | f   | 1500   |\n\n| 3  | C    | m   | 5500   |\n\n| 4  | D    | f   | 500    |\n\n运行你所编写的更新语句之后，将会得到以下表:\n\n| id | name | sex | salary |\n\n|----|------|-----|--------|\n\n| 1  | A    | f   | 2500   |\n\n| 2  | B    | m   | 1500   |\n\n| 3  | C    | f   | 5500   |\n\n| 4  | D    | m   | 500    |\n\n','examDataFiles/auto_upload_627_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_627_1637126775642.sql',1,1,0),(1135,'0','买下所有产品的客户','Customer表：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| customer_id | int     |\n| product_key | int     |\n+-------------+---------+\n```\n\nproduct_key 是 Customer 表的外键。\n\nProduct表：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| product_key | int     |\n+-------------+---------+\n```\n\nproduct_key 是这张表的主键。\n\n写一条 SQL 查询语句，从 Customer 表中查询购买了 Product 表中所有产品的客户的 id。\n\n示例：\n\nCustomer 表：\n\n```\n+-------------+-------------+\n| customer_id | product_key |\n+-------------+-------------+\n| 1           | 5           |\n| 2           | 6           |\n| 3           | 5           |\n| 3           | 6           |\n| 1           | 6           |\n+-------------+-------------+\n```\n\nProduct 表：\n\n```\n+-------------+\n| product_key |\n+-------------+\n| 5           |\n| 6           |\n+-------------+\n```\n\nResult 表：\n\n```\n+-------------+\n| customer_id |\n+-------------+\n| 1           |\n| 3           |\n+-------------+\n```\n\n购买了所有产品（5 和 6）的客户的 id 是 1 和 3 。\n\n','examDataFiles/auto_upload_1135_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1135_1637126775642.sql',2,1,0),(1136,'0','合作过至少三次的演员和导演','ActorDirector表：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| actor_id    | int     |\n| director_id | int     |\n| timestamp   | int     |\n+-------------+---------+\n```\n\ntimestamp 是这张表的主键.\n\n写一条SQL查询语句获取合作过至少三次的演员和导演的 id 对(actor_id, director_id)\n\n示例：\n\nActorDirector 表：\n\n```\n+-------------+-------------+-------------+\n| actor_id    | director_id | timestamp   |\n+-------------+-------------+-------------+\n| 1           | 1           | 0           |\n| 1           | 1           | 1           |\n| 1           | 1           | 2           |\n| 1           | 2           | 3           |\n| 1           | 2           | 4           |\n| 2           | 1           | 5           |\n| 2           | 1           | 6           |\n+-------------+-------------+-------------+\n```\n\nResult 表：\n\n```\n+-------------+-------------+\n| actor_id    | director_id |\n+-------------+-------------+\n| 1           | 1           |\n+-------------+-------------+\n```\n\n唯一的 id 对是 (1, 1)，他们恰好合作了 3 次。\n\n','examDataFiles/auto_upload_1136_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1136_1637126775642.sql',1,1,0),(1161,'0','项目员工 I','项目表Project：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| project_id  | int     |\n| employee_id | int     |\n+-------------+---------+\n```\n\n主键为 (project_id, employee_id)。\n\nemployee_id 是员工表 Employee 表的外键。\n\n员工表Employee：\n\n```\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| employee_id      | int     |\n| name             | varchar |\n| experience_years | int     |\n+------------------+---------+\n```\n\n主键是 employee_id。\n\n请写一个 SQL语句，查询每一个项目中员工的平均工作年限，精确到小数点后两位。\n\n查询结果的格式如下：\n\nProject 表：\n\n```\n+-------------+-------------+\n| project_id  | employee_id |\n+-------------+-------------+\n| 1           | 1           |\n| 1           | 2           |\n| 1           | 3           |\n| 2           | 1           |\n| 2           | 4           |\n+-------------+-------------+\n```\n\nEmployee 表：\n\n```\n+-------------+--------+------------------+\n| employee_id | name   | experience_years |\n+-------------+--------+------------------+\n| 1           | Khaled | 3                |\n| 2           | Ali    | 2                |\n| 3           | John   | 1                |\n| 4           | Doe    | 2                |\n+-------------+--------+------------------+\n```\n\nResult 表：\n\n```\n+-------------+---------------+\n| project_id  | average_years |\n+-------------+---------------+\n| 1           | 2.00          |\n| 2           | 2.50          |\n+-------------+---------------+\n```\n\n第一个项目中，员工的平均工作年限是 (3 + 2 + 1) / 3 = 2.00；第二个项目中，员工的平均工作年限是 (3 + 2) / 2 = 2.50\n\n','examDataFiles/auto_upload_1161_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1161_1637126775642.sql',1,1,0),(1162,'0','项目员工II','Table:Project\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| project_id  | int     |\n| employee_id | int     |\n+-------------+---------+\n```\n\n主键为 (project_id, employee_id)。\n\nemployee_id 是员工表 Employee 表的外键。\n\nTable:Employee\n\n```\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| employee_id      | int     |\n| name             | varchar |\n| experience_years | int     |\n+------------------+---------+\n```\n\n主键是 employee_id。\n\n编写一个SQL查询，报告所有雇员最多的项目。\n\n查询结果格式如下所示：\n\nProject table:\n\n```\n+-------------+-------------+\n| project_id  | employee_id |\n+-------------+-------------+\n| 1           | 1           |\n| 1           | 2           |\n| 1           | 3           |\n| 2           | 1           |\n| 2           | 4           |\n+-------------+-------------+\n```\n\nEmployee table:\n\n```\n+-------------+--------+------------------+\n| employee_id | name   | experience_years |\n+-------------+--------+------------------+\n| 1           | Khaled | 3                |\n| 2           | Ali    | 2                |\n| 3           | John   | 1                |\n| 4           | Doe    | 2                |\n+-------------+--------+------------------+\n```\n\nResult table:\n\n```\n+-------------+\n| project_id  |\n+-------------+\n| 1           |\n+-------------+\n```\n\n第一个项目有3名员工，第二个项目有2名员工。\n\n','examDataFiles/auto_upload_1162_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1162_1637126775642.sql',1,1,0),(1163,'0','项目员工 III','项目表Project：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| project_id  | int     |\n| employee_id | int     |\n+-------------+---------+\n```\n\n(project_id, employee_id) 是这个表的主键\n\nemployee_id 是员工表 Employee 的外键\n\n员工表Employee：\n\n```\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| employee_id      | int     |\n| name             | varchar |\n| experience_years | int     |\n+------------------+---------+\n```\n\nemployee_id 是这个表的主键\n\n写 一个 SQL 查询语句，报告在每一个项目中经验最丰富的雇员是谁。如果出现经验年数相同的情况，请报告所有具有最大经验年数的员工。\n\n查询结果格式在以下示例中：\n\nProject 表：\n\n```\n+-------------+-------------+\n| project_id  | employee_id |\n+-------------+-------------+\n| 1           | 1           |\n| 1           | 2           |\n| 1           | 3           |\n| 2           | 1           |\n| 2           | 4           |\n+-------------+-------------+\n```\n\nEmployee 表：\n\n```\n+-------------+--------+------------------+\n| employee_id | name   | experience_years |\n+-------------+--------+------------------+\n| 1           | Khaled | 3                |\n| 2           | Ali    | 2                |\n| 3           | John   | 3                |\n| 4           | Doe    | 2                |\n+-------------+--------+------------------+\n```\n\nResult 表：\n\n```\n+-------------+---------------+\n| project_id  | employee_id   |\n+-------------+---------------+\n| 1           | 1             |\n| 1           | 3             |\n| 2           | 1             |\n+-------------+---------------+\n```\n\nemployee_id 为 1 和 3 的员工在 project_id 为 1 的项目中拥有最丰富的经验。在 project_id 为 2 的项目中，employee_id 为 1 的员工拥有最丰富的经验。\n\n','examDataFiles/auto_upload_1163_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1163_1637126775642.sql',2,1,0),(1172,'0','销售分析 I ','产品表：Product\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| product_id   | int     |\n| product_name | varchar |\n| unit_price   | int     |\n+--------------+---------+\n```\n\nproduct_id 是这个表的主键.\n\n销售表：Sales\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| seller_id   | int     |\n| product_id  | int     |\n| buyer_id    | int     |\n| sale_date   | date    |\n| quantity    | int     |\n| price       | int     |\n+------ ------+---------+\n```\n\n这个表没有主键，它可以有重复的行.\n\nproduct_id 是 Product 表的外键.\n\n编写一个 SQL 查询，查询总销售额最高的销售者，如果有并列的，就都展示出来。\n\n查询结果格式如下所示：\n\nProduct 表：\n\n```\n+------------+--------------+------------+\n| product_id | product_name | unit_price |\n+------------+--------------+------------+\n| 1          | S8           | 1000       |\n| 2          | G4           | 800        |\n| 3          | iPhone       | 1400       |\n+------------+--------------+------------+\n```\n\nSales 表：\n\n```\n+-----------+------------+----------+------------+----------+-------+\n| seller_id | product_id | buyer_id | sale_date  | quantity | price |\n+-----------+------------+----------+------------+----------+-------+\n| 1         | 1          | 1        | 2019-01-21 | 2        | 2000  |\n| 1         | 2          | 2        | 2019-02-17 | 1        | 800   |\n| 2         | 2          | 3        | 2019-06-02 | 1        | 800   |\n| 3         | 3          | 4        | 2019-05-13 | 2        | 2800  |\n+-----------+------------+----------+------------+----------+-------+\n```\n\nResult 表：\n\n```\n+-------------+\n| seller_id   |\n+-------------+\n| 1           |\n| 3           |\n+-------------+\n```\n\nId 为 1 和 3 的销售者，销售总金额都为最高的 2800。\n\n','examDataFiles/auto_upload_1172_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1172_1637126775642.sql',1,1,0),(1173,'0','销售分析 II','Table:Product\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| product_id   | int     |\n| product_name | varchar |\n| unit_price   | int     |\n+--------------+---------+\n```\n\nproduct_id 是这张表的主键\n\nTable:Sales\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| seller_id   | int     |\n| product_id  | int     |\n| buyer_id    | int     |\n| sale_date   | date    |\n| quantity    | int     |\n| price       | int     |\n+------ ------+---------+\n```\n\n这个表没有主键，它可以有重复的行.\n\nproduct_id 是 Product 表的外键.\n\n编写一个 SQL 查询，查询购买了 S8 手机却没有购买 iPhone 的买家。注意这里 S8 和 iPhone 是 Product 表中的产品。\n\n查询结果格式如下图表示：\n\nProduct table:\n\n```\n+------------+--------------+------------+\n| product_id | product_name | unit_price |\n+------------+--------------+------------+\n| 1          | S8           | 1000       |\n| 2          | G4           | 800        |\n| 3          | iPhone       | 1400       |\n+------------+--------------+------------+\n```\n\nSales table:\n\n```\n+-----------+------------+----------+------------+----------+-------+\n| seller_id | product_id | buyer_id | sale_date  | quantity | price |\n+-----------+------------+----------+------------+----------+-------+\n| 1         | 1          | 1        | 2019-01-21 | 2        | 2000  |\n| 1         | 2          | 2        | 2019-02-17 | 1        | 800   |\n| 2         | 1          | 3        | 2019-06-02 | 1        | 800   |\n| 3         | 3          | 3        | 2019-05-13 | 2        | 2800  |\n+-----------+------------+----------+------------+----------+-------+\n```\n\nResult table:\n\n```\n+-------------+\n| buyer_id    |\n+-------------+\n| 1           |\n+-------------+\n```\n\nid 为 1 的买家购买了一部 S8，但是却没有购买 iPhone，而 id 为 3 的买家却同时购买了这 2 部手机。\n\n','examDataFiles/auto_upload_1173_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1173_1637126775642.sql',1,1,0),(1174,'0','销售分析III','Table:Product\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| product_id   | int     |\n| product_name | varchar |\n| unit_price   | int     |\n+--------------+---------+\n```\n\nproduct_id 是这个表的主键\n\nTable:Sales\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| seller_id   | int     |\n| product_id  | int     |\n| buyer_id    | int     |\n| sale_date   | date    |\n| quantity    | int     |\n| price       | int     |\n+------ ------+---------+\n```\n\n这个表没有主键，它可以有重复的行.\n\nproduct_id 是 Product 表的外键.\n\n编写一个SQL查询，报告2019年春季才售出的产品。即仅在2019-01-01至2019-03-31（含）之间出售的商品。\n\n查询结果格式如下所示：\n\nProduct table:\n\n```\n+------------+--------------+------------+\n| product_id | product_name | unit_price |\n+------------+--------------+------------+\n| 1          | S8           | 1000       |\n| 2          | G4           | 800        |\n| 3          | iPhone       | 1400       |\n+------------+--------------+------------+\n```\n\nSales table:\n\n```\n+-----------+------------+----------+------------+----------+-------+\n| seller_id | product_id | buyer_id | sale_date  | quantity | price |\n+-----------+------------+----------+------------+----------+-------+\n| 1         | 1          | 1        | 2019-01-21 | 2        | 2000  |\n| 1         | 2          | 2        | 2019-02-17 | 1        | 800   |\n| 2         | 2          | 3        | 2019-06-02 | 1        | 800   |\n| 3         | 3          | 4        | 2019-05-13 | 2        | 2800  |\n+-----------+------------+----------+------------+----------+-------+\n```\n\nResult table:\n\n```\n+-------------+--------------+\n| product_id  | product_name |\n+-------------+--------------+\n| 1           | S8           |\n+-------------+--------------+\n```\n\nid为1的产品仅在2019年春季销售，其他两个产品在之后销售。\n\n','examDataFiles/auto_upload_1174_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1174_1637126775642.sql',1,1,0),(1179,'0','游戏玩法分析 I','活动表Activity：\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| player_id    | int     |\n| device_id    | int     |\n| event_date   | date    |\n| games_played | int     |\n+--------------+---------+\n```\n\n表的主键是 (player_id, event_date)。\n\n这张表展示了一些游戏玩家在游戏平台上的行为活动。\n\n每行数据记录了一名玩家在退出平台之前，当天使用同一台设备登录平台后打开的游戏的数目（可能是 0 个）。\n\n写一条 SQL查询语句获取每位玩家 第一次登陆平台的日期。\n\n查询结果的格式如下所示：\n\nActivity 表：\n\n```\n+-----------+-----------+------------+--------------+\n| player_id | device_id | event_date | games_played |\n+-----------+-----------+------------+--------------+\n| 1         | 2         | 2016-03-01 | 5            |\n| 1         | 2         | 2016-05-02 | 6            |\n| 2         | 3         | 2017-06-25 | 1            |\n| 3         | 1         | 2016-03-02 | 0            |\n| 3         | 4         | 2018-07-03 | 5            |\n+-----------+-----------+------------+--------------+\n```\n\nResult 表：\n\n```\n+-----------+-------------+\n| player_id | first_login |\n+-----------+-------------+\n| 1         | 2016-03-01  |\n| 2         | 2017-06-25  |\n| 3         | 2016-03-02  |\n+-----------+-------------+\n```\n\n','examDataFiles/auto_upload_1179_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1179_1637126775642.sql',1,1,0),(1180,'0','游戏玩法分析 II','Table:Activity\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| player_id    | int     |\n| device_id    | int     |\n| event_date   | date    |\n| games_played | int     |\n+--------------+---------+\n```\n\n(player_id, event_date) 是这个表的两个主键\n\n这个表显示的是某些游戏玩家的游戏活动情况\n\n每一行是在某天使用某个设备登出之前登录并玩多个游戏（可能为0）的玩家的记录\n\n请编写一个 SQL 查询，描述每一个玩家首次登陆的设备名称\n\n查询结果格式在以下示例中：\n\nActivity table:\n\n```\n+-----------+-----------+------------+--------------+\n| player_id | device_id | event_date | games_played |\n+-----------+-----------+------------+--------------+\n| 1         | 2         | 2016-03-01 | 5            |\n| 1         | 2         | 2016-05-02 | 6            |\n| 2         | 3         | 2017-06-25 | 1            |\n| 3         | 1         | 2016-03-02 | 0            |\n| 3         | 4         | 2018-07-03 | 5            |\n+-----------+-----------+------------+--------------+\n```\n\nResult table:\n\n```\n+-----------+-----------+\n| player_id | device_id |\n+-----------+-----------+\n| 1         | 2         |\n| 2         | 3         |\n| 3         | 1         |\n+-----------+-----------+\n```\n\n','examDataFiles/auto_upload_1180_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1180_1637126775642.sql',1,1,0),(1181,'0','游戏玩法分析 III','Table:Activity\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| player_id    | int     |\n| device_id    | int     |\n| event_date   | date    |\n| games_played | int     |\n+--------------+---------+\n```\n\n（player_id，event_date）是此表的主键。\n\n这张表显示了某些游戏的玩家的活动情况。\n\n每一行是一个玩家的记录，他在某一天使用某个设备注销之前登录并玩了很多游戏（可能是 0 ）。\n\n编写一个 SQL 查询，同时报告每组玩家和日期，以及玩家到目前为止玩了多少游戏。也就是说，在此日期之前玩家所玩的游戏总数。详细情况请查看示例。\n\n查询结果格式如下所示：\n\nActivity table:\n\n```\n+-----------+-----------+------------+--------------+\n| player_id | device_id | event_date | games_played |\n+-----------+-----------+------------+--------------+\n| 1         | 2         | 2016-03-01 | 5            |\n| 1         | 2         | 2016-05-02 | 6            |\n| 1         | 3         | 2017-06-25 | 1            |\n| 3         | 1         | 2016-03-02 | 0            |\n| 3         | 4         | 2018-07-03 | 5            |\n+-----------+-----------+------------+--------------+\n```\n\nResult table:\n\n```\n+-----------+------------+---------------------+\n| player_id | event_date | games_played_so_far |\n+-----------+------------+---------------------+\n| 1         | 2016-03-01 | 5                   |\n| 1         | 2016-05-02 | 11                  |\n| 1         | 2017-06-25 | 12                  |\n| 3         | 2016-03-02 | 0                   |\n| 3         | 2018-07-03 | 5                   |\n+-----------+------------+---------------------+\n```\n\n对于 ID 为 1 的玩家，2016-05-02 共玩了 5+6=11 个游戏，2017-06-25 共玩了 5+6+1=12 个游戏。\n\n对于 ID 为 3 的玩家，2018-07-03 共玩了 0+5=5 个游戏。\n\n请注意，对于每个玩家，我们只关心玩家的登录日期。\n\n','examDataFiles/auto_upload_1181_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1181_1637126775642.sql',2,1,0),(1182,'0','游戏玩法分析 IV','Table:Activity\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| player_id    | int     |\n| device_id    | int     |\n| event_date   | date    |\n| games_played | int     |\n+--------------+---------+\n```\n\n（player_id，event_date）是此表的主键。\n\n这张表显示了某些游戏的玩家的活动情况。\n\n每一行是一个玩家的记录，他在某一天使用某个设备注销之前登录并玩了很多游戏（可能是 0）。\n\n编写一个 SQL 查询，报告在首次登录的第二天再次登录的玩家的比率，四舍五入到小数点后两位。换句话说，您需要计算从首次登录日期开始至少连续两天登录的玩家的数量，然后除以玩家总数。\n\n查询结果格式如下所示：\n\nActivity table:\n\n```\n+-----------+-----------+------------+--------------+\n| player_id | device_id | event_date | games_played |\n+-----------+-----------+------------+--------------+\n| 1         | 2         | 2016-03-01 | 5            |\n| 1         | 2         | 2016-03-02 | 6            |\n| 2         | 3         | 2017-06-25 | 1            |\n| 3         | 1         | 2016-03-02 | 0            |\n| 3         | 4         | 2018-07-03 | 5            |\n+-----------+-----------+------------+--------------+\n```\n\nResult table:\n\n```\n+-----------+\n| fraction  |\n+-----------+\n| 0.33      |\n+-----------+\n```\n\n只有 ID 为 1 的玩家在第一天登录后才重新登录，所以答案是 1/3 = 0.33\n\n','examDataFiles/auto_upload_1182_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1182_1637126775642.sql',2,1,0),(1193,'0','游戏玩法分析 V','Activity 活动记录表\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| player_id    | int     |\n| device_id    | int     |\n| event_date   | date    |\n| games_played | int     |\n+--------------+---------+\n```\n\n（player_id，event_date）是此表的主键\n\n这张表显示了某些游戏的玩家的活动情况\n\n每一行表示一个玩家的记录，在某一天使用某个设备注销之前，登录并玩了很多游戏（可能是 0）\n\n玩家的 安装日期 定义为该玩家的第一个登录日。\n\n玩家的 第一天留存率 定义为：假定安装日期为 X的玩家的数量为 N ，其中在 X之后的一天重新登录的玩家数量为 M ，M/N 就是第一天留存率，四舍五入到小数点后两位。\n\n编写一个 SQL 查询，报告所有安装日期、当天安装游戏的玩家数量和玩家的第一天留存率。\n\n查询结果格式如下所示：\n\nActivity 表：\n\n```\n+-----------+-----------+------------+--------------+\n| player_id | device_id | event_date | games_played |\n+-----------+-----------+------------+--------------+\n| 1         | 2         | 2016-03-01 | 5            |\n| 1         | 2         | 2016-03-02 | 6            |\n| 2         | 3         | 2017-06-25 | 1            |\n| 3         | 1         | 2016-03-01 | 0            |\n| 3         | 4         | 2016-07-03 | 5            |\n+-----------+-----------+------------+--------------+\n```\n\nResult 表：\n\n```\n+------------+----------+----------------+\n| install_dt | installs | Day1_retention |\n+------------+----------+----------------+\n| 2016-03-01 | 2        | 0.50           |\n| 2017-06-25 | 1        | 0.00           |\n+------------+----------+----------------+\n```\n\n玩家 1 和 3 在 2016-03-01 安装了游戏，但只有玩家 1 在 2016-03-02 重新登录，所以 2016-03-01 的第一天留存率是 1/2=0.50\n\n玩家 2 在 2017-06-25 安装了游戏，但在 2017-06-26 没有重新登录，因此 2017-06-25 的第一天留存率为 0/1=0.00\n\n','examDataFiles/auto_upload_1193_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1193_1637126775642.sql',3,1,0),(1198,'0','小众书籍','书籍表Books：\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| book_id        | int     |\n| name           | varchar |\n| available_from | date    |\n+----------------+---------+\n```\n\nbook_id 是这个表的主键。\n\n订单表Orders：\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| order_id       | int     |\n| book_id        | int     |\n| quantity       | int     |\n| dispatch_date  | date    |\n+----------------+---------+\n```\n\norder_id 是这个表的主键。\n\nbook_id  是 Books 表的外键。\n\n你需要写一段 SQL 命令，筛选出过去一年中订单总量少于10本的书籍。\n\n注意：不考虑上架（available from）距今不满一个月 的书籍。并且假设今天是2019-06-23。\n\n下面是样例输出结果：\n\nBooks 表：\n\n```\n+---------+--------------------+----------------+\n| book_id | name               | available_from |\n+---------+--------------------+----------------+\n| 1       | \"Kalila And Demna\" | 2010-01-01     |\n| 2       | \"28 Letters\"       | 2012-05-12     |\n| 3       | \"The Hobbit\"       | 2019-06-10     |\n| 4       | \"13 Reasons Why\"   | 2019-06-01     |\n| 5       | \"The Hunger Games\" | 2008-09-21     |\n+---------+--------------------+----------------+\n```\n\nOrders 表：\n\n```\n+----------+---------+----------+---------------+\n| order_id | book_id | quantity | dispatch_date |\n+----------+---------+----------+---------------+\n| 1        | 1       | 2        | 2018-07-26    |\n| 2        | 1       | 1        | 2018-11-05    |\n| 3        | 3       | 8        | 2019-06-11    |\n| 4        | 4       | 6        | 2019-06-05    |\n| 5        | 4       | 5        | 2019-06-20    |\n| 6        | 5       | 9        | 2009-02-02    |\n| 7        | 5       | 8        | 2010-04-13    |\n+----------+---------+----------+---------------+\n```\n\nResult 表：\n\n```\n+-----------+--------------------+\n| book_id   | name               |\n+-----------+--------------------+\n| 1         | \"Kalila And Demna\" |\n| 2         | \"28 Letters\"       |\n| 5         | \"The Hunger Games\" |\n+-----------+--------------------+\n```\n\n','examDataFiles/auto_upload_1198_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1198_1637126775642.sql',2,1,0),(1204,'0','每日新用户统计','Traffic表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| activity      | enum    |\n| activity_date | date    |\n+---------------+---------+\n```\n\n该表没有主键，它可能有重复的行。\n\nactivity 列是 ENUM 类型，可能取 (\'login\', \'logout\', \'jobs\', \'groups\', \'homepage\') 几个值之一。\n\n编写一个 SQL 查询，以查询从今天起最多 90 天内，每个日期该日期首次登录的用户数。假设今天是2019-06-30.\n\n查询结果格式如下例所示：\n\nTraffic 表：\n\n```\n+---------+----------+---------------+\n| user_id | activity | activity_date |\n+---------+----------+---------------+\n| 1       | login    | 2019-05-01    |\n| 1       | homepage | 2019-05-01    |\n| 1       | logout   | 2019-05-01    |\n| 2       | login    | 2019-06-21    |\n| 2       | logout   | 2019-06-21    |\n| 3       | login    | 2019-01-01    |\n| 3       | jobs     | 2019-01-01    |\n| 3       | logout   | 2019-01-01    |\n| 4       | login    | 2019-06-21    |\n| 4       | groups   | 2019-06-21    |\n| 4       | logout   | 2019-06-21    |\n| 5       | login    | 2019-03-01    |\n| 5       | logout   | 2019-03-01    |\n| 5       | login    | 2019-06-21    |\n| 5       | logout   | 2019-06-21    |\n+---------+----------+---------------+\n```\n\nResult 表：\n\n```\n+------------+-------------+\n| login_date | user_count  |\n+------------+-------------+\n| 2019-05-01 | 1           |\n| 2019-06-21 | 2           |\n+------------+-------------+\n```\n\n请注意，我们只关心用户数非零的日期.\n\nID 为 5 的用户第一次登陆于 2019-03-01，因此他不算在 2019-06-21 的的统计内。\n\n','examDataFiles/auto_upload_1204_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1204_1637126775642.sql',2,1,0),(1214,'0','每位学生的最高成绩','表：Enrollments\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| student_id    | int     |\n| course_id     | int     |\n| grade         | int     |\n+---------------+---------+\n```\n\n(student_id, course_id) 是该表的主键。\n\n编写一个 SQL 查询，查询每位学生获得的最高成绩和它所对应的科目，若科目成绩并列，取course_id最小的一门。查询结果需按student_id增序进行排序。\n\n查询结果格式如下所示：\n\nEnrollments 表：\n\n```\n+------------+-------------------+\n| student_id | course_id | grade |\n+------------+-----------+-------+\n| 2          | 2         | 95    |\n| 2          | 3         | 95    |\n| 1          | 1         | 90    |\n| 1          | 2         | 99    |\n| 3          | 1         | 80    |\n| 3          | 2         | 75    |\n| 3          | 3         | 82    |\n+------------+-----------+-------+\n```\n\nResult 表：\n\n```\n+------------+-------------------+\n| student_id | course_id | grade |\n+------------+-----------+-------+\n| 1          | 2         | 99    |\n| 2          | 2         | 95    |\n| 3          | 3         | 82    |\n+------------+-----------+-------+\n```\n\n','examDataFiles/auto_upload_1214_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1214_1637126775642.sql',2,1,0),(1215,'0','报告的记录','动作表：Actions\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| post_id       | int     |\n| action_date   | date    | \n| action        | enum    |\n| extra         | varchar |\n+---------------+---------+\n```\n\n此表没有主键，所以可能会有重复的行。\n\naction 字段是 ENUM 类型的，包含:(\'view\', \'like\', \'reaction\', \'comment\', \'report\', \'share\')\n\nextra 字段是可选的信息（可能为 null），其中的信息例如有：1.报告理由(a reason for report) 2.反应类型(a type of reaction)\n\n编写一条SQL，查询每种报告理由（report reason）在昨天的不同报告数量（post_id）。假设今天是2019-07-05。\n\n查询及结果的格式示例：\n\nActions table:\n\n```\n+---------+---------+-------------+--------+--------+\n| user_id | post_id | action_date | action | extra  |\n+---------+---------+-------------+--------+--------+\n| 1       | 1       | 2019-07-01  | view   | null   |\n| 1       | 1       | 2019-07-01  | like   | null   |\n| 1       | 1       | 2019-07-01  | share  | null   |\n| 2       | 4       | 2019-07-04  | view   | null   |\n| 2       | 4       | 2019-07-04  | report | spam   |\n| 3       | 4       | 2019-07-04  | view   | null   |\n| 3       | 4       | 2019-07-04  | report | spam   |\n| 4       | 3       | 2019-07-02  | view   | null   |\n| 4       | 3       | 2019-07-02  | report | spam   |\n| 5       | 2       | 2019-07-04  | view   | null   |\n| 5       | 2       | 2019-07-04  | report | racism |\n| 5       | 5       | 2019-07-04  | view   | null   |\n| 5       | 5       | 2019-07-04  | report | racism |\n+---------+---------+-------------+--------+--------+\n```\n\nResult table:\n\n```\n+---------------+--------------+\n| report_reason | report_count |\n+---------------+--------------+\n| spam          | 1            |\n| racism        | 2            |\n+---------------+--------------+ \n```\n\n注意，我们只关心报告数量非零的结果。\n\n','examDataFiles/auto_upload_1215_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1215_1637126775642.sql',1,1,0),(1225,'0','查询活跃业务','事件表：Events\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| business_id   | int     |\n| event_type    | varchar |\n| occurences    | int     | \n+---------------+---------+\n```\n\n此表的主键是 (business_id, event_type)。\n\n表中的每一行记录了某种类型的事件在某些业务中多次发生的信息。\n\n写一段 SQL 来查询所有活跃的业务。\n\n如果一个业务的某个事件类型的发生次数大于此事件类型在所有业务中的平均发生次数，并且该业务至少有两个这样的事件类型，那么该业务就可被看做是活跃业务。\n\n查询结果格式如下所示：\n\nEvents table:\n\n```\n+-------------+------------+------------+\n| business_id | event_type | occurences |\n+-------------+------------+------------+\n| 1           | reviews    | 7          |\n| 3           | reviews    | 3          |\n| 1           | ads        | 11         |\n| 2           | ads        | 7          |\n| 3           | ads        | 6          |\n| 1           | page views | 3          |\n| 2           | page views | 12         |\n+-------------+------------+------------+\n```\n\n结果表\n\n```\n+-------------+\n| business_id |\n+-------------+\n| 1           |\n+-------------+ \n```\n\n\'reviews\'、 \'ads\' 和 \'page views\' 的总平均发生次数分别是 (7+3)/2=5, (11+7+6)/3=8, (3+12)/2=7.5。\n\nid 为 1 的业务有 7 个 \'reviews\' 事件（大于 5）和 11 个 \'ads\' 事件（大于 8），所以它是活跃业务。\n\n','examDataFiles/auto_upload_1225_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1225_1637126775642.sql',2,1,0),(1226,'0','用户购买平台','支出表: Spending\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| user_id     | int     |\n| spend_date  | date    |\n| platform    | enum    | \n| amount      | int     |\n+-------------+---------+\n```\n\n这张表记录了用户在一个在线购物网站的支出历史，该在线购物平台同时拥有桌面端（\'desktop\'）和手机端（\'mobile\'）的应用程序。\n\n这张表的主键是 (user_id, spend_date, platform)。\n\n平台列 platform 是一种 ENUM ，类型为（\'desktop\', \'mobile\'）。\n\n写一段 SQL 来查找每天仅使用手机端用户、仅使用桌面端用户和同时使用桌面端和手机端的用户人数和总支出金额。\n\n查询结果格式如下例所示：\n\nSpending table:\n\n```\n+---------+------------+----------+--------+\n| user_id | spend_date | platform | amount |\n+---------+------------+----------+--------+\n| 1       | 2019-07-01 | mobile   | 100    |\n| 1       | 2019-07-01 | desktop  | 100    |\n| 2       | 2019-07-01 | mobile   | 100    |\n| 2       | 2019-07-02 | mobile   | 100    |\n| 3       | 2019-07-01 | desktop  | 100    |\n| 3       | 2019-07-02 | desktop  | 100    |\n+---------+------------+----------+--------+\n```\n\nResult table:\n\n```\n+------------+----------+--------------+-------------+\n| spend_date | platform | total_amount | total_users |\n+------------+----------+--------------+-------------+\n| 2019-07-01 | desktop  | 100          | 1           |\n| 2019-07-01 | mobile   | 100          | 1           |\n| 2019-07-01 | both     | 200          | 1           |\n| 2019-07-02 | desktop  | 100          | 1           |\n| 2019-07-02 | mobile   | 100          | 1           |\n| 2019-07-02 | both     | 0            | 0           |\n+------------+----------+--------------+-------------+ \n```\n\n在 2019-07-01, 用户1 同时 使用桌面端和手机端购买, 用户2 仅 使用了手机端购买，而用户3 仅 使用了桌面端购买。\n\n在 2019-07-02, 用户2 仅 使用了手机端购买, 用户3 仅 使用了桌面端购买，且没有用户 同时 使用桌面端和手机端购买。\n\n','examDataFiles/auto_upload_1226_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1226_1637126775642.sql',3,1,0),(1237,'0','报告的记录 II','动作表：Actions\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| post_id       | int     |\n| action_date   | date    |\n| action        | enum    |\n| extra         | varchar |\n+---------------+---------+\n```\n\n这张表没有主键，并有可能存在重复的行。\n\naction 列的类型是 ENUM，可能的值为 (\'view\', \'like\', \'reaction\', \'comment\', \'report\', \'share\')。\n\nextra 列拥有一些可选信息，例如：报告理由（a reason for report）或反应类型（a type of reaction）等。\n\n移除表：Removals\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| post_id       | int     |\n| remove_date   | date    | \n+---------------+---------+\n```\n\n这张表的主键是 post_id。\n\n这张表的每一行表示一个被移除的帖子，原因可能是由于被举报或被管理员审查。\n\n编写一段 SQL 来查找：在被报告为垃圾广告的帖子中，被移除的帖子的每日平均占比，四舍五入到小数点后 2 位。\n\n查询结果的格式如下：\n\nActions table:\n\n```\n+---------+---------+-------------+--------+--------+\n| user_id | post_id | action_date | action | extra  |\n+---------+---------+-------------+--------+--------+\n| 1       | 1       | 2019-07-01  | view   | null   |\n| 1       | 1       | 2019-07-01  | like   | null   |\n| 1       | 1       | 2019-07-01  | share  | null   |\n| 2       | 2       | 2019-07-04  | view   | null   |\n| 2       | 2       | 2019-07-04  | report | spam   |\n| 3       | 4       | 2019-07-04  | view   | null   |\n| 3       | 4       | 2019-07-04  | report | spam   |\n| 4       | 3       | 2019-07-02  | view   | null   |\n| 4       | 3       | 2019-07-02  | report | spam   |\n| 5       | 2       | 2019-07-03  | view   | null   |\n| 5       | 2       | 2019-07-03  | report | racism |\n| 5       | 5       | 2019-07-03  | view   | null   |\n| 5       | 5       | 2019-07-03  | report | racism |\n+---------+---------+-------------+--------+--------+\n```\n\nRemovals table:\n\n```\n+---------+-------------+\n| post_id | remove_date |\n+---------+-------------+\n| 2       | 2019-07-20  |\n| 3       | 2019-07-18  |\n+---------+-------------+\n```\n\nResult table:\n\n```\n+-----------------------+\n| average_daily_percent |\n+-----------------------+\n| 75.00                 |\n+-----------------------+\n```\n\n2019-07-04 的垃圾广告移除率是 50%，因为有两张帖子被报告为垃圾广告，但只有一个得到移除。\n\n2019-07-02 的垃圾广告移除率是 100%，因为有一张帖子被举报为垃圾广告并得到移除。\n\n其余几天没有收到垃圾广告的举报，因此平均值为：(50 + 100) / 2 = 75%\n\n注意，输出仅需要一个平均值即可，我们并不关注移除操作的日期。\n\n','examDataFiles/auto_upload_1237_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1237_1637126775642.sql',2,1,0),(1245,'0','查询近30天活跃用户数','活动记录表：Activity\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| session_id    | int     |\n| activity_date | date    |\n| activity_type | enum    |\n+---------------+---------+\n```\n\n该表是用户在社交网站的活动记录。\n\n该表没有主键，可能包含重复数据。\n\nactivity_type 字段为以下四种值 (\'open_session\', \'end_session\', \'scroll_down\', \'send_message\')。\n\n每个 session_id 只属于一个用户。\n\n请写SQL查询出截至2019-07-27（包含2019-07-27），近30天的每日活跃用户数（当天只要有一条活动记录，即为活跃用户）。\n\n查询结果示例如下：\n\nActivity table:\n\n```\n+---------+------------+---------------+---------------+\n| user_id | session_id | activity_date | activity_type |\n+---------+------------+---------------+---------------+\n| 1       | 1          | 2019-07-20    | open_session  |\n| 1       | 1          | 2019-07-20    | scroll_down   |\n| 1       | 1          | 2019-07-20    | end_session   |\n| 2       | 4          | 2019-07-20    | open_session  |\n| 2       | 4          | 2019-07-21    | send_message  |\n| 2       | 4          | 2019-07-21    | end_session   |\n| 3       | 2          | 2019-07-21    | open_session  |\n| 3       | 2          | 2019-07-21    | send_message  |\n| 3       | 2          | 2019-07-21    | end_session   |\n| 4       | 3          | 2019-06-25    | open_session  |\n| 4       | 3          | 2019-06-25    | end_session   |\n+---------+------------+---------------+---------------+\n```\n\nResult table:\n\n```\n+------------+--------------+ \n| day        | active_users |\n+------------+--------------+ \n| 2019-07-20 | 2            |\n| 2019-07-21 | 2            |\n+------------+--------------+ \n```\n\n非活跃用户的记录不需要展示。\n\n','examDataFiles/auto_upload_1245_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1245_1637126775642.sql',1,1,0),(1246,'0','过去30天的用户活动 II','Table: Activity\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| session_id    | int     |\n| activity_date | date    |\n| activity_type | enum    |\n+---------------+---------+\n```\n\n该表没有主键，它可能有重复的行。\n\nactivity_type 列是 ENUM（“ open_session”，“ end_session”，“ scroll_down”，“ send_message”）中的某一类型。\n\n该表显示了社交媒体网站的用户活动。\n\n请注意，每个会话完全属于一个用户。\n\n编写SQL查询以查找截至2019年7月27日（含）的30天内每个用户的平均会话数，四舍五入到小数点后两位。我们只统计那些会话期间用户至少进行一项活动的有效会话。\n\n查询结果格式如下例所示：\n\nActivity table:\n\n```\n+---------+------------+---------------+---------------+\n| user_id | session_id | activity_date | activity_type |\n+---------+------------+---------------+---------------+\n| 1       | 1          | 2019-07-20    | open_session  |\n| 1       | 1          | 2019-07-20    | scroll_down   |\n| 1       | 1          | 2019-07-20    | end_session   |\n| 2       | 4          | 2019-07-20    | open_session  |\n| 2       | 4          | 2019-07-21    | send_message  |\n| 2       | 4          | 2019-07-21    | end_session   |\n| 3       | 2          | 2019-07-21    | open_session  |\n| 3       | 2          | 2019-07-21    | send_message  |\n| 3       | 2          | 2019-07-21    | end_session   |\n| 3       | 5          | 2019-07-21    | open_session  |\n| 3       | 5          | 2019-07-21    | scroll_down   |\n| 3       | 5          | 2019-07-21    | end_session   |\n| 4       | 3          | 2019-06-25    | open_session  |\n| 4       | 3          | 2019-06-25    | end_session   |\n+---------+------------+---------------+---------------+\n```\n\nResult table:\n\n```\n+---------------------------+ \n| average_sessions_per_user |\n+---------------------------+ \n| 1.33                      |\n+---------------------------+ \n```\n\nUser 1 和 2 在过去30天内各自进行了1次会话，而用户3进行了2次会话，因此平均值为（1 +1 + 2）/ 3 = 1.33。\n\n','examDataFiles/auto_upload_1246_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1246_1637126775642.sql',1,1,0),(1258,'0','文章浏览 I','Views表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| article_id    | int     |\n| author_id     | int     |\n| viewer_id     | int     |\n| view_date     | date    |\n+---------------+---------+\n```\n\n此表无主键，因此可能会存在重复行。\n\n此表的每一行都表示某人在某天浏览了某位作者的某篇文章。\n\n请注意，同一人的 author_id 和 viewer_id 是相同的。\n\n请编写一条 SQL 查询以找出所有浏览过自己文章的作者，结果按照 id 升序排列。\n\n查询结果的格式如下所示：\n\nViews 表：\n\n```\n+------------+-----------+-----------+------------+\n| article_id | author_id | viewer_id | view_date  |\n+------------+-----------+-----------+------------+\n| 1          | 3         | 5         | 2019-08-01 |\n| 1          | 3         | 6         | 2019-08-02 |\n| 2          | 7         | 7         | 2019-08-01 |\n| 2          | 7         | 6         | 2019-08-02 |\n| 4          | 7         | 1         | 2019-07-22 |\n| 3          | 4         | 4         | 2019-07-21 |\n| 3          | 4         | 4         | 2019-07-21 |\n+------------+-----------+-----------+------------+\n```\n\n结果表：\n\n```\n+------+\n| id   |\n+------+\n| 4    |\n| 7    |\n+------+\n```\n\n','examDataFiles/auto_upload_1258_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1258_1637126775642.sql',1,1,0),(1259,'0','文章浏览 II','Table: Views\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| article_id    | int     |\n| author_id     | int     |\n| viewer_id     | int     |\n| view_date     | date    |\n+---------------+---------+\n```\n\n此表无主键，因此可能会存在重复行。此表的每一行都表示某人在某天浏览了某位作者的某篇文章。 请注意，同一人的 author_id 和 viewer_id 是相同的。\n\n编写一条 SQL 查询来找出在同一天阅读至少两篇文章的人，结果按照 id 升序排序。\n\n查询结果的格式如下：\n\nViews table:\n\n```\n+------------+-----------+-----------+------------+\n| article_id | author_id | viewer_id | view_date  |\n+------------+-----------+-----------+------------+\n| 1          | 3         | 5         | 2019-08-01 |\n| 3          | 4         | 5         | 2019-08-01 |\n| 1          | 3         | 6         | 2019-08-02 |\n| 2          | 7         | 7         | 2019-08-01 |\n| 2          | 7         | 6         | 2019-08-02 |\n| 4          | 7         | 1         | 2019-07-22 |\n| 3          | 4         | 4         | 2019-07-21 |\n| 3          | 4         | 4         | 2019-07-21 |\n+------------+-----------+-----------+------------+\n```\n\nResult table:\n\n```\n+------+\n| id   |\n+------+\n| 5    |\n| 6    |\n+------+\n```\n\n','examDataFiles/auto_upload_1259_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1259_1637126775642.sql',2,1,0),(1268,'0','市场分析 I','Table: Users\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| user_id        | int     |\n| join_date      | date    |\n| favorite_brand | varchar |\n+----------------+---------+\n```\n\n此表主键是 user_id，表中描述了购物网站的用户信息，用户可以在此网站上进行商品买卖。\n\nTable: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| item_id       | int     |\n| buyer_id      | int     |\n| seller_id     | int     |\n+---------------+---------+\n```\n\n此表主键是 order_id，外键是 item_id 和（buyer_id，seller_id）。\n\nTable: Item\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| item_id       | int     |\n| item_brand    | varchar |\n+---------------+---------+\n```\n\n此表主键是 item_id。\n\n请写出一条SQL语句以查询每个用户的注册日期和在 2019 年作为买家的订单总数。\n\n查询结果格式如下：\n\nUsers table:\n\n```\n+---------+------------+----------------+\n| user_id | join_date  | favorite_brand |\n+---------+------------+----------------+\n| 1       | 2018-01-01 | Lenovo         |\n| 2       | 2018-02-09 | Samsung        |\n| 3       | 2018-01-19 | LG             |\n| 4       | 2018-05-21 | HP             |\n+---------+------------+----------------+\n```\n\nOrders table:\n\n```\n+----------+------------+---------+----------+-----------+\n| order_id | order_date | item_id | buyer_id | seller_id |\n+----------+------------+---------+----------+-----------+\n| 1        | 2019-08-01 | 4       | 1        | 2         |\n| 2        | 2018-08-02 | 2       | 1        | 3         |\n| 3        | 2019-08-03 | 3       | 2        | 3         |\n| 4        | 2018-08-04 | 1       | 4        | 2         |\n| 5        | 2018-08-04 | 1       | 3        | 4         |\n| 6        | 2019-08-05 | 2       | 2        | 4         |\n+----------+------------+---------+----------+-----------+\n```\n\nItems table:\n\n```\n+---------+------------+\n| item_id | item_brand |\n+---------+------------+\n| 1       | Samsung    |\n| 2       | Lenovo     |\n| 3       | LG         |\n| 4       | HP         |\n+---------+------------+\n```\n\nResult table:\n\n```\n+-----------+------------+----------------+\n| buyer_id  | join_date  | orders_in_2019 |\n+-----------+------------+----------------+\n| 1         | 2018-01-01 | 1              |\n| 2         | 2018-02-09 | 2              |\n| 3         | 2018-01-19 | 0              |\n| 4         | 2018-05-21 | 0              |\n+-----------+------------+----------------+\n```\n\n','examDataFiles/auto_upload_1268_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1268_1637126775642.sql',2,1,0),(1269,'0','市场分析 II','表: Users\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| user_id        | int     |\n| join_date      | date    |\n| favorite_brand | varchar |\n+----------------+---------+\n```\n\nuser_id 是该表的主键\n\n表中包含一位在线购物网站用户的个人信息，用户可以在该网站出售和购买商品。\n\n表: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| item_id       | int     |\n| buyer_id      | int     |\n| seller_id     | int     |\n+---------------+---------+\n```\n\norder_id 是该表的主键\n\nitem_id 是 Items 表的外键\n\nbuyer_id 和 seller_id 是 Users 表的外键\n\n表: Items\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| item_id       | int     |\n| item_brand    | varchar |\n+---------------+---------+\n```\n\nitem_id 是该表的主键\n\n写一个 SQL 查询确定每一个用户按日期顺序卖出的第二件商品的品牌是否是他们最喜爱的品牌。如果一个用户卖出少于两件商品，查询的结果是 no 。\n\n题目保证没有一个用户在一天中卖出超过一件商品\n\n下面是查询结果格式的例子：\n\nUsers table:\n\n```\n+---------+------------+----------------+\n| user_id | join_date  | favorite_brand |\n+---------+------------+----------------+\n| 1       | 2019-01-01 | Lenovo         |\n| 2       | 2019-02-09 | Samsung        |\n| 3       | 2019-01-19 | LG             |\n| 4       | 2019-05-21 | HP             |\n+---------+------------+----------------+\n```\n\nOrders table:\n\n```\n+----------+------------+---------+----------+-----------+\n| order_id | order_date | item_id | buyer_id | seller_id |\n+----------+------------+---------+----------+-----------+\n| 1        | 2019-08-01 | 4       | 1        | 2         |\n| 2        | 2019-08-02 | 2       | 1        | 3         |\n| 3        | 2019-08-03 | 3       | 2        | 3         |\n| 4        | 2019-08-04 | 1       | 4        | 2         |\n| 5        | 2019-08-04 | 1       | 3        | 4         |\n| 6        | 2019-08-05 | 2       | 2        | 4         |\n+----------+------------+---------+----------+-----------+\n```\n\nItems table:\n\n```\n+---------+------------+\n| item_id | item_brand |\n+---------+------------+\n| 1       | Samsung    |\n| 2       | Lenovo     |\n| 3       | LG         |\n| 4       | HP         |\n+---------+------------+\n```\n\nResult table:\n\n```\n+-----------+--------------------+\n| seller_id | 2nd_item_fav_brand |\n+-----------+--------------------+\n| 1         | no                 |\n| 2         | yes                |\n| 3         | yes                |\n| 4         | no                 |\n+-----------+--------------------+\n```\n\nid 为 1 的用户的查询结果是 no，因为他什么也没有卖出\n\nid为 2 和 3 的用户的查询结果是 yes，因为他们卖出的第二件商品的品牌是他们自己最喜爱的品牌\n\nid为 4 的用户的查询结果是 no，因为他卖出的第二件商品的品牌不是他最喜爱的品牌\n\n','examDataFiles/auto_upload_1269_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1269_1637126775642.sql',3,1,0),(1278,'0','指定日期的产品价格','产品数据表: Products\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| new_price     | int     |\n| change_date   | date    |\n+---------------+---------+\n```\n\n这张表的主键是 (product_id, change_date)。\n\n这张表的每一行分别记录了 某产品 在某个日期 更改后 的新价格。\n\n写一段 SQL来查找在2019-08-16 时全部产品的价格，假设所有产品在修改前的价格都是10。\n\n查询结果格式如下例所示：\n\nProducts table:\n\n```\n+------------+-----------+-------------+\n| product_id | new_price | change_date |\n+------------+-----------+-------------+\n| 1          | 20        | 2019-08-14  |\n| 2          | 50        | 2019-08-14  |\n| 1          | 30        | 2019-08-15  |\n| 1          | 35        | 2019-08-16  |\n| 2          | 65        | 2019-08-17  |\n| 3          | 20        | 2019-08-18  |\n+------------+-----------+-------------+\n```\n\nResult table:\n\n```\n+------------+-------+\n| product_id | price |\n+------------+-------+\n| 2          | 50    |\n| 1          | 35    |\n| 3          | 10    |\n+------------+-------+\n```\n\n','examDataFiles/auto_upload_1278_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1278_1637126775642.sql',2,1,0),(1291,'0','即时食物配送 I','配送表: Delivery\n\n```\n+-----------------------------+---------+\n| Column Name                 | Type    |\n+-----------------------------+---------+\n| delivery_id                 | int     |\n| customer_id                 | int     |\n| order_date                  | date    |\n| customer_pref_delivery_date | date    |\n+-----------------------------+---------+\n```\n\ndelivery_id 是表的主键。\n\n该表保存着顾客的食物配送信息，顾客在某个日期下了订单，并指定了一个期望的配送日期（和下单日期相同或者在那之后）。\n\n如果顾客期望的配送日期和下单日期相同，则该订单称为 「即时订单」，否则称为「计划订单」。\n\n写一条 SQL查询语句获取即时订单所占的百分比，保留两位小数。\n\n查询结果如下所示：\n\nDelivery 表:\n\n```\n+-------------+-------------+------------+-----------------------------+\n| delivery_id | customer_id | order_date | customer_pref_delivery_date |\n+-------------+-------------+------------+-----------------------------+\n| 1           | 1           | 2019-08-01 | 2019-08-02                  |\n| 2           | 5           | 2019-08-02 | 2019-08-02                  |\n| 3           | 1           | 2019-08-11 | 2019-08-11                  |\n| 4           | 3           | 2019-08-24 | 2019-08-26                  |\n| 5           | 4           | 2019-08-21 | 2019-08-22                  |\n| 6           | 2           | 2019-08-11 | 2019-08-13                  |\n+-------------+-------------+------------+-----------------------------+\n```\n\nResult 表:\n\n```\n+----------------------+\n| immediate_percentage |\n+----------------------+\n| 33.33                |\n+----------------------+\n```\n\n2 和 3 号订单为即时订单，其他的为计划订单。\n\n','examDataFiles/auto_upload_1291_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1291_1637126775642.sql',1,1,0),(1292,'0','即时食物配送 II','配送表: Delivery\n\n```\n+-----------------------------+---------+\n| Column Name                 | Type    |\n+-----------------------------+---------+\n| delivery_id                 | int     |\n| customer_id                 | int     |\n| order_date                  | date    |\n| customer_pref_delivery_date | date    |\n+-----------------------------+---------+\n```\n\ndelivery_id 是表的主键。\n\n该表保存着顾客的食物配送信息，顾客在某个日期下了订单，并指定了一个期望的配送日期（和下单日期相同或者在那之后）。\n\n如果顾客期望的配送日期和下单日期相同，则该订单称为 「即时订单」，否则称为「计划订单」。\n\n「首次订单」是顾客最早创建的订单。我们保证一个顾客只会有一个「首次订单」。\n\n写一条 SQL 查询语句获取即时订单在所有用户的首次订单中的比例。保留两位小数。\n\n查询结果如下所示：\n\nDelivery 表：\n\n```\n+-------------+-------------+------------+-----------------------------+\n| delivery_id | customer_id | order_date | customer_pref_delivery_date |\n+-------------+-------------+------------+-----------------------------+\n| 1           | 1           | 2019-08-01 | 2019-08-02                  |\n| 2           | 2           | 2019-08-02 | 2019-08-02                  |\n| 3           | 1           | 2019-08-11 | 2019-08-12                  |\n| 4           | 3           | 2019-08-24 | 2019-08-24                  |\n| 5           | 3           | 2019-08-21 | 2019-08-22                  |\n| 6           | 2           | 2019-08-11 | 2019-08-13                  |\n| 7           | 4           | 2019-08-09 | 2019-08-09                  |\n+-------------+-------------+------------+-----------------------------+\n```\n\nResult 表：\n\n```\n+----------------------+\n| immediate_percentage |\n+----------------------+\n| 50.00                |\n+----------------------+\n```\n\n1 号顾客的 1 号订单是首次订单，并且是计划订单。\n\n2 号顾客的 2 号订单是首次订单，并且是即时订单。\n\n3 号顾客的 5 号订单是首次订单，并且是计划订单。\n\n4 号顾客的 7 号订单是首次订单，并且是即时订单。\n\n因此，一半顾客的首次订单是即时的。\n\n','examDataFiles/auto_upload_1292_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1292_1637126775642.sql',2,1,0),(1301,'0','重新格式化部门表','部门表Department：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| revenue       | int     |\n| month         | varchar |\n+---------------+---------+\n```\n\n(id, month) 是表的联合主键。\n\n这个表格有关于每个部门每月收入的信息。\n\n月份（month）可以取下列值 [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]。\n\n编写一个 SQL 查询来重新格式化表，使得新的表中有一个部门 id 列和一些对应每个月 的收入（revenue）列。\n\n查询结果格式如下面的示例所示：\n\nDepartment 表：\n\n```\n+------+---------+-------+\n| id   | revenue | month |\n+------+---------+-------+\n| 1    | 8000    | Jan   |\n| 2    | 9000    | Jan   |\n| 3    | 10000   | Feb   |\n| 1    | 7000    | Feb   |\n| 1    | 6000    | Mar   |\n+------+---------+-------+\n```\n\n查询得到的结果表：\n\n```\n+------+-------------+-------------+-------------+-----+-------------+\n| id   | Jan_Revenue | Feb_Revenue | Mar_Revenue | ... | Dec_Revenue |\n+------+-------------+-------------+-------------+-----+-------------+\n| 1    | 8000        | 7000        | 6000        | ... | null        |\n| 2    | 9000        | null        | null        | ... | null        |\n| 3    | null        | 10000       | null        | ... | null        |\n+------+-------------+-------------+-------------+-----+-------------+\n```\n\n注意，结果表有 13 列 (1个部门 id 列 + 12个月份的收入列)。\n\n','examDataFiles/auto_upload_1301_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1301_1637126775642.sql',1,1,0),(1317,'0','每月交易 I','Table: Transactions\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| country       | varchar |\n| state         | enum    |\n| amount        | int     |\n| trans_date    | date    |\n+---------------+---------+\n```\n\nid 是这个表的主键。\n\n该表包含有关传入事务的信息。\n\nstate 列类型为 “[”批准“，”拒绝“] 之一。\n\n编写一个 sql 查询来查找每个月和每个国家/地区的事务数及其总金额、已批准的事务数及其总金额。\n\n查询结果格式如下所示：\n\nTransactions table:\n\n```\n+------+---------+----------+--------+------------+\n| id   | country | state    | amount | trans_date |\n+------+---------+----------+--------+------------+\n| 121  | US      | approved | 1000   | 2018-12-18 |\n| 122  | US      | declined | 2000   | 2018-12-19 |\n| 123  | US      | approved | 2000   | 2019-01-01 |\n| 124  | DE      | approved | 2000   | 2019-01-07 |\n+------+---------+----------+--------+------------+\n```\n\nResult table:\n\n```\n+----------+---------+-------------+----------------+--------------------+-----------------------+\n| month    | country | trans_count | approved_count | trans_total_amount | approved_total_amount |\n+----------+---------+-------------+----------------+--------------------+-----------------------+\n| 2018-12  | US      | 2           | 1              | 3000               | 1000                  |\n| 2019-01  | US      | 1           | 1              | 2000               | 2000                  |\n| 2019-01  | DE      | 1           | 1              | 2000               | 2000                  |\n+----------+---------+-------------+----------------+--------------------+-----------------------+\n```\n\n','examDataFiles/auto_upload_1317_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1317_1637126775642.sql',2,1,0),(1318,'0','锦标赛优胜者','Players玩家表\n\n```\n+-------------+-------+\n| Column Name | Type  |\n+-------------+-------+\n| player_id   | int   |\n| group_id    | int   |\n+-------------+-------+\n```\n\nplayer_id 是此表的主键。\n\n此表的每一行表示每个玩家的组。\n\nMatches赛事表\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| match_id      | int     |\n| first_player  | int     |\n| second_player | int     | \n| first_score   | int     |\n| second_score  | int     |\n+---------------+---------+\n```\n\nmatch_id 是此表的主键。\n\n每一行是一场比赛的记录，first_player 和 second_player 表示该场比赛的球员 ID。\n\nfirst_score 和 second_score 分别表示 first_player 和 second_player 的得分。\n\n你可以假设，在每一场比赛中，球员都属于同一组。\n\n每组的获胜者是在组内累积得分最高的选手。如果平局，player_id 最小的选手获胜。\n\n编写一个 SQL 查询来查找每组中的获胜者。\n\n查询结果格式如下所示\n\nPlayers 表:\n\n```\n+-----------+------------+\n| player_id | group_id   |\n+-----------+------------+\n| 15        | 1          |\n| 25        | 1          |\n| 30        | 1          |\n| 45        | 1          |\n| 10        | 2          |\n| 35        | 2          |\n| 50        | 2          |\n| 20        | 3          |\n| 40        | 3          |\n+-----------+------------+\n```\n\nMatches 表:\n\n```\n+------------+--------------+---------------+-------------+--------------+\n| match_id   | first_player | second_player | first_score | second_score |\n+------------+--------------+---------------+-------------+--------------+\n| 1          | 15           | 45            | 3           | 0            |\n| 2          | 30           | 25            | 1           | 2            |\n| 3          | 30           | 15            | 2           | 0            |\n| 4          | 40           | 20            | 5           | 2            |\n| 5          | 35           | 50            | 1           | 1            |\n+------------+--------------+---------------+-------------+--------------+\n```\n\nResult 表:\n\n```\n+-----------+------------+\n| group_id  | player_id  |\n+-----------+------------+ \n| 1         | 15         |\n| 2         | 35         |\n| 3         | 40         |\n+-----------+------------+\n```\n\n','examDataFiles/auto_upload_1318_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1318_1637126775642.sql',3,1,0),(1327,'0','最后一个能进入电梯的人','表: Queue\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| person_id   | int     |\n| person_name | varchar |\n| weight      | int     |\n| turn        | int     |\n+-------------+---------+\n```\n\nperson_id 是这个表的主键。\n\n该表展示了所有等待电梯的人的信息。\n\n表中 person_id 和 turn 列将包含从 1 到 n 的所有数字，其中 n 是表中的行数。\n\n电梯最大载重量为 1000。\n\n写一条 SQL 查询语句查找最后一个能进入电梯且不超过重量限制的 person_name 。题目确保队列中第一位的人可以进入电梯 。\n\n查询结果如下所示 :\n\nQueue 表\n\n```\n+-----------+-------------------+--------+------+\n| person_id | person_name       | weight | turn |\n+-----------+-------------------+--------+------+\n| 5         | George Washington | 250    | 1    |\n| 3         | John Adams        | 350    | 2    |\n| 6         | Thomas Jefferson  | 400    | 3    |\n| 2         | Will Johnliams    | 200    | 4    |\n| 4         | Thomas Jefferson  | 175    | 5    |\n| 1         | James Elephant    | 500    | 6    |\n+-----------+-------------------+--------+------+\n```\n\nResult 表\n\n```\n+-------------------+\n| person_name       |\n+-------------------+\n| Thomas Jefferson  |\n+-------------------+\n```\n\n为了简化，Queue 表按 turn 列由小到大排序。\n\n上例中 George Washington(id 5), John Adams(id 3) 和 Thomas Jefferson(id 6) 将可以进入电梯,因为他们的体重和为 250 + 350 + 400 = 1000。\n\nThomas Jefferson(id 6) 是最后一个体重合适并进入电梯的人。\n\n','examDataFiles/auto_upload_1327_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1327_1637126775642.sql',2,1,0),(1328,'0','每月交易II','Transactions 记录表\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| id             | int     |\n| country        | varchar |\n| state          | enum    |\n| amount         | int     |\n| trans_date     | date    |\n+----------------+---------+\n```\n\nid 是这个表的主键。\n\n该表包含有关传入事务的信息。\n\n状态列是类型为 [approved（已批准）、declined（已拒绝）] 的枚举。\n\nChargebacks 表\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| trans_id       | int     |\n| trans_date     | date    |\n+----------------+---------+\n```\n\n退单包含有关放置在事务表中的某些事务的传入退单的基本信息。\n\ntrans_id 是 transactions 表的 id 列的外键。\n\n每项退单都对应于之前进行的交易，即使未经批准。\n\n编写一个 SQL查询，以查找每个月和每个国家/地区的信息：已批准交易的数量及其总金额、退单的数量及其总金额。\n\n注意：在您的查询中，只需显示给定月份和国家，忽略所有为零的行。\n\n查询结果格式如下所示：\n\nTransactions 表：\n\n```\n+-----+---------+----------+--------+------------+\n| id  | country | state    | amount | trans_date |\n+-----+---------+----------+--------+------------+\n| 101 | US      | approved | 1000   | 2019-05-18 |\n| 102 | US      | declined | 2000   | 2019-05-19 |\n| 103 | US      | approved | 3000   | 2019-06-10 |\n| 104 | US      | declined | 4000   | 2019-06-13 |\n| 105 | US      | approved | 5000   | 2019-06-15 |\n+-----+---------+----------+--------+------------+\n```\n\nChargebacks 表：\n\n```\n+----------+------------+\n| trans_id | trans_date |\n+----------+------------+\n| 102      | 2019-05-29 |\n| 101      | 2019-06-30 |\n| 105      | 2019-09-18 |\n+----------+------------+\n```\n\nResult 表：\n\n```\n+---------+---------+----------------+-----------------+------------------+-------------------+\n| month   | country | approved_count | approved_amount | chargeback_count | chargeback_amount |\n+---------+---------+----------------+-----------------+------------------+-------------------+\n| 2019-05 | US      | 1              | 1000            | 1                | 2000              |\n| 2019-06 | US      | 2              | 8000            | 1                | 1000              |\n| 2019-09 | US      | 0              | 0               | 1                | 5000              |\n+---------+---------+----------------+-----------------+------------------+-------------------+\n```\n\n','examDataFiles/auto_upload_1328_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1328_1637126775642.sql',2,1,0),(1338,'0','查询结果的质量和占比','查询表 Queries：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| query_name  | varchar |\n| result      | varchar |\n| position    | int     |\n| rating      | int     |\n+-------------+---------+\n```\n\n此表没有主键，并可能有重复的行。\n\n此表包含了一些从数据库中收集的查询信息。\n\n“位置”（position）列的值为 1 到 500 。\n\n“评分”（rating）列的值为 1 到 5 。评分小于 3 的查询被定义为质量很差的查询。\n\n将查询结果的质量 quality 定义为：\n\n各查询结果的评分与其位置之间比率的平均值。\n\n将劣质查询百分比poor_query_percentage 为：\n\n评分小于 3 的查询结果占全部查询结果的百分比。\n\n编写一组 SQL 来查找每次查询的名称(query_name)、质量(quality) 和劣质查询百分比(poor_query_percentage)。\n\n质量(quality) 和劣质查询百分比(poor_query_percentage) 都应四舍五入到小数点后两位。\n\n查询结果格式如下所示：\n\nQueries table:\n\n```\n+------------+-------------------+----------+--------+\n| query_name | result            | position | rating |\n+------------+-------------------+----------+--------+\n| Dog        | Golden Retriever  | 1        | 5      |\n| Dog        | German Shepherd   | 2        | 5      |\n| Dog        | Mule              | 200      | 1      |\n| Cat        | Shirazi           | 5        | 2      |\n| Cat        | Siamese           | 3        | 3      |\n| Cat        | Sphynx            | 7        | 4      |\n+------------+-------------------+----------+--------+\n```\n\nResult table:\n\n```\n+------------+---------+-----------------------+\n| query_name | quality | poor_query_percentage |\n+------------+---------+-----------------------+\n| Dog        | 2.50    | 33.33                 |\n| Cat        | 0.66    | 33.33                 |\n+------------+---------+-----------------------+\n```\n\nDog 查询结果的质量为 ((5 / 1) + (5 / 2) + (1 / 200)) / 3 = 2.50\n\nDog 查询结果的劣质查询百分比为 (1 / 3) * 100 = 33.33\n\nCat 查询结果的质量为 ((2 / 5) + (3 / 3) + (4 / 7)) / 3 = 0.66\n\nCat 查询结果的劣质查询百分比为 (1 / 3) * 100 = 33.33\n\n','examDataFiles/auto_upload_1338_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1338_1637126775642.sql',1,1,0),(1339,'0','查询球队积分','Table: Teams\n\n```\n+---------------+----------+\n| Column Name   | Type     |\n+---------------+----------+\n| team_id       | int      |\n| team_name     | varchar  |\n+---------------+----------+\n```\n\n此表的主键是 team_id，表中的每一行都代表一支独立足球队。\n\nTable:Matches\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| match_id      | int     |\n| host_team     | int     |\n| guest_team    | int     | \n| host_goals    | int     |\n| guest_goals   | int     |\n+---------------+---------+\n```\n\n此表的主键是 match_id，表中的每一行都代表一场已结束的比赛，比赛的主客队分别由它们自己的 id 表示，他们的进球由 host_goals 和 guest_goals 分别表示。\n\n积分规则如下：\n\n赢一场得三分；\n\n平一场得一分；\n\n输一场不得分。\n\n写出一条SQL语句以查询每个队的team_id，team_name 和 num_points。结果根据num_points 降序排序，如果有两队积分相同，那么这两队按team_id 升序排序。\n\n查询结果格式如下：\n\nTeams table:\n\n```\n+-----------+--------------+\n| team_id   | team_name    |\n+-----------+--------------+\n| 10        | Leetcode FC  |\n| 20        | NewYork FC   |\n| 30        | Atlanta FC   |\n| 40        | Chicago FC   |\n| 50        | Toronto FC   |\n+-----------+--------------+\n```\n\nMatches table:\n\n```\n+------------+--------------+---------------+-------------+--------------+\n| match_id   | host_team    | guest_team    | host_goals  | guest_goals  |\n+------------+--------------+---------------+-------------+--------------+\n| 1          | 10           | 20            | 3           | 0            |\n| 2          | 30           | 10            | 2           | 2            |\n| 3          | 10           | 50            | 5           | 1            |\n| 4          | 20           | 30            | 1           | 0            |\n| 5          | 50           | 30            | 1           | 0            |\n+------------+--------------+---------------+-------------+--------------+\n```\n\nResult table:\n\n```\n+------------+--------------+---------------+\n| team_id    | team_name    | num_points    |\n+------------+--------------+---------------+\n| 10         | Leetcode FC  | 7             |\n| 20         | NewYork FC   | 3             |\n| 50         | Toronto FC   | 3             |\n| 30         | Atlanta FC   | 1             |\n| 40         | Chicago FC   | 0             |\n+------------+--------------+---------------+\n```\n\n','examDataFiles/auto_upload_1339_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1339_1637126775642.sql',2,1,0),(1357,'0','报告系统状态的连续日期','Table: Failed\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| fail_date    | date    |\n+--------------+---------+\n```\n\n该表主键为 fail_date。\n\n该表包含失败任务的天数.\n\nTable: Succeeded\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| success_date | date    |\n+--------------+---------+\n```\n\n该表主键为 success_date。\n\n该表包含成功任务的天数.\n\n系统 每天 运行一个任务。每个任务都独立于先前的任务。任务的状态可以是失败或是成功。\n\n编写一个 SQL 查询2019-01-01到2019-12-31 期间任务连续同状态period_state的起止日期（start_date 和 end_date）。即如果任务失败了，就是失败状态的起止日期，如果任务成功了，就是成功状态的起止日期。\n\n最后结果按照起始日期start_date排序\n\n查询结果样例如下所示:\n\nFailed table:\n\n```\n+-------------------+\n| fail_date         |\n+-------------------+\n| 2018-12-28        |\n| 2018-12-29        |\n| 2019-01-04        |\n| 2019-01-05        |\n+-------------------+\n```\n\nSucceeded table:\n\n```\n+-------------------+\n| success_date      |\n+-------------------+\n| 2018-12-30        |\n| 2018-12-31        |\n| 2019-01-01        |\n| 2019-01-02        |\n| 2019-01-03        |\n| 2019-01-06        |\n+-------------------+\n```\n\nResult table:\n\n```\n+--------------+--------------+--------------+\n| period_state | start_date   | end_date     |\n+--------------+--------------+--------------+\n| succeeded    | 2019-01-01   | 2019-01-03   |\n| failed       | 2019-01-04   | 2019-01-05   |\n| succeeded    | 2019-01-06   | 2019-01-06   |\n+--------------+--------------+--------------+\n```\n\n结果忽略了 2018 年的记录，因为我们只关心从 2019-01-01 到 2019-12-31 的记录\n\n从 2019-01-01 到 2019-01-03 所有任务成功，系统状态为 \"succeeded\"。\n\n从 2019-01-04 到 2019-01-05 所有任务失败，系统状态为 \"failed\"。\n\n从 2019-01-06 到 2019-01-06 所有任务成功，系统状态为 \"succeeded\"。\n\n','examDataFiles/auto_upload_1357_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1357_1637126775642.sql',3,1,0),(1377,'0','每个帖子的评论数','表Submissions 结构如下：\n\n```\n+---------------+----------+\n| 列名           | 类型     |\n+---------------+----------+\n| sub_id        | int      |\n| parent_id     | int      |\n+---------------+----------+\n```\n\n上表没有主键, 所以可能会出现重复的行。\n\n每行可以是一个帖子或对该帖子的评论。\n\n如果是帖子的话，parent_id 就是 null。\n\n对于评论来说，parent_id 就是表中对应帖子的 sub_id。\n\n编写 SQL 语句以查找每个帖子的评论数。\n\n结果表应包含帖子的post_id 和对应的评论数number_of_comments 并且按post_id升序排列。\n\nSubmissions 可能包含重复的评论。您应该计算每个帖子的唯一评论数。\n\nSubmissions 可能包含重复的帖子。您应该将它们视为一个帖子。\n\n查询结果格式如下例所示：\n\nSubmissions table:\n\n```\n+---------+------------+\n| sub_id  | parent_id  |\n+---------+------------+\n| 1       | Null       |\n| 2       | Null       |\n| 1       | Null       |\n| 12      | Null       |\n| 3       | 1          |\n| 5       | 2          |\n| 3       | 1          |\n| 4       | 1          |\n| 9       | 1          |\n| 10      | 2          |\n| 6       | 7          |\n+---------+------------+\n```\n\n结果表：\n\n```\n+---------+--------------------+\n| post_id | number_of_comments |\n+---------+--------------------+\n| 1       | 3                  |\n| 2       | 2                  |\n| 12      | 0                  |\n+---------+--------------------+\n```\n\n表中 ID 为 1 的帖子有 ID 为 3、4 和 9 的三个评论。表中 ID 为 3 的评论重复出现了，所以我们只对它进行了一次计数。\n\n表中 ID 为 2 的帖子有 ID 为 5 和 10 的两个评论。\n\nID 为 12 的帖子在表中没有评论。\n\n表中 ID 为 6 的评论是对 ID 为 7 的已删除帖子的评论，因此我们将其忽略。\n\n','examDataFiles/auto_upload_1377_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1377_1637126775642.sql',1,1,0),(1390,'0','平均售价','Table: Prices\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| start_date    | date    |\n| end_date      | date    |\n| price         | int     |\n+---------------+---------+\n```\n\n(product_id，start_date，end_date) 是 Prices 表的主键。\n\nPrices 表的每一行表示的是某个产品在一段时期内的价格。\n\n每个产品的对应时间段是不会重叠的，这也意味着同一个产品的价格时段不会出现交叉。\n\nTable: UnitsSold\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| purchase_date | date    |\n| units         | int     |\n+---------------+---------+\n```\n\nUnitsSold 表没有主键，它可能包含重复项。\n\nUnitsSold 表的每一行表示的是每种产品的出售日期，单位和产品 id。\n\n编写SQL查询以查找每种产品的平均售价。\n\naverage_price 应该四舍五入到小数点后两位。\n\n查询结果格式如下例所示：\n\nPrices table:\n\n```\n+------------+------------+------------+--------+\n| product_id | start_date | end_date   | price  |\n+------------+------------+------------+--------+\n| 1          | 2019-02-17 | 2019-02-28 | 5      |\n| 1          | 2019-03-01 | 2019-03-22 | 20     |\n| 2          | 2019-02-01 | 2019-02-20 | 15     |\n| 2          | 2019-02-21 | 2019-03-31 | 30     |\n+------------+------------+------------+--------+\n```\n\n \n\nUnitsSold table:\n\n```\n+------------+---------------+-------+\n| product_id | purchase_date | units |\n+------------+---------------+-------+\n| 1          | 2019-02-25    | 100   |\n| 1          | 2019-03-01    | 15    |\n| 2          | 2019-02-10    | 200   |\n| 2          | 2019-03-22    | 30    |\n+------------+---------------+-------+\n```\n\nResult table:\n\n```\n+------------+---------------+\n| product_id | average_price |\n+------------+---------------+\n| 1          | 6.96          |\n| 2          | 16.96         |\n+------------+---------------+\n```\n\n平均售价 = 产品总价 / 销售的产品数量。\n\n产品 1 的平均售价 = ((100 * 5)+(15 * 20) )/ 115 = 6.96\n\n产品 2 的平均售价 = ((200 * 15)+(30 * 30) )/ 230 = 16.96\n\n','examDataFiles/auto_upload_1390_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1390_1637126775642.sql',1,1,0),(1399,'0','页面推荐','朋友关系列表：Friendship\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user1_id      | int     |\n| user2_id      | int     |\n+---------------+---------+\n```\n\n这张表的主键是 (user1_id, user2_id)。\n\n这张表的每一行代表着 user1_id 和 user2_id 之间存在着朋友关系。\n\n喜欢列表：Likes\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| user_id     | int     |\n| page_id     | int     |\n+-------------+---------+\n```\n\n这张表的主键是 (user_id, page_id)。\n\n这张表的每一行代表着 user_id 喜欢 page_id。\n\n写一段 SQL 向user_id = 1 的用户，推荐其朋友们喜欢的页面。不要推荐该用户已经喜欢的页面。\n\n你返回的结果中不应当包含重复项。\n\n返回结果的格式如下例所示：\n\nFriendship table:\n\n```\n+----------+----------+\n| user1_id | user2_id |\n+----------+----------+\n| 1        | 2        |\n| 1        | 3        |\n| 1        | 4        |\n| 2        | 3        |\n| 2        | 4        |\n| 2        | 5        |\n| 6        | 1        |\n+----------+----------+\n```\n\n \n\nLikes table:\n\n```\n+---------+---------+\n| user_id | page_id |\n+---------+---------+\n| 1       | 88      |\n| 2       | 23      |\n| 3       | 24      |\n| 4       | 56      |\n| 5       | 11      |\n| 6       | 33      |\n| 2       | 77      |\n| 3       | 77      |\n| 6       | 88      |\n+---------+---------+\n```\n\nResult table:\n\n```\n+------------------+\n| recommended_page |\n+------------------+\n| 23               |\n| 24               |\n| 56               |\n| 33               |\n| 77               |\n+------------------+\n```\n\n用户1 同 用户2, 3, 4, 6 是朋友关系。\n\n推荐页面为： 页面23 来自于 用户2, 页面24 来自于 用户3, 页面56 来自于 用户3 以及 页面33 来自于 用户6。\n\n页面77 同时被 用户2 和 用户3 推荐。\n\n页面88 没有被推荐，因为 用户1 已经喜欢了它。\n\n','examDataFiles/auto_upload_1399_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1399_1637126775642.sql',2,1,0),(1405,'0','向公司CEO汇报工作的所有人','员工表：Employees\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| employee_id   | int     |\n| employee_name | varchar |\n| manager_id    | int     |\n+---------------+---------+\n```\n\nemployee_id 是这个表的主键。\n\n这个表中每一行中，employee_id 表示职工的 ID，employee_name 表示职工的名字，manager_id 表示该职工汇报工作的直线经理。\n\n这个公司 CEO 是 employee_id = 1 的人。\n\n用 SQL 查询出所有直接或间接向公司 CEO 汇报工作的职工的 employee_id 。\n\n由于公司规模较小，经理之间的间接关系不超过 3 个经理。\n\n可以以任何顺序返回无重复项的结果。\n\n查询结果示例如下：\n\nEmployees table:\n\n```\n+-------------+---------------+------------+\n| employee_id | employee_name | manager_id |\n+-------------+---------------+------------+\n| 1           | Boss          | 1          |\n| 3           | Alice         | 3          |\n| 2           | Bob           | 1          |\n| 4           | Daniel        | 2          |\n| 7           | Luis          | 4          |\n| 8           | Jhon          | 3          |\n| 9           | Angela        | 8          |\n| 77          | Robert        | 1          |\n+-------------+---------------+------------+\n```\n\nResult table:\n\n```\n+-------------+\n| employee_id |\n+-------------+\n| 2           |\n| 77          |\n| 4           |\n| 7           |\n+-------------+\n```\n\n公司 CEO 的 employee_id 是 1.\n\nemployee_id 是 2 和 77 的职员直接汇报给公司 CEO。\n\nemployee_id 是 4 的职员间接汇报给公司 CEO 4 --> 2 --> 1 。\n\nemployee_id 是 7 的职员间接汇报给公司 CEO 7 --> 4 --> 2 --> 1 。\n\nemployee_id 是 3, 8 ，9 的职员不会直接或间接的汇报给公司 CEO。 \n\n','examDataFiles/auto_upload_1405_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1405_1637126775642.sql',2,1,0),(1415,'0','学生们参加各科测试的次数','学生表: Students\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| student_id    | int     |\n| student_name  | varchar |\n+---------------+---------+\n```\n\n主键为 student_id（学生ID），该表内的每一行都记录有学校一名学生的信息。\n\n科目表: Subjects\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| subject_name | varchar |\n+--------------+---------+\n```\n\n主键为 subject_name（科目名称），每一行记录学校的一门科目名称。\n\n考试表: Examinations\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| student_id   | int     |\n| subject_name | varchar |\n+--------------+---------+\n```\n\n这张表压根没有主键，可能会有重复行。\n\n学生表里的一个学生修读科目表里的每一门科目，而这张考试表的每一行记录就表示学生表里的某个学生参加了一次科目表里某门科目的测试。\n\n要求写一段 SQL 语句，查询出每个学生参加每一门科目测试的次数，结果按 student_id 和 subject_name 排序。\n\n查询结构格式如下所示：\n\nStudents table:\n\n```\n+------------+--------------+\n| student_id | student_name |\n+------------+--------------+\n| 1          | Alice        |\n| 2          | Bob          |\n| 13         | John         |\n| 6          | Alex         |\n+------------+--------------+\n```\n\nSubjects table:\n\n```\n+--------------+\n| subject_name |\n+--------------+\n| Math         |\n| Physics      |\n| Programming  |\n+--------------+\n```\n\nExaminations table:\n\n```\n+------------+--------------+\n| student_id | subject_name |\n+------------+--------------+\n| 1          | Math         |\n| 1          | Physics      |\n| 1          | Programming  |\n| 2          | Programming  |\n| 1          | Physics      |\n| 1          | Math         |\n| 13         | Math         |\n| 13         | Programming  |\n| 13         | Physics      |\n| 2          | Math         |\n| 1          | Math         |\n+------------+--------------+\n```\n\nResult table:\n\n```\n+------------+--------------+--------------+----------------+\n| student_id | student_name | subject_name | attended_exams |\n+------------+--------------+--------------+----------------+\n| 1          | Alice        | Math         | 3              |\n| 1          | Alice        | Physics      | 2              |\n| 1          | Alice        | Programming  | 1              |\n| 2          | Bob          | Math         | 1              |\n| 2          | Bob          | Physics      | 0              |\n| 2          | Bob          | Programming  | 1              |\n| 6          | Alex         | Math         | 0              |\n| 6          | Alex         | Physics      | 0              |\n| 6          | Alex         | Programming  | 0              |\n| 13         | John         | Math         | 1              |\n| 13         | John         | Physics      | 1              |\n| 13         | John         | Programming  | 1              |\n+------------+--------------+--------------+----------------+\n```\n\n结果表需包含所有学生和所有科目（即便测试次数为0）：\n\nAlice 参加了 3 次数学测试, 2 次物理测试，以及 1 次编程测试；\n\nBob 参加了 1 次数学测试, 1 次编程测试，没有参加物理测试；\n\nAlex 啥测试都没参加；\n\nJohn  参加了数学、物理、编程测试各 1 次。\n\n','examDataFiles/auto_upload_1415_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1415_1637126775642.sql',1,1,0),(1420,'0','找到连续区间的开始和结束数字','表：Logs\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| log_id        | int     |\n+---------------+---------+\n```\n\nid 是上表的主键。\n\n上表的每一行包含日志表中的一个 ID。\n\n后来一些 ID 从Logs表中删除。编写一个 SQL 查询得到Logs表中的连续区间的开始数字和结束数字。\n\n将查询表按照 start_id排序。\n\n查询结果格式如下面的例子：\n\nLogs 表：\n\n```\n+------------+\n| log_id     |\n+------------+\n| 1          |\n| 2          |\n| 3          |\n| 7          |\n| 8          |\n| 10         |\n+------------+\n```\n\n结果表：\n\n```\n+------------+--------------+\n| start_id   | end_id       |\n+------------+--------------+\n| 1          | 3            |\n| 7          | 8            |\n| 10         | 10           |\n+------------+--------------+\n```\n\n结果表应包含 Logs 表中的所有区间。\n\n从 1 到 3 在表中。\n\n从 4 到 6 不在表中。\n\n从 7 到 8 在表中。\n\n9 不在表中。\n\n10 在表中。\n\n','examDataFiles/auto_upload_1420_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1420_1637126775642.sql',2,1,0),(1425,'0','不同国家的天气类型','国家表：Countries\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| country_id    | int     |\n| country_name  | varchar |\n+---------------+---------+\n```\n\ncountry_id 是这张表的主键。\n\n该表的每行有 country_id 和 country_name 两列。\n\n天气表：Weather\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| country_id    | int     |\n| weather_state | varchar |\n| day           | date    |\n+---------------+---------+\n```\n\n(country_id, day) 是该表的复合主键。\n\n该表的每一行记录了某个国家某一天的天气情况。\n\n写一段 SQL 来找到表中每个国家在 2019 年 11 月的天气类型。\n\n天气类型的定义如下：当 weather_state 的平均值小于或等于15返回 Cold，当 weather_state 的平均值大于或等于 25 返回 Hot，否则返回Warm。\n\n你可以以任意顺序返回你的查询结果。\n\n查询结果格式如下所示：\n\nCountries table:\n\n```\n+------------+--------------+\n| country_id | country_name |\n+------------+--------------+\n| 2          | USA          |\n| 3          | Australia    |\n| 7          | Peru         |\n| 5          | China        |\n| 8          | Morocco      |\n| 9          | Spain        |\n+------------+--------------+\n```\n\nWeather table:\n\n```\n+------------+---------------+------------+\n| country_id | weather_state | day        |\n+------------+---------------+------------+\n| 2          | 15            | 2019-11-01 |\n| 2          | 12            | 2019-10-28 |\n| 2          | 12            | 2019-10-27 |\n| 3          | -2            | 2019-11-10 |\n| 3          | 0             | 2019-11-11 |\n| 3          | 3             | 2019-11-12 |\n| 5          | 16            | 2019-11-07 |\n| 5          | 18            | 2019-11-09 |\n| 5          | 21            | 2019-11-23 |\n| 7          | 25            | 2019-11-28 |\n| 7          | 22            | 2019-12-01 |\n| 7          | 20            | 2019-12-02 |\n| 8          | 25            | 2019-11-05 |\n| 8          | 27            | 2019-11-15 |\n| 8          | 31            | 2019-11-25 |\n| 9          | 7             | 2019-10-23 |\n| 9          | 3             | 2019-12-23 |\n+------------+---------------+------------+\n```\n\nResult table:\n\n```\n+--------------+--------------+\n| country_name | weather_type |\n+--------------+--------------+\n| USA          | Cold         |\n| Austraila    | Cold         |\n| Peru         | Hot          |\n| China        | Warm         |\n| Morocco      | Hot          |\n+--------------+--------------+\n```\n\nUSA 11 月的平均 weather_state 为 (15) / 1 = 15 所以天气类型为 Cold。\n\nAustralia 11 月的平均 weather_state 为 (-2 + 0 + 3) / 3 = 0.333 所以天气类型为 Cold。\n\nPeru 11 月的平均 weather_state 为 (25) / 1 = 25 所以天气类型为 Hot。\n\nChina 11 月的平均 weather_state 为 (16 + 18 + 21) / 3 = 18.333 所以天气类型为 Warm。\n\nMorocco 11 月的平均 weather_state 为 (25 + 27 + 31) / 3 = 27.667 所以天气类型为 Hot。\n\n我们并不知道 Spain 在 11 月的 weather_state 情况所以无需将他包含在结果中。\n\n','examDataFiles/auto_upload_1425_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1425_1637126775642.sql',1,1,0),(1438,'0','求团队人数','员工表：Employee\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| employee_id   | int     |\n| team_id       | int     |\n+---------------+---------+\n```\n\nemployee_id 字段是这张表的主键，表中的每一行都包含每个员工的 ID 和他们所属的团队。\n\n编写一个 SQL 查询，以求得每个员工所在团队的总人数。\n\n查询结果中的顺序无特定要求。\n\n查询结果格式示例如下：\n\nEmployee Table:\n\n```\n+-------------+------------+\n| employee_id | team_id    |\n+-------------+------------+\n|     1       |     8      |\n|     2       |     8      |\n|     3       |     8      |\n|     4       |     7      |\n|     5       |     9      |\n|     6       |     9      |\n+-------------+------------+\n```\n\nResult table:\n\n```\n+-------------+------------+\n| employee_id | team_size  |\n+-------------+------------+\n|     1       |     3      |\n|     2       |     3      |\n|     3       |     3      |\n|     4       |     1      |\n|     5       |     2      |\n|     6       |     2      |\n+-------------+------------+\n```\n\nID 为 1、2、3 的员工是 team_id 为 8 的团队的成员，\n\nID 为 4 的员工是 team_id 为 7 的团队的成员，\n\nID 为 5、6 的员工是 team_id 为 9 的团队的成员。\n\n','examDataFiles/auto_upload_1438_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1438_1637126775642.sql',1,1,0),(1439,'0','不同性别每日分数总计','表: Scores\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| player_name   | varchar |\n| gender        | varchar |\n| day           | date    |\n| score_points  | int     |\n+---------------+---------+\n```\n\n(gender, day)是该表的主键\n\n一场比赛是在女队和男队之间举行的\n\n该表的每一行表示一个名叫 (player_name) 性别为 (gender) 的参赛者在某一天获得了 (score_points) 的分数\n\n如果参赛者是女性，那么 gender 列为 \'F\'，如果参赛者是男性，那么 gender 列为 \'M\'\n\n写一条SQL语句查询每种性别在每一天的总分，并按性别和日期对查询结果排序\n\n下面是查询结果格式的例子：\n\nScores表:\n\n```\n+-------------+--------+------------+--------------+\n| player_name | gender | day        | score_points |\n+-------------+--------+------------+--------------+\n| Aron        | F      | 2020-01-01 | 17           |\n| Alice       | F      | 2020-01-07 | 23           |\n| Bajrang     | M      | 2020-01-07 | 7            |\n| Khali       | M      | 2019-12-25 | 11           |\n| Slaman      | M      | 2019-12-30 | 13           |\n| Joe         | M      | 2019-12-31 | 3            |\n| Jose        | M      | 2019-12-18 | 2            |\n| Priya       | F      | 2019-12-31 | 23           |\n| Priyanka    | F      | 2019-12-30 | 17           |\n+-------------+--------+------------+--------------+\n```\n\n结果表:\n\n```\n+--------+------------+-------+\n| gender | day        | total |\n+--------+------------+-------+\n| F      | 2019-12-30 | 17    |\n| F      | 2019-12-31 | 40    |\n| F      | 2020-01-01 | 57    |\n| F      | 2020-01-07 | 80    |\n| M      | 2019-12-18 | 2     |\n| M      | 2019-12-25 | 13    |\n| M      | 2019-12-30 | 26    |\n| M      | 2019-12-31 | 29    |\n| M      | 2020-01-07 | 36    |\n+--------+------------+-------+\n```\n\n女性队伍:\n\n第一天是 2019-12-30，Priyanka 获得 17 分，队伍的总分是 17 分\n\n第二天是 2019-12-31, Priya 获得 23 分，队伍的总分是 40 分\n\n第三天是 2020-01-01, Aron 获得 17 分，队伍的总分是 57 分\n\n第四天是 2020-01-07, Alice 获得 23 分，队伍的总分是 80 分\n\n男性队伍：\n\n第一天是 2019-12-18, Jose 获得 2 分，队伍的总分是 2 分\n\n第二天是 2019-12-25, Khali 获得 11 分，队伍的总分是 13 分\n\n第三天是 2019-12-30, Slaman 获得 13 分，队伍的总分是 26 分\n\n第四天是 2019-12-31, Joe 获得 3 分，队伍的总分是 29 分\n\n第五天是 2020-01-07, Bajrang 获得 7 分，队伍的总分是 36 分\n\n','examDataFiles/auto_upload_1439_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1439_1637126775642.sql',2,1,0),(1452,'0','餐馆营业额变化增长','表: Customer\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n| visited_on    | date    |\n| amount        | int     |\n+---------------+---------+\n```\n\n(customer_id, visited_on) 是该表的主键\n\n该表包含一家餐馆的顾客交易数据\n\nvisited_on 表示 (customer_id) 的顾客在 visited_on 那天访问了餐馆\n\namount 是一个顾客某一天的消费总额\n\n你是餐馆的老板，现在你想分析一下可能的营业额变化增长（每天至少有一位顾客）\n\n写一条 SQL 查询计算以 7 天（某日期 + 该日期前的 6 天）为一个时间段的顾客消费平均值\n\n查询结果格式的例子如下：\n\n查询结果按 visited_on 排序\n\naverage_amount要 保留两位小数，日期数据的格式为(\'YYYY-MM-DD\')\n\nCustomer 表:\n\n```\n+-------------+--------------+--------------+-------------+\n| customer_id | name         | visited_on   | amount      |\n+-------------+--------------+--------------+-------------+\n| 1           | Jhon         | 2019-01-01   | 100         |\n| 2           | Daniel       | 2019-01-02   | 110         |\n| 3           | Jade         | 2019-01-03   | 120         |\n| 4           | Khaled       | 2019-01-04   | 130         |\n| 5           | Winston      | 2019-01-05   | 110         | \n| 6           | Elvis        | 2019-01-06   | 140         | \n| 7           | Anna         | 2019-01-07   | 150         |\n| 8           | Maria        | 2019-01-08   | 80          |\n| 9           | Jaze         | 2019-01-09   | 110         | \n| 1           | Jhon         | 2019-01-10   | 130         | \n| 3           | Jade         | 2019-01-10   | 150         | \n+-------------+--------------+--------------+-------------+\n```\n\n结果表:\n\n```\n+--------------+--------------+----------------+\n| visited_on   | amount       | average_amount |\n+--------------+--------------+----------------+\n| 2019-01-07   | 860          | 122.86         |\n| 2019-01-08   | 840          | 120            |\n| 2019-01-09   | 840          | 120            |\n| 2019-01-10   | 1000         | 142.86         |\n+--------------+--------------+----------------+\n```\n\n第一个七天消费平均值从 2019-01-01 到 2019-01-07 是 (100 + 110 + 120 + 130 + 110 + 140 + 150)/7 = 122.86\n\n第二个七天消费平均值从 2019-01-02 到 2019-01-08 是 (110 + 120 + 130 + 110 + 140 + 150 + 80)/7 = 120\n\n第三个七天消费平均值从 2019-01-03 到 2019-01-09 是 (120 + 130 + 110 + 140 + 150 + 80 + 110)/7 = 120\n\n第四个七天消费平均值从 2019-01-04 到 2019-01-10 是 (130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7 = 142.86\n\n','examDataFiles/auto_upload_1452_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1452_1637126775642.sql',2,1,0),(1453,'0','广告效果','表: Ads\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| ad_id         | int     |\n| user_id       | int     |\n| action        | enum    |\n+---------------+---------+\n```\n\n(ad_id, user_id) 是该表的主键\n\n该表的每一行包含一条广告的 ID(ad_id)，用户的 ID(user_id) 和用户对广告采取的行为 (action)\n\naction 列是一个枚举类型 (\'Clicked\', \'Viewed\', \'Ignored\') 。\n\n一家公司正在运营这些广告并想计算每条广告的效果。\n\n广告效果用点击通过率（Click-Through Rate：CTR）来衡量，公式如下:\n\n写一条SQL语句来查询每一条广告的ctr，\n\nctr要保留两位小数。结果需要按ctr降序、按ad_id升序进行排序。\n\n查询结果示例如下：\n\nAds 表:\n\n```\n+-------+---------+---------+\n| ad_id | user_id | action  |\n+-------+---------+---------+\n| 1     | 1       | Clicked |\n| 2     | 2       | Clicked |\n| 3     | 3       | Viewed  |\n| 5     | 5       | Ignored |\n| 1     | 7       | Ignored |\n| 2     | 7       | Viewed  |\n| 3     | 5       | Clicked |\n| 1     | 4       | Viewed  |\n| 2     | 11      | Viewed  |\n| 1     | 2       | Clicked |\n+-------+---------+---------+\n```\n\n结果表:\n\n```\n+-------+-------+\n| ad_id | ctr   |\n+-------+-------+\n| 1     | 66.67 |\n| 3     | 50.00 |\n| 2     | 33.33 |\n| 5     | 0.00  |\n+-------+-------+\n```\n\n对于 ad_id = 1, ctr = (2/(2+1)) * 100 = 66.67\n\n对于 ad_id = 2, ctr = (1/(1+2)) * 100 = 33.33\n\n对于 ad_id = 3, ctr = (1/(1+1)) * 100 = 50.00\n\n对于 ad_id = 5, ctr = 0.00, 注意 ad_id = 5 没有被点击 (Clicked) 或查看 (Viewed) 过\n\n注意我们不关心 action 为 Ingnored 的广告\n\n结果按 ctr（降序），ad_id（升序）排序\n\n','examDataFiles/auto_upload_1453_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1453_1637126775642.sql',1,1,0),(1462,'0','列出指定时间段内所有的下单产品','表: Products\n\n```\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| product_id       | int     |\n| product_name     | varchar |\n| product_category | varchar |\n+------------------+---------+\n```\n\nproduct_id 是该表主键。\n\n该表包含该公司产品的数据。\n\n表: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| order_date    | date    |\n| unit          | int     |\n+---------------+---------+\n```\n\n该表无主键，可能包含重复行。\n\nproduct_id 是表单 Products 的外键。\n\nunit 是在日期 order_date 内下单产品的数目。\n\n写一个 SQL 语句，要求获取在 2020 年 2 月份下单的数量不少于 100 的产品的名字和数目。\n\n返回结果表单的顺序无要求。\n\n查询结果的格式如下：\n\nProducts 表:\n\n```\n+-------------+-----------------------+------------------+\n| product_id  | product_name          | product_category |\n+-------------+-----------------------+------------------+\n| 1           | Leetcode Solutions    | Book             |\n| 2           | Jewels of Stringology | Book             |\n| 3           | HP                    | Laptop           |\n| 4           | Lenovo                | Laptop           |\n| 5           | Leetcode Kit          | T-shirt          |\n+-------------+-----------------------+------------------+\n```\n\nOrders 表:\n\n```\n+--------------+--------------+----------+\n| product_id   | order_date   | unit     |\n+--------------+--------------+----------+\n| 1            | 2020-02-05   | 60       |\n| 1            | 2020-02-10   | 70       |\n| 2            | 2020-01-18   | 30       |\n| 2            | 2020-02-11   | 80       |\n| 3            | 2020-02-17   | 2        |\n| 3            | 2020-02-24   | 3        |\n| 4            | 2020-03-01   | 20       |\n| 4            | 2020-03-04   | 30       |\n| 4            | 2020-03-04   | 60       |\n| 5            | 2020-02-25   | 50       |\n| 5            | 2020-02-27   | 50       |\n| 5            | 2020-03-01   | 50       |\n+--------------+--------------+----------+\n```\n\nResult 表:\n\n```\n+--------------------+---------+\n| product_name       | unit    |\n+--------------------+---------+\n| Leetcode Solutions | 130     |\n| Leetcode Kit       | 100     |\n+--------------------+---------+\n```\n\n2020 年 2 月份下单 product_id = 1 的产品的数目总和为 (60 + 70) = 130 。\n\n2020 年 2 月份下单 product_id = 2 的产品的数目总和为 80 。\n\n2020 年 2 月份下单 product_id = 3 的产品的数目总和为 (2 + 3) = 5 。\n\n2020 年 2 月份 product_id = 4 的产品并没有下单。\n\n2020 年 2 月份下单 product_id = 5 的产品的数目总和为 (50 + 50) = 100 。\n\n','examDataFiles/auto_upload_1462_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1462_1637126775642.sql',1,1,0),(1480,'0','电影评分','表：Movies\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| movie_id      | int     |\n| title         | varchar |\n+---------------+---------+\n```\n\nmovie_id 是这个表的主键。\n\ntitle 是电影的名字。\n\n表：Users\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nuser_id 是表的主键。\n\n表：Movie_Rating\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| movie_id      | int     |\n| user_id       | int     |\n| rating        | int     |\n| created_at    | date    |\n+---------------+---------+\n```\n\n(movie_id, user_id) 是这个表的主键。\n\n这个表包含用户在其评论中对电影的评分 rating 。\n\ncreated_at 是用户的点评日期。 \n\n请你编写一组SQL 查询：\n\n查找评论电影数量最多的用户名。\n\n	如果出现平局，返回字典序较小的用户名。\n\n查找在 2020 年 2 月 平均评分最高 的电影名称。\n\n	如果出现平局，返回字典序较小的电影名称。\n\n字典序 ，即按字母在字典中出现顺序对字符串排序，字典序较小则意味着排序靠前。\n\n查询分两行返回，查询结果格式如下例所示：\n\nMovies 表：\n\n```\n+-------------+--------------+\n| movie_id    |  title       |\n+-------------+--------------+\n| 1           | Avengers     |\n| 2           | Frozen 2     |\n| 3           | Joker        |\n+-------------+--------------+\n```\n\nUsers 表：\n\n```\n+-------------+--------------+\n| user_id     |  name        |\n+-------------+--------------+\n| 1           | Daniel       |\n| 2           | Monica       |\n| 3           | Maria        |\n| 4           | James        |\n+-------------+--------------+\n```\n\nMovie_Rating 表：\n\n```\n+-------------+--------------+--------------+-------------+\n| movie_id    | user_id      | rating       | created_at  |\n+-------------+--------------+--------------+-------------+\n| 1           | 1            | 3            | 2020-01-12  |\n| 1           | 2            | 4            | 2020-02-11  |\n| 1           | 3            | 2            | 2020-02-12  |\n| 1           | 4            | 1            | 2020-01-01  |\n| 2           | 1            | 5            | 2020-02-17  | \n| 2           | 2            | 2            | 2020-02-01  | \n| 2           | 3            | 2            | 2020-03-01  |\n| 3           | 1            | 3            | 2020-02-22  | \n| 3           | 2            | 4            | 2020-02-25  | \n+-------------+--------------+--------------+-------------+\n```\n\nResult 表：\n\n```\n+--------------+\n| results      |\n+--------------+\n| Daniel       |\n| Frozen 2     |\n+--------------+\n```\n\nDaniel 和 Monica 都点评了 3 部电影（\"Avengers\", \"Frozen 2\" 和 \"Joker\"） 但是 Daniel 字典序比较小。\n\nFrozen 2 和 Joker 在 2 月的评分都是 3.5，但是 Frozen 2 的字典序比较小。\n\n','examDataFiles/auto_upload_1480_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1480_1637126775642.sql',2,1,0),(1481,'0','院系无效的学生','院系表: Departments\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nid 是该表的主键\n\n该表包含一所大学每个院系的 id 信息\n\n学生表: Students\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n| department_id | int     |\n+---------------+---------+\n```\n\nid 是该表的主键\n\n该表包含一所大学每个学生的 id 和他/她就读的院系信息\n\n写一条 SQL 语句以查询那些所在院系不存在的学生的 id 和姓名\n\n可以以任何顺序返回结果\n\n下面是返回结果格式的例子\n\nDepartments 表:\n\n```\n+------+--------------------------+\n| id   | name                     |\n+------+--------------------------+\n| 1    | Electrical Engineering   |\n| 7    | Computer Engineering     |\n| 13   | Bussiness Administration |\n+------+--------------------------+\n```\n\nStudents 表:\n\n```\n+------+----------+---------------+\n| id   | name     | department_id |\n+------+----------+---------------+\n| 23   | Alice    | 1             |\n| 1    | Bob      | 7             |\n| 5    | Jennifer | 13            |\n| 2    | John     | 14            |\n| 4    | Jasmine  | 77            |\n| 3    | Steve    | 74            |\n| 6    | Luis     | 1             |\n| 8    | Jonathan | 7             |\n| 7    | Daiana   | 33            |\n| 11   | Madelynn | 1             |\n+------+----------+---------------+\n```\n\n结果表:\n\n```\n+------+----------+\n| id   | name     |\n+------+----------+\n| 2    | John     |\n| 7    | Daiana   |\n| 4    | Jasmine  |\n| 3    | Steve    |\n+------+----------+\n```\n\nJohn, Daiana, Steve 和 Jasmine 所在的院系分别是 14, 33, 74 和 77， 其中 14, 33, 74 和 77 并不存在于院系表\n\n','examDataFiles/auto_upload_1481_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1481_1637126775642.sql',1,1,0),(1494,'0','活动参与者','表: Friends\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n| activity      | varchar |\n+---------------+---------+\n```\n\nid 是朋友的 id 和该表的主键\n\nname 是朋友的名字\n\nactivity 是朋友参加的活动的名字\n\n表: Activities\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nid 是该表的主键\n\nname 是活动的名字\n\n写一条 SQL 查询那些既没有最多，也没有最少参与者的活动的名字\n\n可以以任何顺序返回结果，Activities 表的每项活动的参与者都来自 Friends 表\n\n注意：名称相同 id 不同的参与者算作两个人\n\n下面是查询结果格式的例子：\n\nFriends 表:\n\n```\n+------+--------------+---------------+\n| id   | name         | activity      |\n+------+--------------+---------------+\n| 1    | Jonathan D.  | Eating        |\n| 2    | Jade W.      | Singing       |\n| 3    | Victor J.    | Singing       |\n| 4    | Elvis Q.     | Eating        |\n| 5    | Daniel A.    | Eating        |\n| 6    | Bob B.       | Horse Riding  |\n+------+--------------+---------------+\n```\n\nActivities 表:\n\n```\n+------+--------------+\n| id   | name         |\n+------+--------------+\n| 1    | Eating       |\n| 2    | Singing      |\n| 3    | Horse Riding |\n+------+--------------+\n```\n\nResult 表:\n\n```\n+--------------+\n| activity     |\n+--------------+\n| Singing      |\n+--------------+\n```\n\nEating 活动有三个人参加, 是最多人参加的活动 (Jonathan D. , Elvis Q. and Daniel A.)\n\nHorse Riding 活动有一个人参加, 是最少人参加的活动 (Bob B.)\n\nSinging 活动有两个人参加 (Victor J. and Jade W.)\n\n','examDataFiles/auto_upload_1494_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1494_1637126775642.sql',2,1,0),(1495,'0','顾客的可信联系人数量','顾客表：Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| customer_name | varchar |\n| email         | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是这张表的主键。\n\n此表的每一行包含了某在线商店顾客的姓名和电子邮件。\n\n联系方式表：Contacts\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | id      |\n| contact_name  | varchar |\n| contact_email | varchar |\n+---------------+---------+\n```\n\n(user_id, contact_email) 是这张表的主键。\n\n此表的每一行表示编号为 user_id 的顾客的某位联系人的姓名和电子邮件。\n\n此表包含每位顾客的联系人信息，但顾客的联系人不一定存在于顾客表中。\n\n发票表：Invoices\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| invoice_id   | int     |\n| price        | int     |\n| user_id      | int     |\n+--------------+---------+\n```\n\ninvoice_id 是这张表的主键。\n\n此表的每一行分别表示编号为 user_id 的顾客拥有有一张编号为 invoice_id、价格为 price 的发票。\n\n为每张发票 invoice_id 编写一个SQL查询以查找以下内容：\n\ncustomer_name：与发票相关的顾客名称。\n\nprice：发票的价格。\n\ncontacts_cnt：该顾客的联系人数量。\n\ntrusted_contacts_cnt：可信联系人的数量：既是该顾客的联系人又是商店顾客的联系人数量（即：可信联系人的电子邮件存在于客户表中）。\n\n将查询的结果按照invoice_id排序。\n\n查询结果的格式如下例所示：\n\nCustomers table:\n\n```\n+-------------+---------------+--------------------+\n| customer_id | customer_name | email              |\n+-------------+---------------+--------------------+\n| 1           | Alice         | alice@leetcode.com |\n| 2           | Bob           | bob@leetcode.com   |\n| 13          | John          | john@leetcode.com  |\n| 6           | Alex          | alex@leetcode.com  |\n+-------------+---------------+--------------------+\n```\n\nContacts table:\n\n```\n+-------------+--------------+--------------------+\n| user_id     | contact_name | contact_email      |\n+-------------+--------------+--------------------+\n| 1           | Bob          | bob@leetcode.com   |\n| 1           | John         | john@leetcode.com  |\n| 1           | Jal          | jal@leetcode.com   |\n| 2           | Omar         | omar@leetcode.com  |\n| 2           | Meir         | meir@leetcode.com  |\n| 6           | Alice        | alice@leetcode.com |\n+-------------+--------------+--------------------+\n```\n\nInvoices table:\n\n```\n+------------+-------+---------+\n| invoice_id | price | user_id |\n+------------+-------+---------+\n| 77         | 100   | 1       |\n| 88         | 200   | 1       |\n| 99         | 300   | 2       |\n| 66         | 400   | 2       |\n| 55         | 500   | 13      |\n| 44         | 60    | 6       |\n+------------+-------+---------+\n```\n\nResult table:\n\n```\n+------------+---------------+-------+--------------+----------------------+\n| invoice_id | customer_name | price | contacts_cnt | trusted_contacts_cnt |\n+------------+---------------+-------+--------------+----------------------+\n| 44         | Alex          | 60    | 1            | 1                    |\n| 55         | John          | 500   | 0            | 0                    |\n| 66         | Bob           | 400   | 2            | 0                    |\n| 77         | Alice         | 100   | 3            | 2                    |\n| 88         | Alice         | 200   | 3            | 2                    |\n| 99         | Bob           | 300   | 2            | 0                    |\n+------------+---------------+-------+--------------+----------------------+\n```\n\nAlice 有三位联系人，其中两位(Bob 和 John)是可信联系人。\n\nBob 有两位联系人, 他们中的任何一位都不是可信联系人。\n\nAlex 只有一位联系人(Alice)，并是一位可信联系人。\n\nJohn 没有任何联系人。\n\n','examDataFiles/auto_upload_1495_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1495_1637126775642.sql',2,1,0),(1504,'0','获取最近第二次的活动','表: UserActivity\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| username      | varchar |\n| activity      | varchar |\n| startDate     | Date    |\n| endDate       | Date    |\n+---------------+---------+\n```\n\n该表不包含主键\n\n该表包含每个用户在一段时间内进行的活动的信息\n\n名为 username 的用户在 startDate 到 endDate 日内有一次活动\n\n写一条SQL查询展示每一位用户 最近第二次 的活动\n\n如果用户仅有一次活动，返回该活动\n\n一个用户不能同时进行超过一项活动，以 任意 顺序返回结果\n\n下面是查询结果格式的例子：\n\nUserActivity 表:\n\n```\n+------------+--------------+-------------+-------------+\n| username   | activity     | startDate   | endDate     |\n+------------+--------------+-------------+-------------+\n| Alice      | Travel       | 2020-02-12  | 2020-02-20  |\n| Alice      | Dancing      | 2020-02-21  | 2020-02-23  |\n| Alice      | Travel       | 2020-02-24  | 2020-02-28  |\n| Bob        | Travel       | 2020-02-11  | 2020-02-18  |\n+------------+--------------+-------------+-------------+\n```\n\nResult 表:\n\n```\n+------------+--------------+-------------+-------------+\n| username   | activity     | startDate   | endDate     |\n+------------+--------------+-------------+-------------+\n| Alice      | Dancing      | 2020-02-21  | 2020-02-23  |\n| Bob        | Travel       | 2020-02-11  | 2020-02-18  |\n+------------+--------------+-------------+-------------+\n```\n\nAlice 最近一次的活动是从 2020-02-24 到 2020-02-28 的旅行, 在此之前的 2020-02-21 到 2020-02-23 她进行了舞蹈\n\nBob 只有一条记录，我们就取这条记录\n\n','examDataFiles/auto_upload_1504_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1504_1637126775642.sql',3,1,0),(1509,'0','使用唯一标识码替换员工ID','Employees 表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nid 是这张表的主键。\n\n这张表的每一行分别代表了某公司其中一位员工的名字和 ID 。\n\nEmployeeUNI表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| unique_id     | int     |\n+---------------+---------+\n```\n\n(id, unique_id) 是这张表的主键。\n\n这张表的每一行包含了该公司某位员工的 ID 和他的唯一标识码（unique ID）。\n\n写一段SQL查询来展示每位用户的 唯一标识码（unique ID ）；如果某位员工没有唯一标识码，使用 null 填充即可。\n\n你可以以 任意 顺序返回结果表。\n\n查询结果的格式如下例所示：\n\nEmployees table:\n\n```\n+----+----------+\n| id | name     |\n+----+----------+\n| 1  | Alice    |\n| 7  | Bob      |\n| 11 | Meir     |\n| 90 | Winston  |\n| 3  | Jonathan |\n+----+----------+\n```\n\nEmployeeUNI table:\n\n```\n+----+-----------+\n| id | unique_id |\n+----+-----------+\n| 3  | 1         |\n| 11 | 2         |\n| 90 | 3         |\n+----+-----------+\n```\n\nEmployeeUNI table:\n\n```\n+-----------+----------+\n| unique_id | name     |\n+-----------+----------+\n| null      | Alice    |\n| null      | Bob      |\n| 2         | Meir     |\n| 3         | Winston  |\n| 1         | Jonathan |\n+-----------+----------+\n```\n\nAlice and Bob 没有唯一标识码, 因此我们使用 null 替代。\n\nMeir 的唯一标识码是 2 。\n\nWinston 的唯一标识码是 3 。\n\nJonathan 唯一标识码是 1 。\n\n','examDataFiles/auto_upload_1509_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1509_1637126775642.sql',1,1,0),(1518,'0','按年度列出销售总额','Product表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| product_name  | varchar |\n+---------------+---------+\n```\n\nproduct_id 是这张表的主键。\n\nproduct_name 是产品的名称。\n\nSales表：\n\n```\n+---------------------+---------+\n| Column Name         | Type    |\n+---------------------+---------+\n| product_id          | int     |\n| period_start        | date    |\n| period_end          | date    |\n| average_daily_sales | int     |\n+---------------------+---------+\n```\n\nproduct_id 是这张表的主键。\n\nperiod_start和 period_end是该产品销售期的起始日期和结束日期，且这两个日期包含在销售期内。\n\naverage_daily_sales 列存储销售期内该产品的日平均销售额。\n\n编写一段 SQL 查询每个产品每年的总销售额，并包含 product_id, product_name 以及 report_year 等信息。\n\n销售年份的日期介于 2018 年到 2020 年之间。你返回的结果需要按product_id 和 report_year 排序。\n\n查询结果格式如下例所示：\n\nProduct table:\n\n```\n+------------+--------------+\n| product_id | product_name |\n+------------+--------------+\n| 1          | LC Phone     |\n| 2          | LC T-Shirt   |\n| 3          | LC Keychain  |\n+------------+--------------+\n```\n\nSales table:\n\n```\n+------------+--------------+-------------+---------------------+\n| product_id | period_start | period_end  | average_daily_sales |\n+------------+--------------+-------------+---------------------+\n| 1          | 2019-01-25   | 2019-02-28  | 100                 |\n| 2          | 2018-12-01   | 2020-01-01  | 10                  |\n| 3          | 2019-12-01   | 2020-01-31  | 1                   |\n+------------+--------------+-------------+---------------------+\n```\n\nResult table:\n\n```\n+------------+--------------+-------------+--------------+\n| product_id | product_name | report_year | total_amount |\n+------------+--------------+-------------+--------------+\n| 1          | LC Phone     |    2019     | 3500         |\n| 2          | LC T-Shirt   |    2018     | 310          |\n| 2          | LC T-Shirt   |    2019     | 3650         |\n| 2          | LC T-Shirt   |    2020     | 10           |\n| 3          | LC Keychain  |    2019     | 31           |\n| 3          | LC Keychain  |    2020     | 31           |\n+------------+--------------+-------------+--------------+\n```\n\nLC Phone 在 2019-01-25 至 2019-02-28 期间销售，该产品销售时间总计35天。销售总额 35*100 = 3500。\n\nLC T-shirt 在 2018-12-01至 2020-01-01 期间销售，该产品在2018年、2019年、2020年的销售时间分别是31天、365天、1天，2018年、2019年、2020年的销售总额分别是31*10=310、365*10=3650、1*10=10。\n\nLC Keychain 在 2019-12-01至 2020-01-31 期间销售，该产品在2019年、2020年的销售时间分别是：31天、31天，2019年、2020年的销售总额分别是31*1=31、31*1=31。\n\n','examDataFiles/auto_upload_1518_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1518_1637126775642.sql',3,1,0),(1523,'0','股票的资本损益','Stocks表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| stock_name    | varchar |\n| operation     | enum    |\n| operation_day | int     |\n| price         | int     |\n+---------------+---------+\n```\n\n(stock_name, day) 是这张表的主键\n\noperation 列使用的是一种枚举类型，包括：(\'Sell\',\'Buy\')\n\n此表的每一行代表了名为 stock_name 的某支股票在 operation_day 这一天的操作价格。\n\n保证股票的每次\'Sell\'操作前，都有相应的\'Buy\'操作。\n\n编写一个SQL查询来报告每支股票的资本损益。\n\n股票的资本损益是一次或多次买卖股票后的全部收益或损失。\n\n以任意顺序返回结果即可。\n\nSQL查询结果的格式如下例所示：\n\nStocks 表:\n\n```\n+---------------+-----------+---------------+--------+\n| stock_name    | operation | operation_day | price  |\n+---------------+-----------+---------------+--------+\n| Leetcode      | Buy       | 1             | 1000   |\n| Corona Masks  | Buy       | 2             | 10     |\n| Leetcode      | Sell      | 5             | 9000   |\n| Handbags      | Buy       | 17            | 30000  |\n| Corona Masks  | Sell      | 3             | 1010   |\n| Corona Masks  | Buy       | 4             | 1000   |\n| Corona Masks  | Sell      | 5             | 500    |\n| Corona Masks  | Buy       | 6             | 1000   |\n| Handbags      | Sell      | 29            | 7000   |\n| Corona Masks  | Sell      | 10            | 10000  |\n+---------------+-----------+---------------+--------+\n```\n\nResult 表:\n\n```\n+---------------+-------------------+\n| stock_name    | capital_gain_loss |\n+---------------+-------------------+\n| Corona Masks  | 9500              |\n| Leetcode      | 8000              |\n| Handbags      | -23000            |\n+---------------+-------------------+\n```\n\nLeetcode 股票在第一天以1000美元的价格买入，在第五天以9000美元的价格卖出。资本收益=9000-1000=8000美元。\n\nHandbags 股票在第17天以30000美元的价格买入，在第29天以7000美元的价格卖出。资本损失=7000-30000=-23000美元。\n\nCorona Masks 股票在第1天以10美元的价格买入，在第3天以1010美元的价格卖出。在第4天以1000美元的价格再次购买，在第5天以500美元的价格出售。最后，它在第6天以1000美元的价格被买走，在第10天以10000美元的价格被卖掉。资本损益是每次（’Buy\'->\'Sell\'）操作资本收益或损失的和=（1010-10）+（500-1000）+（10000-1000）=1000-500+9000=9500美元。\n\n','examDataFiles/auto_upload_1523_1637126775642.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1523_1637126775642.sql',2,1,0),(1536,'0','购买了产品 A 和产品 B 却没有购买产品 C 的顾客','Customers表：\n\n```\n+---------------------+---------+\n| Column Name         | Type    |\n+---------------------+---------+\n| customer_id         | int     |\n| customer_name       | varchar |\n+---------------------+---------+\n```\n\ncustomer_id 是这张表的主键。\n\ncustomer_name 是顾客的名称。\n\nOrders表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| customer_id   | int     |\n| product_name  | varchar |\n+---------------+---------+\n```\n\norder_id 是这张表的主键。\n\ncustomer_id 是购买了名为 \"product_name\" 产品顾客的id。\n\n请你设计 SQL 查询来报告购买了产品 A 和产品 B 却没有购买产品 C 的顾客的 ID 和姓名（ customer_id 和customer_name ），我们将基于此结果为他们推荐产品 C 。\n\n您返回的查询结果需要按照customer_id 排序。\n\n查询结果如下例所示。\n\nCustomers table:\n\n```\n+-------------+---------------+\n| customer_id | customer_name |\n+-------------+---------------+\n| 1           | Daniel        |\n| 2           | Diana         |\n| 3           | Elizabeth     |\n| 4           | Jhon          |\n+-------------+---------------+\n```\n\nOrders table:\n\n```\n+------------+--------------+---------------+\n| order_id   | customer_id  | product_name  |\n+------------+--------------+---------------+\n| 10         |     1        |     A         |\n| 20         |     1        |     B         |\n| 30         |     1        |     D         |\n| 40         |     1        |     C         |\n| 50         |     2        |     A         |\n| 60         |     3        |     A         |\n| 70         |     3        |     B         |\n| 80         |     3        |     D         |\n| 90         |     4        |     C         |\n+------------+--------------+---------------+\n```\n\nResult table:\n\n```\n+-------------+---------------+\n| customer_id | customer_name |\n+-------------+---------------+\n| 3           | Elizabeth     |\n+-------------+---------------+\n```\n\n只有 customer_id 为 3 的顾客购买了产品 A 和产品 B ，却没有购买产品 C 。\n\n','examDataFiles/auto_upload_1536_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1536_1637126775643.sql',2,1,0),(1541,'0','排名靠前的旅行者','表：Users\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nid 是该表单主键。\n\nname 是用户名字。\n\n表：Rides\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| user_id       | int     |\n| distance      | int     |\n+---------------+---------+\n```\n\nid 是该表单主键。\n\nuser_id 是本次行程的用户的 id, 而该用户此次行程距离为 distance 。\n\n写一段 SQL ,报告每个用户的旅行距离。\n\n返回的结果表单，以travelled_distance降序排列 ，如果有两个或者更多的用户旅行了相同的距离,那么再以name升序排列 。\n\n查询结果格式如下例所示。\n\nUsers 表：\n\n```\n+------+-----------+\n| id   | name      |\n+------+-----------+\n| 1    | Alice     |\n| 2    | Bob       |\n| 3    | Alex      |\n| 4    | Donald    |\n| 7    | Lee       |\n| 13   | Jonathan  |\n| 19   | Elvis     |\n+------+-----------+\n```\n\nRides 表：\n\n```\n+------+----------+----------+\n| id   | user_id  | distance |\n+------+----------+----------+\n| 1    | 1        | 120      |\n| 2    | 2        | 317      |\n| 3    | 3        | 222      |\n| 4    | 7        | 100      |\n| 5    | 13       | 312      |\n| 6    | 19       | 50       |\n| 7    | 7        | 120      |\n| 8    | 19       | 400      |\n| 9    | 7        | 230      |\n+------+----------+----------+\n```\n\nResult 表：\n\n```\n+----------+--------------------+\n| name     | travelled_distance |\n+----------+--------------------+\n| Elvis    | 450                |\n| Lee      | 450                |\n| Bob      | 317                |\n| Jonathan | 312                |\n| Alex     | 222                |\n| Alice    | 120                |\n| Donald   | 0                  |\n+----------+--------------------+\n```\n\nElvis 和 Lee 旅行了 450 英里，Elvis 是排名靠前的旅行者，因为他的名字在字母表上的排序比 Lee 更小。\n\nBob, Jonathan, Alex 和 Alice 只有一次行程，我们只按此次行程的全部距离对他们排序。\n\nDonald 没有任何行程, 他的旅行距离为 0。\n\n','examDataFiles/auto_upload_1541_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1541_1637126775643.sql',1,1,0),(1546,'0','查找成绩处于中游的学生','表: Student\n\n```\n+---------------------+---------+\n| Column Name         | Type    |\n+---------------------+---------+\n| student_id          | int     |\n| student_name        | varchar |\n+---------------------+---------+\n```\n\nstudent_id 是该表主键.\n\nstudent_name 学生名字.\n\n表: Exam\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| exam_id       | int     |\n| student_id    | int     |\n| score         | int     |\n+---------------+---------+\n```\n\n(exam_id, student_id) 是该表主键.\n\n学生 student_id 在测验 exam_id 中得分为 score.\n\n成绩处于中游的学生是指至少参加了一次测验,且得分既不是最高分也不是最低分的学生。\n\n写一个 SQL 语句，找出在 所有 测验中都处于中游的学生 (student_id, student_name)。\n\n不要返回从来没有参加过测验的学生。返回结果表按照student_id排序。\n\n查询结果格式如下。\n\nStudent 表：\n\n```\n+-------------+---------------+\n| student_id  | student_name  |\n+-------------+---------------+\n| 1           | Daniel        |\n| 2           | Jade          |\n| 3           | Stella        |\n| 4           | Jonathan      |\n| 5           | Will          |\n+-------------+---------------+\n```\n\nExam 表：\n\n```\n+------------+--------------+-----------+\n| exam_id    | student_id   | score     |\n+------------+--------------+-----------+\n| 10         |     1        |    70     |\n| 10         |     2        |    80     |\n| 10         |     3        |    90     |\n| 20         |     1        |    80     |\n| 30         |     1        |    70     |\n| 30         |     3        |    80     |\n| 30         |     4        |    90     |\n| 40         |     1        |    60     |\n| 40         |     2        |    70     |\n| 40         |     4        |    80     |\n+------------+--------------+-----------+\n```\n\nResult 表：\n\n```\n+-------------+---------------+\n| student_id  | student_name  |\n+-------------+---------------+\n| 2           | Jade          |\n+-------------+---------------+\n```\n\n对于测验 1: 学生 1 和 3 分别获得了最低分和最高分。\n\n对于测验 2: 学生 1 既获得了最高分, 也获得了最低分。\n\n对于测验 3 和 4: 学生 1 和 4 分别获得了最低分和最高分。\n\n学生 2 和 5 没有在任一场测验中获得了最高分或者最低分。\n\n因为学生 5 从来没有参加过任何测验, 所以他被排除于结果表。\n\n由此, 我们仅仅返回学生 2 的信息。\n\n','examDataFiles/auto_upload_1546_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1546_1637126775643.sql',3,1,0),(1551,'0','净现值查询','表: NPV\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| year          | int     |\n| npv           | int     |\n+---------------+---------+\n```\n\n(id, year) 是该表主键.\n\n该表有每一笔存货的年份, id 和对应净现值的信息.\n\n表: Queries\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| year          | int     |\n+---------------+---------+\n```\n\n(id, year) 是该表主键.\n\n该表有每一次查询所对应存货的 id 和年份的信息.\n\n写一个 SQL,找到 Queries表中每一次查询的净现值.\n\n结果表没有顺序要求.\n\n查询结果的格式如下所示:\n\nNPV 表:\n\n```\n+------+--------+--------+\n| id   | year   | npv    |\n+------+--------+--------+\n| 1    | 2018   | 100    |\n| 7    | 2020   | 30     |\n| 13   | 2019   | 40     |\n| 1    | 2019   | 113    |\n| 2    | 2008   | 121    |\n| 3    | 2009   | 12     |\n| 11   | 2020   | 99     |\n| 7    | 2019   | 0      |\n+------+--------+--------+\n```\n\nQueries 表:\n\n```\n+------+--------+\n| id   | year   |\n+------+--------+\n| 1    | 2019   |\n| 2    | 2008   |\n| 3    | 2009   |\n| 7    | 2018   |\n| 7    | 2019   |\n| 7    | 2020   |\n| 13   | 2019   |\n+------+--------+\n```\n\n结果表:\n\n```\n+------+--------+--------+\n| id   | year   | npv    |\n+------+--------+--------+\n| 1    | 2019   | 113    |\n| 2    | 2008   | 121    |\n| 3    | 2009   | 12     |\n| 7    | 2018   | 0      |\n| 7    | 2019   | 0      |\n| 7    | 2020   | 30     |\n| 13   | 2019   | 40     |\n+------+--------+--------+\n```\n\n(7, 2018)的净现值不在 NPV 表中, 我们把它看作是 0.\n\n所有其它查询的净现值都能在 NPV 表中找到.\n\n','examDataFiles/auto_upload_1551_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1551_1637126775643.sql',2,1,0),(1564,'0','制作会话柱状图','表：Sessions\n\n```\n+---------------------+---------+\n| Column Name         | Type    |\n+---------------------+---------+\n| session_id          | int     |\n| duration            | int     |\n+---------------------+---------+\n```\n\nsession_id 是该表主键\n\nduration 是用户访问应用的时间, 以秒为单位\n\n你想知道用户在你的 app 上的访问时长情况。因此决定统计访问时长区间分别为 \"[0-5>\", \"[5-10>\", \"[10-15>\"和\"15 or more\" （单位：分钟）的会话数量，并以此绘制柱状图。\n\n写一个SQL查询来报告（访问时长区间，会话总数）。结果可用任何顺序呈现。\n\n下方为查询的输出格式：\n\nSessions 表：\n\n```\n+-------------+---------------+\n| session_id  | duration      |\n+-------------+---------------+\n| 1           | 30            |\n| 2           | 199           |\n| 3           | 299           |\n| 4           | 580           |\n| 5           | 1000          |\n+-------------+---------------+\n```\n\nResult 表：\n\n```\n+--------------+--------------+\n| bin          | total        |\n+--------------+--------------+\n| [0-5>        | 3            |\n| [5-10>       | 1            |\n| [10-15>      | 0            |\n| 15 or more   | 1            |\n+--------------+--------------+\n```\n\n对于 session_id 1，2 和 3 ，它们的访问时间大于等于 0 分钟且小于 5 分钟。\n\n对于 session_id 4，它的访问时间大于等于 5 分钟且小于 10 分钟。\n\n没有会话的访问时间大于等于 10 分钟且小于 15 分钟。\n\n对于 session_id 5, 它的访问时间大于等于 15 分钟。\n\n','examDataFiles/auto_upload_1564_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1564_1637126775643.sql',1,1,0),(1565,'0','计算布尔表达式的值','表 Variables:\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| name          | varchar |\n| value         | int     |\n+---------------+---------+\n```\n\nname 是该表主键.\n\n该表包含了存储的变量及其对应的值.\n\n表 Expressions:\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| left_operand  | varchar |\n| operator      | enum    |\n| right_operand | varchar |\n+---------------+---------+\n```\n\n(left_operand, operator, right_operand) 是该表主键.\n\n该表包含了需要计算的布尔表达式.\n\noperator 是枚举类型, 取值于(\'<\', \'>\', \'=\')\n\nleft_operand 和 right_operand 的值保证存在于 Variables 表单中.\n\n写一个 SQL 查询, 以计算表 Expressions中的布尔表达式.\n\n返回的结果表没有顺序要求.\n\n查询结果格式如下例所示.\n\nVariables 表:\n\n```\n+------+-------+\n| name | value |\n+------+-------+\n| x    | 66    |\n| y    | 77    |\n+------+-------+\n```\n\nExpressions 表:\n\n```\n+--------------+----------+---------------+\n| left_operand | operator | right_operand |\n+--------------+----------+---------------+\n| x            | >        | y             |\n| x            | <        | y             |\n| x            | =        | y             |\n| y            | >        | x             |\n| y            | <        | x             |\n| x            | =        | x             |\n+--------------+----------+---------------+\n```\n\nResult 表:\n\n```\n+--------------+----------+---------------+-------+\n| left_operand | operator | right_operand | value |\n+--------------+----------+---------------+-------+\n| x            | >        | y             | false |\n| x            | <        | y             | true  |\n| x            | =        | y             | false |\n| y            | >        | x             | true  |\n| y            | <        | x             | false |\n| x            | =        | x             | true  |\n+--------------+----------+---------------+-------+\n```\n\n如上所示, 你需要通过使用 Variables 表来找到 Expressions 表中的每一个布尔表达式的值.\n\n','examDataFiles/auto_upload_1565_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1565_1637126775643.sql',2,1,0),(1578,'0','苹果和桔子','表: Sales\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| sale_date     | date    |\n| fruit         | enum    | \n| sold_num      | int     | \n+---------------+---------+\n```\n\n(sale_date,fruit) 是该表主键.\n\n该表包含了每一天中\"苹果\" 和 \"桔子\"的销售情况.\n\n写一个 SQL查询,报告每一天苹果和桔子销售的数目的差异.\n\n返回的结果表,按照格式为(\'YYYY-MM-DD\') 的 sale_date 排序.\n\n查询结果表如下例所示:\n\nSales 表:\n\n```\n+------------+------------+-------------+\n| sale_date  | fruit      | sold_num    |\n+------------+------------+-------------+\n| 2020-05-01 | apples     | 10          |\n| 2020-05-01 | oranges    | 8           |\n| 2020-05-02 | apples     | 15          |\n| 2020-05-02 | oranges    | 15          |\n| 2020-05-03 | apples     | 20          |\n| 2020-05-03 | oranges    | 0           |\n| 2020-05-04 | apples     | 15          |\n| 2020-05-04 | oranges    | 16          |\n+------------+------------+-------------+\n```\n\nResult 表:\n\n```\n+------------+--------------+\n| sale_date  | diff         |\n+------------+--------------+\n| 2020-05-01 | 2            |\n| 2020-05-02 | 0            |\n| 2020-05-03 | 20           |\n| 2020-05-04 | -1           |\n+------------+--------------+\n```\n\n在 2020-05-01, 卖了 10 个苹果 和 8 个桔子 (差异为 10 - 8 = 2).\n\n在 2020-05-02, 卖了 15 个苹果 和 15 个桔子 (差异为 15 - 15 = 0).\n\n在 2020-05-03, 卖了 20 个苹果 和 0 个桔子 (差异为 20 - 0 = 20).\n\n在 2020-05-04, 卖了 15 个苹果 和 16 个桔子 (差异为 15 - 16 = -1).\n\n','examDataFiles/auto_upload_1578_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1578_1637126775643.sql',2,1,0),(1579,'0','活跃用户','表 Accounts:\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\nid 是该表主键.\n\n该表包含账户 id 和账户的用户名.\n\n表 Logins:\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| login_date    | date    |\n+---------------+---------+\n```\n\n该表无主键, 可能包含重复项.\n\n该表包含登录用户的账户 id 和登录日期. 用户也许一天内登录多次.\n\n写一个 SQL 查询, 找到活跃用户的 id 和 name.\n\n活跃用户是指那些至少连续5 天登录账户的用户.\n\n返回的结果表按照 id 排序.\n\n结果表格式如下例所示:\n\nAccounts 表:\n\n```\n+----+----------+\n| id | name     |\n+----+----------+\n| 1  | Winston  |\n| 7  | Jonathan |\n+----+----------+\n```\n\nLogins 表:\n\n```\n+----+------------+\n| id | login_date |\n+----+------------+\n| 7  | 2020-05-30 |\n| 1  | 2020-05-30 |\n| 7  | 2020-05-31 |\n| 7  | 2020-06-01 |\n| 7  | 2020-06-02 |\n| 7  | 2020-06-02 |\n| 7  | 2020-06-03 |\n| 1  | 2020-06-07 |\n| 7  | 2020-06-10 |\n+----+------------+\n```\n\nResult 表:\n\n```\n+----+----------+\n| id | name     |\n+----+----------+\n| 7  | Jonathan |\n+----+----------+\n```\n\nid = 1 的用户 Winston 仅仅在不同的 2 天内登录了 2 次, 所以, Winston 不是活跃用户.\n\nid = 7 的用户 Jonathon 在不同的 6 天内登录了 7 次, , 6 天中有 5 天是连续的, 所以, Jonathan 是活跃用户.\n\n进阶问题:\n\n如果活跃用户是那些至少连续n天登录账户的用户,你能否写出通用的解决方案?\n\n','examDataFiles/auto_upload_1579_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1579_1637126775643.sql',2,1,0),(1607,'0','矩形面积','表: Points\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| id            | int     |\n| x_value       | int     |\n| y_value       | int     |\n+---------------+---------+\n```\n\nid 是该表主键\n\n每个点都用二维坐标 (x_value, y_value) 表示\n\n写一个 SQL 语句，报告由表中任意两点可以形成的所有 边与坐标轴平行 且 面积不为零 的矩形。\n\n结果表中的每一行包含三列 (p1, p2, area)如下:\n\np1和p2是矩形两个对角的 id\n\n矩形的面积由列area表示\n\n请按照面积area 大小降序排列；如果面积相同的话, 则按照p1升序排序；若仍相同，则按 p2 升序排列。\n\n查询结果如下例所示：\n\nPoints 表:\n\n```\n+----------+-------------+-------------+\n| id       | x_value     | y_value     |\n+----------+-------------+-------------+\n| 1        | 2           | 7           |\n| 2        | 4           | 8           |\n| 3        | 2           | 10          |\n+----------+-------------+-------------+\n```\n\nResult 表:\n\n```\n+----------+-------------+-------------+\n| p1       | p2          | area        |\n+----------+-------------+-------------+\n| 2        | 3           | 4           |\n| 1        | 2           | 2           |\n+----------+-------------+-------------+\n```\n\np1 = 2 且 p2 = 3 时, 面积等于 |4-2| * |8-10| = 4\n\np1 = 1 且 p2 = 2 时, 面积等于 ||2-4| * |7-8| = 2 \n\np1 = 1 且 p2 = 3 时, 是不可能为矩形的, 面积等于 0\n\n','examDataFiles/auto_upload_1607_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1607_1637126775643.sql',2,1,0),(1608,'0','计算税后工资','Salaries 表：\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| company_id    | int     |\n| employee_id   | int     |\n| employee_name | varchar |\n| salary        | int     |\n+---------------+---------+\n```\n\n(company_id, employee_id) 是这个表的主键\n\n这个表包括员工的company id, id, name 和 salary \n\n写一条查询 SQL 来查找每个员工的税后工资\n\n每个公司的税率计算依照以下规则\n\n如果这个公司员工最高工资不到 1000 ，税率为 0%\n\n如果这个公司员工最高工资在 1000 到 10000 之间，税率为 24%\n\n如果这个公司员工最高工资大于 10000 ，税率为 49%\n\n按任意顺序返回结果，税后工资结果取整\n\n结果表格式如下例所示：\n\nSalaries 表：\n\n```\n+------------+-------------+---------------+--------+\n| company_id | employee_id | employee_name | salary |\n+------------+-------------+---------------+--------+\n| 1          | 1           | Tony          | 2000   |\n| 1          | 2           | Pronub        | 21300  |\n| 1          | 3           | Tyrrox        | 10800  |\n| 2          | 1           | Pam           | 300    |\n| 2          | 7           | Bassem        | 450    |\n| 2          | 9           | Hermione      | 700    |\n| 3          | 7           | Bocaben       | 100    |\n| 3          | 2           | Ognjen        | 2200   |\n| 3          | 13          | Nyancat       | 3300   |\n| 3          | 15          | Morninngcat   | 7777   |\n+------------+-------------+---------------+--------+\n```\n\nResult 表：\n\n```\n+------------+-------------+---------------+--------+\n| company_id | employee_id | employee_name | salary |\n+------------+-------------+---------------+--------+\n| 1          | 1           | Tony          | 1020   |\n| 1          | 2           | Pronub        | 10863  |\n| 1          | 3           | Tyrrox        | 5508   |\n| 2          | 1           | Pam           | 300    |\n| 2          | 7           | Bassem        | 450    |\n| 2          | 9           | Hermione      | 700    |\n| 3          | 7           | Bocaben       | 76     |\n| 3          | 2           | Ognjen        | 1672   |\n| 3          | 13          | Nyancat       | 2508   |\n| 3          | 15          | Morninngcat   | 5911   |\n+------------+-------------+---------------+--------+\n```\n\n对于公司 1 ，最高工资是 21300 ，其每个员工的税率为 49%\n\n对于公司 2 ，最高工资是 700 ，其每个员工税率为 0%\n\n对于公司 3 ，最高工资是 7777 ，其每个员工税率是 24%\n\n税后工资计算 = 工资 - ( 税率 / 100）*工资\n\n对于上述案例，Morninngcat 的税后工资 = 7777 - 7777 * ( 24 / 100) = 7777 - 1866.48 = 5910.52 ，取整为 5911\n\n','examDataFiles/auto_upload_1608_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1608_1637126775643.sql',2,1,0),(1623,'0','周内每天的销售情况','表：Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| customer_id   | int     |\n| order_date    | date    | \n| item_id       | varchar |\n| quantity      | int     |\n+---------------+---------+\n```\n\n(order_id, item_id) 是该表主键\n\n该表包含了订单信息\n\norder_date 是id为 item_id 的商品被id为 customer_id 的消费者订购的日期.\n\n表：Items\n\n```\n+---------------------+---------+\n| Column Name         | Type    |\n+---------------------+---------+\n| item_id             | varchar |\n| item_name           | varchar |\n| item_category       | varchar |\n+---------------------+---------+\n```\n\nitem_id 是该表主键\n\nitem_name 是商品的名字\n\nitem_category是商品的类别\n\n你是企业主，想要获得分类商品和周内每天的销售报告。\n\n写一个SQL语句，报告 周内每天 每个商品类别下订购了多少单位。\n\n返回结果表单 按商品类别排序 。\n\n查询结果格式如下例所示：\n\nOrders 表：\n\n```\n+------------+--------------+-------------+--------------+-------------+\n| order_id   | customer_id  | order_date  | item_id      | quantity    |\n+------------+--------------+-------------+--------------+-------------+\n| 1          | 1            | 2020-06-01  | 1            | 10          |\n| 2          | 1            | 2020-06-08  | 2            | 10          |\n| 3          | 2            | 2020-06-02  | 1            | 5           |\n| 4          | 3            | 2020-06-03  | 3            | 5           |\n| 5          | 4            | 2020-06-04  | 4            | 1           |\n| 6          | 4            | 2020-06-05  | 5            | 5           |\n| 7          | 5            | 2020-06-05  | 1            | 10          |\n| 8          | 5            | 2020-06-14  | 4            | 5           |\n| 9          | 5            | 2020-06-21  | 3            | 5           |\n+------------+--------------+-------------+--------------+-------------+\n```\n\nItems 表：\n\n```\n+------------+----------------+---------------+\n| item_id    | item_name      | item_category |\n+------------+----------------+---------------+\n| 1          | LC Alg. Book   | Book          |\n| 2          | LC DB. Book    | Book          |\n| 3          | LC SmarthPhone | Phone         |\n| 4          | LC Phone 2020  | Phone         |\n| 5          | LC SmartGlass  | Glasses       |\n| 6          | LC T-Shirt XL  | T-Shirt       |\n+------------+----------------+---------------+\n```\n\nResult 表：\n\n```\n+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n| Category   | Monday    | Tuesday   | Wednesday | Thursday  | Friday    | Saturday  | Sunday    |\n+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n| Book       | 20        | 5         | 0         | 0         | 10        | 0         | 0         |\n| Glasses    | 0         | 0         | 0         | 0         | 5         | 0         | 0         |\n| Phone      | 0         | 0         | 5         | 1         | 0         | 0         | 10        |\n| T-Shirt    | 0         | 0         | 0         | 0         | 0         | 0         | 0         |\n+------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n```\n\n在周一(2020-06-01, 2020-06-08)，Book分类(ids: 1, 2)下，总共销售了20个单位(10 + 10)\n\n在周二(2020-06-02)，Book分类(ids: 1, 2)下，总共销售了5个单位\n\n在周三(2020-06-03)，Phone分类(ids: 3, 4)下，总共销售了5个单位\n\n在周四(2020-06-04)，Phone分类(ids: 3, 4)下，总共销售了1个单位\n\n在周五(2020-06-05)，Book分类(ids: 1, 2)下，总共销售了10个单位，Glasses分类(ids: 5)下，总共销售了5个单位\n\n在周六, 没有商品销售\n\n在周天(2020-06-14, 2020-06-21)，Phone分类(ids: 3, 4)下，总共销售了10个单位(5 + 5)\n\n没有销售 T-Shirt 类别的商品\n\n','examDataFiles/auto_upload_1623_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1623_1637126775643.sql',3,1,0),(1625,'0','按日期分组销售产品','表Activities：\n\n```\n+-------------+---------+\n| 列名         | 类型    |\n+-------------+---------+\n| sell_date   | date    |\n| product     | varchar |\n+-------------+---------+\n```\n\n此表没有主键，它可能包含重复项。\n\n此表的每一行都包含产品名称和在市场上销售的日期。\n\n编写一个 SQL 查询来查找每个日期、销售的不同产品的数量及其名称。\n\n每个日期的销售产品名称应按词典序排列。\n\n返回按sell_date 排序的结果表。\n\n查询结果格式如下例所示。\n\nActivities 表：\n\n```\n+------------+-------------+\n| sell_date  | product     |\n+------------+-------------+\n| 2020-05-30 | Headphone   |\n| 2020-06-01 | Pencil      |\n| 2020-06-02 | Mask        |\n| 2020-05-30 | Basketball  |\n| 2020-06-01 | Bible       |\n| 2020-06-02 | Mask        |\n| 2020-05-30 | T-Shirt     |\n+------------+-------------+\n```\n\nResult 表：\n\n```\n+------------+----------+------------------------------+\n| sell_date  | num_sold | products                     |\n+------------+----------+------------------------------+\n| 2020-05-30 | 3        | Basketball,Headphone,T-shirt |\n| 2020-06-01 | 2        | Bible,Pencil                 |\n| 2020-06-02 | 1        | Mask                         |\n+------------+----------+------------------------------+\n```\n\n对于2020-05-30，出售的物品是 (Headphone, Basketball, T-shirt)，按词典序排列，并用逗号 \',\' 分隔。\n\n对于2020-06-01，出售的物品是 (Pencil, Bible)，按词典序排列，并用逗号分隔。\n\n对于2020-06-02，出售的物品是 (Mask)，只需返回该物品名。\n\n','examDataFiles/auto_upload_1625_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1625_1637126775643.sql',1,1,0),(1639,'0','上月播放的儿童适宜电影','表: TVProgram\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| program_date  | date    |\n| content_id    | int     |\n| channel       | varchar |\n+---------------+---------+\n```\n\n(program_date, content_id) 是该表主键.\n\n该表包含电视上的节目信息.\n\ncontent_id 是电视一些频道上的节目的 id.\n\n表: Content\n\n```\n+------------------+---------+\n| Column Name      | Type    |\n+------------------+---------+\n| content_id       | varchar |\n| title            | varchar |\n| Kids_content     | enum    |\n| content_type     | varchar |\n+------------------+---------+\n```\n\ncontent_id 是该表主键.\n\nKids_content 是枚举类型, 取值为(\'Y\', \'N\'), 其中: \n\n\'Y\' 表示儿童适宜内容, 而\'N\'表示儿童不宜内容.\n\ncontent_type表示内容的类型, 比如电影, 电视剧等.\n\n写一个 SQL 语句,报告在 2020 年 6 月份播放的儿童适宜电影的去重电影名.\n\n返回的结果表单没有顺序要求.\n\n查询结果的格式如下例所示.\n\nTVProgram 表:\n\n```\n+--------------------+--------------+-------------+\n| program_date       | content_id   | channel     |\n+--------------------+--------------+-------------+\n| 2020-06-10 08:00   | 1            | LC-Channel  |\n| 2020-05-11 12:00   | 2            | LC-Channel  |\n| 2020-05-12 12:00   | 3            | LC-Channel  |\n| 2020-05-13 14:00   | 4            | Disney Ch   |\n| 2020-06-18 14:00   | 4            | Disney Ch   |\n| 2020-07-15 16:00   | 5            | Disney Ch   |\n+--------------------+--------------+-------------+\n```\n\nContent 表:\n\n```\n+------------+----------------+---------------+---------------+\n| content_id | title          | Kids_content  | content_type  |\n+------------+----------------+---------------+---------------+\n| 1          | Leetcode Movie | N             | Movies        |\n| 2          | Alg. for Kids  | Y             | Series        |\n| 3          | Database Sols  | N             | Series        |\n| 4          | Aladdin        | Y             | Movies        |\n| 5          | Cinderella     | Y             | Movies        |\n+------------+----------------+---------------+---------------+\n```\n\nResult 表:\n\n```\n+--------------+\n| title        |\n+--------------+\n| Aladdin      |\n+--------------+\n```\n\n\"Leetcode Movie\" 是儿童不宜的电影.\n\n\"Alg. for Kids\" 不是电影.\n\n\"Database Sols\" 不是电影\n\n\"Alladin\" 是电影, 儿童适宜, 并且在 2020 年 6 月份播放.\n\n\"Cinderella\" 不在 2020 年 6 月份播放.\n\n','examDataFiles/auto_upload_1639_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1639_1637126775643.sql',1,1,0),(1641,'0','可以放心投资的国家','表Person:\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| id             | int     |\n| name           | varchar |\n| phone_number   | varchar |\n+----------------+---------+\n```\n\nid 是该表主键.\n\n该表每一行包含一个人的名字和电话号码.\n\n电话号码的格式是:\'xxx-yyyyyyy\', 其中xxx是国家码(3个字符), yyyyyyy是电话号码(7个字符), x和y都表示数字. 同时, 国家码和电话号码都可以包含前导0.\n\n表Country:\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| name           | varchar |\n| country_code   | varchar |\n+----------------+---------+\n```\n\ncountry_code是该表主键.\n\n该表每一行包含国家名和国家码. country_code的格式是\'xxx\', x是数字.\n\n表Calls:\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| caller_id   | int  |\n| callee_id   | int  |\n| duration    | int  |\n+-------------+------+\n```\n\n该表无主键, 可能包含重复行.\n\n每一行包含呼叫方id, 被呼叫方id和以分钟为单位的通话时长. caller_id != callee_id\n\n一家电信公司想要投资新的国家. 该公司想要投资的国家是: 该国的平均通话时长要严格地大于全球平均通话时长.\n\n写一段 SQL,找到所有该公司可以投资的国家.\n\n返回的结果表没有顺序要求.\n\n查询的结果格式如下例所示.\n\nPerson 表:\n\n```\n+----+----------+--------------+\n| id | name     | phone_number |\n+----+----------+--------------+\n| 3  | Jonathan | 051-1234567  |\n| 12 | Elvis    | 051-7654321  |\n| 1  | Moncef   | 212-1234567  |\n| 2  | Maroua   | 212-6523651  |\n| 7  | Meir     | 972-1234567  |\n| 9  | Rachel   | 972-0011100  |\n+----+----------+--------------+\n```\n\nCountry 表:\n\n```\n+----------+--------------+\n| name     | country_code |\n+----------+--------------+\n| Peru     | 051          |\n| Israel   | 972          |\n| Morocco  | 212          |\n| Germany  | 049          |\n| Ethiopia | 251          |\n+----------+--------------+\n```\n\nCalls 表:\n\n```\n+-----------+-----------+----------+\n| caller_id | callee_id | duration |\n+-----------+-----------+----------+\n| 1         | 9         | 33       |\n| 2         | 9         | 4        |\n| 1         | 2         | 59       |\n| 3         | 12        | 102      |\n| 3         | 12        | 330      |\n| 12        | 3         | 5        |\n| 7         | 9         | 13       |\n| 7         | 1         | 3        |\n| 9         | 7         | 1        |\n| 1         | 7         | 7        |\n+-----------+-----------+----------+\n```\n\nResult 表:\n\n```\n+----------+\n| country  |\n+----------+\n| Peru     |\n+----------+\n```\n\n国家Peru的平均通话时长是 (102 + 102 + 330 + 330 + 5 + 5) / 6 = 145.666667\n\n国家Israel的平均通话时长是 (33 + 4 + 13 + 13 + 3 + 1 + 1 + 7) / 8 = 9.37500\n\n国家Morocco的平均通话时长是 (33 + 4 + 59 + 59 + 3 + 7) / 6 = 27.5000 \n\n全球平均通话时长 = (2 * (33 + 4 + 59 + 102 + 330 + 5 + 13 + 3 + 1 + 7)) / 20 = 55.70000\n\n所以, Peru是唯一的平均通话时长大于全球平均通话时长的国家, 也是唯一的推荐投资的国家.\n\n','examDataFiles/auto_upload_1641_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1641_1637126775643.sql',2,1,0),(1654,'0','消费者下单频率','表: Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n| country       | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键.\n\n该表包含公司消费者的信息.\n\n表: Product\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| description   | varchar |\n| price         | int     |\n+---------------+---------+\n```\n\nproduct_id 是该表主键.\n\n该表包含公司产品的信息.\n\nprice 是本产品的花销.\n\n表: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| customer_id   | int     |\n| product_id    | int     |\n| order_date    | date    |\n| quantity      | int     |\n+---------------+---------+\n```\n\norder_id 是该表主键.\n\n该表包含消费者下单的信息.\n\ncustomer_id 是买了数量为\"quantity\", id为\"product_id\"产品的消费者的 id.\n\nOrder_date 是订单发货的日期, 格式为(\'YYYY-MM-DD\').\n\n写一个 SQL 语句, 报告消费者的 id 和名字,其中消费者在 2020 年 6 月和 7 月,每月至少花费了$100.\n\n结果表无顺序要求.\n\n查询结果格式如下例所示.\n\nCustomers\n\n```\n+--------------+-----------+-------------+\n| customer_id  | name     | country   |\n+--------------+-----------+-------------+\n| 1           | Winston  | USA        |\n| 2           | Jonathan  | Peru       |\n| 3           | Moustafa | Egypt      |\n+--------------+-----------+-------------+\n```\n\nProduct\n\n```\n+--------------+-------------+-------------+\n| product_id   | description | price     |\n+--------------+-------------+-------------+\n| 10          | LC Phone   | 300        |\n| 20          | LC T-Shirt  | 10         |\n| 30          | LC Book    | 45         |\n| 40           | LC Keychain| 2          |\n+--------------+-------------+-------------+\n```\n\nOrders\n\n```\n+--------------+-------------+-------------+-------------+-----------+\n| order_id     | customer_id | product_id  | order_date  | quantity  |\n+--------------+-------------+-------------+-------------+-----------+\n| 1           | 1          | 10         | 2020-06-10  | 1         |\n| 2           | 1           | 20         | 2020-07-01  | 1         |\n| 3           | 1           | 30         | 2020-07-08  | 2         |\n| 4           | 2          | 10         | 2020-06-15  | 2         |\n| 5           | 2           | 40         | 2020-07-01  | 10        |\n| 6           | 3           | 20         | 2020-06-24  | 2         |\n| 7           | 3          | 30         | 2020-06-25  | 2         |\n| 9           | 3           | 30         | 2020-05-08  | 3         |\n+--------------+-------------+-------------+-------------+-----------+\n```\n\nResult 表:\n\n```\n+--------------+------------+\n| customer_id  | name       |  \n+--------------+------------+\n| 1            | Winston    |\n+--------------+------------+ \n```\n\nWinston 在2020年6月花费了$300(300 * 1), 在7月花费了$100(10 * 1 + 45 * 2).\n\nJonathan 在2020年6月花费了$600(300 * 2), 在7月花费了$20(2 * 10).\n\nMoustafa 在2020年6月花费了$110 (10 * 2 + 45 * 2), 在7月花费了$0.\n\n','examDataFiles/auto_upload_1654_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1654_1637126775643.sql',1,1,0),(1664,'0','查找拥有有效邮箱的用户','用户表：Users\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user_id       | int     |\n| name          | varchar |\n| mail          | varchar | \n+---------------+---------+\n```\n\nuser_id （用户 ID）是该表的主键。\n\n这个表包含用户在某网站上注册的信息。有些邮箱是无效的。\n\n写一条SQL 语句，查询拥有有效邮箱的用户。\n\n有效的邮箱包含符合下列条件的前缀名和域名：\n\n前缀名是包含字母（大写或小写）、数字、下划线\'_\'、句点\'.\'和/或横杠\'-\'的字符串。前缀名必须以字母开头。\n\n域名是\'@leetcode.com\'。\n\n按任意顺序返回结果表。\n\n查询格式如下所示：\n\nUsers\n\n```\n+---------+-----------+-------------------------+\n| user_id | name      | mail                    |\n+---------+-----------+-------------------------+\n| 1       | Winston   | winston@leetcode.com    |\n| 2       | Jonathan  | jonathanisgreat         |\n| 3       | Annabelle | bella-@leetcode.com     |\n| 4       | Sally     | sally.come@leetcode.com |\n| 5       | Marwan    | quarz#2020@leetcode.com |\n| 6       | David     | david69@gmail.com       |\n| 7       | Shapiro   | .shapo@leetcode.com     |\n+---------+-----------+-------------------------+\n```\n\n结果表：\n\n```\n+---------+-----------+-------------------------+\n| user_id | name      | mail                    |\n+---------+-----------+-------------------------+\n| 1       | Winston   | winston@leetcode.com    |\n| 3       | Annabelle | bella-@leetcode.com     |\n| 4       | Sally     | sally.come@leetcode.com |\n+---------+-----------+-------------------------+\n```\n\n2 号用户的邮箱没有域名。\n\n5 号用户的邮箱包含非法字符 #。\n\n6 号用户的邮箱的域名不是 leetcode。\n\n7 号用户的邮箱以句点（.）开头。\n\n','examDataFiles/auto_upload_1664_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1664_1637126775643.sql',1,1,0),(1670,'0','患某种疾病的患者','患者信息表：Patients\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| patient_id   | int     |\n| patient_name | varchar |\n| conditions   | varchar |\n+--------------+---------+\n```\n\npatient_id （患者 ID）是该表的主键。\n\n\'conditions\' （疾病）包含 0 个或以上的疾病代码，以空格分隔。\n\n这个表包含医院中患者的信息。\n\n写一条SQL 语句，查询患有 I 类糖尿病的患者ID （patient_id）、患者姓名（patient_name）以及其患有的所有疾病代码（conditions）。I 类糖尿病的代码总是包含前缀DIAB1。\n\n按任意顺序返回结果表。\n\n查询结果格式如下示例所示：\n\nPatients\n\n```\n+------------+--------------+--------------+\n| patient_id | patient_name | conditions   |\n+------------+--------------+--------------+\n| 1          | Daniel      | YFEV COUGH   |\n| 2         | Alice        |             |\n| 3         | Bob         | DIAB100 MYOP|\n| 4         | George      | ACNE DIAB100|\n| 5         | Alain       | DIAB201     |\n+------------+--------------+--------------+\n```\n\n结果表：\n\n```\n+------------+--------------+--------------+\n| patient_id | patient_name | conditions   |\n+------------+--------------+--------------+\n| 3         | Bob         | DIAB100 MYOP|\n| 4         | George      | ACNE DIAB100| \n+------------+--------------+--------------+\n```\n\nBob 和 George 都患有代码以 DIAB1 开头的疾病。\n\n','examDataFiles/auto_upload_1670_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1670_1637126775643.sql',1,1,0),(1671,'0','最近的三笔订单','表：Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键\n\n该表包含消费者的信息\n\n表：Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| customer_id   | int     |\n| cost          | int     |\n+---------------+---------+\n```\n\norder_id 是该表主键\n\n该表包含id为customer_id的消费者的订单信息\n\n每一个消费者 每天一笔订单\n\n写一个 SQL 语句，找到每个用户的最近三笔订单。如果用户的订单少于 3 笔，则返回他的全部订单。\n\n返回的结果按照 customer_name升序排列。如果排名有相同，则继续按照 customer_id 升序排列。如果排名还有相同，则继续按照 order_date 降序排列。\n\n查询结果格式如下例所示：\n\nCustomers\n\n```\n+-------------+-----------+\n| customer_id | name      |\n+-------------+-----------+\n| 1           | Winston   |\n| 2           | Jonathan  |\n| 3           | Annabelle |\n| 4           | Marwan    |\n| 5           | Khaled    |\n+-------------+-----------+\n```\n\nOrders\n\n```\n+----------+------------+-------------+------+\n| order_id | order_date | customer_id | cost |\n+----------+------------+-------------+------+\n| 1        | 2020-07-31 | 1           | 30   |\n| 2        | 2020-07-30 | 2           | 40   |\n| 3        | 2020-07-31 | 3           | 70   |\n| 4        | 2020-07-29 | 4           | 100  |\n| 5        | 2020-06-10 | 1           | 1010 |\n| 6        | 2020-08-01 | 2           | 102  |\n| 7        | 2020-08-01 | 3           | 111  |\n| 8        | 2020-08-03 | 1           | 99   |\n| 9        | 2020-08-07 | 2           | 32   |\n| 10       | 2020-07-15 | 1           | 2    |\n+----------+------------+-------------+------+\n```\n\nResult table：\n\n```\n+---------------+-------------+----------+------------+\n| customer_name | customer_id | order_id | order_date |\n+---------------+-------------+----------+------------+\n| Annabelle     | 3           | 7        | 2020-08-01 |\n| Annabelle     | 3           | 3        | 2020-07-31 |\n| Jonathan      | 2           | 9        | 2020-08-07 |\n| Jonathan      | 2           | 6        | 2020-08-01 |\n| Jonathan      | 2           | 2        | 2020-07-30 |\n| Marwan        | 4           | 4        | 2020-07-29 |\n| Winston       | 1           | 8        | 2020-08-03 |\n| Winston       | 1           | 1        | 2020-07-31 |\n| Winston       | 1           | 10       | 2020-07-15 |\n+---------------+-------------+----------+------------+\n```\n\nWinston 有 4 笔订单, 排除了 \"2020-06-10\" 的订单, 因为它是最老的订单。\n\nAnnabelle 只有 2 笔订单, 全部返回。\n\nJonathan 恰好有 3 笔订单。\n\nMarwan 只有 1 笔订单。\n\n结果表我们按照 customer_name 升序排列，customer_id 升序排列，order_date 降序排列。\n\n进阶：\n\n你能写出来最近n笔订单的通用解决方案吗?\n\n','examDataFiles/auto_upload_1671_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1671_1637126775643.sql',2,1,0),(1686,'0','产品名称格式修复','表：Sales\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| sale_id      | int     |\n| product_name | varchar |\n| sale_date    | date    |\n+--------------+---------+\n```\n\nsale_id 是该表主键\n\n该表的每一行包含了产品的名称及其销售日期\n\n因为在 2000 年该表是手工填写的，product_name可能包含前后空格，而且包含大小写。\n\n写一个 SQL 语句报告每个月的销售情况：\n\nproduct_name是小写字母且不包含前后空格\n\nsale_date格式为(\'YYYY-MM\')\n\ntotal是产品在本月销售的次数\n\n返回结果以product_name升序 排列，如果有排名相同，再以sale_date 升序 排列。\n\n查询结果格式如下所示：\n\nSales 表：\n\n```\n+------------+------------------+--------------+\n| sale_id    | product_name     | sale_date    |\n+------------+------------------+--------------+\n| 1          |      LCPHONE     | 2000-01-16   |\n| 2         |    LCPhone       | 2000-01-17   |\n| 3         |     LcPhOnE     | 2000-02-18   |\n| 4         |      LCKeyCHAiN  | 2000-02-19   |\n| 5         |   LCKeyChain     | 2000-02-28   |\n| 6         | Matryoshka      | 2000-03-31   | \n+------------+------------------+--------------+\n```\n\nResult 表：\n\n```\n+--------------+--------------+----------+\n| product_name | sale_date    | total    |\n+--------------+--------------+----------+\n| lcphone     | 2000-01     | 2       |\n| lckeychain   | 2000-02     | 2       | \n| lcphone      | 2000-02     | 1       | \n| matryoshka   | 2000-03     | 1       | \n+--------------+--------------+----------+\n```\n\n1 月份，卖了 2 个 LcPhones，请注意产品名称是小写的，中间可能包含空格\n\n2 月份，卖了 2 个 LCKeychains 和 1 个 LCPhone\n\n3 月份，卖了 1 个 matryoshka\n\n','examDataFiles/auto_upload_1686_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1686_1637126775643.sql',1,1,0),(1688,'0','每件商品的最新订单','表: Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键.\n\n该表包含消费者的信息.\n\n表: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| customer_id   | int     |\n| product_id    | int     |\n+---------------+---------+\n```\n\norder_id 是该表主键.\n\n该表包含消费者customer_id产生的订单.\n\n不会有商品被相同的用户在一天内下单超过一次.\n\n表: Products\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| product_name  | varchar |\n| price         | int     |\n+---------------+---------+\n```\n\nproduct_id 是该表主键.\n\n该表包含所有商品的信息.\n\n写一个SQL 语句,找到每件商品的最新订单(可能有多个).\n\n返回的结果以product_name 升序排列,如果有排序相同,再以product_id 升序排列.如果还有排序相同,再以order_id 升序排列.\n\n查询结果格式如下例所示:\n\nCustomers\n\n```\n+-------------+-----------+\n| customer_id | name      |\n+-------------+-----------+\n| 1           | Winston   |\n| 2           | Jonathan  |\n| 3           | Annabelle |\n| 4           | Marwan    |\n| 5           | Khaled    |\n+-------------+-----------+\n```\n\nOrders\n\n```\n+----------+------------+-------------+------------+\n| order_id | order_date | customer_id | product_id |\n+----------+------------+-------------+------------+\n| 1        | 2020-07-31 | 1           | 1          |\n| 2        | 2020-07-30 | 2           | 2          |\n| 3        | 2020-08-29 | 3           | 3          |\n| 4        | 2020-07-29 | 4           | 1          |\n| 5        | 2020-06-10 | 1           | 2          |\n| 6        | 2020-08-01 | 2           | 1          |\n| 7        | 2020-08-01 | 3           | 1          |\n| 8        | 2020-08-03 | 1           | 2          |\n| 9        | 2020-08-07 | 2           | 3          |\n| 10       | 2020-07-15 | 1           | 2          |\n+----------+------------+-------------+------------+\n```\n\nProducts\n\n```\n+------------+--------------+-------+\n| product_id | product_name | price |\n+------------+--------------+-------+\n| 1          | keyboard     | 120   |\n| 2          | mouse        | 80    |\n| 3          | screen       | 600   |\n| 4          | hard disk    | 450   |\n+------------+--------------+-------+\n```\n\nResult\n\n```\n+--------------+------------+----------+------------+\n| product_name | product_id | order_id | order_date |\n+--------------+------------+----------+------------+\n| keyboard     | 1          | 6        | 2020-08-01 |\n| keyboard     | 1          | 7        | 2020-08-01 |\n| mouse        | 2          | 8        | 2020-08-03 |\n| screen       | 3          | 3        | 2020-08-29 |\n+--------------+------------+----------+------------+\n```\n\nkeyboard 的最新订单在2020-08-01, 在这天有两次下单.\n\nmouse 的最新订单在2020-08-03, 在这天只有一次下单.\n\nscreen 的最新订单在2020-08-29, 在这天只有一次下单.\n\nhard disk 没有被下单, 我们不把它包含在结果表中.\n\n','examDataFiles/auto_upload_1688_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1688_1637126775643.sql',2,1,0),(1702,'0','银行账户概要','用户表：Users\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| user_id      | int     |\n| user_name    | varchar |\n| credit       | int     |\n+--------------+---------+\n```\n\nuser_id 是这个表的主键。\n\n表中的每一列包含每一个用户当前的额度信息。\n\n交易表：Transactions\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| trans_id      | int     |\n| paid_by       | int     |\n| paid_to       | int     |\n| amount        | int     |\n| transacted_on | date    |\n+---------------+---------+\n```\n\ntrans_id 是这个表的主键。\n\n表中的每一列包含银行的交易信息。\n\nID 为 paid_by 的用户给 ID 为 paid_to 的用户转账。\n\n力扣银行 (LCB) 帮助程序员们完成虚拟支付。我们的银行在表Transaction中记录每条交易信息，我们要查询每个用户的当前余额，并检查他们是否已透支（当前额度小于 0）。\n\n写一条 SQL 语句，查询：\n\nuser_id用户 ID\n\nuser_name用户名\n\ncredit完成交易后的余额\n\ncredit_limit_breached检查是否透支 （\"Yes\" 或\"No\"）\n\n以任意顺序返回结果表。\n\n查询格式见如下示例：\n\nUsers 表：\n\n```\n+------------+--------------+-------------+\n| user_id    | user_name    | credit      |\n+------------+--------------+-------------+\n| 1          | Moustafa     | 100         |\n| 2          | Jonathan     | 200         |\n| 3          | Winston      | 10000       |\n| 4          | Luis         | 800         | \n+------------+--------------+-------------+\n```\n\nTransactions 表：\n\n```\n+------------+------------+------------+----------+---------------+\n| trans_id   | paid_by    | paid_to    | amount   | transacted_on |\n+------------+------------+------------+----------+---------------+\n| 1          | 1          | 3          | 400      | 2020-08-01    |\n| 2          | 3          | 2          | 500      | 2020-08-02    |\n| 3          | 2          | 1          | 200      | 2020-08-03    |\n+------------+------------+------------+----------+---------------+\n```\n\n结果表：\n\n```\n+------------+------------+------------+-----------------------+\n| user_id    | user_name  | credit     | credit_limit_breached |\n+------------+------------+------------+-----------------------+\n| 1          | Moustafa   | -100       | Yes                   | \n| 2          | Jonathan   | 500        | No                    |\n| 3          | Winston    | 9900       | No                    |\n| 4          | Luis       | 800        | No                    |\n+------------+------------+------------+-----------------------+\n```\n\nMoustafa 在 \"2020-08-01\" 支付了 $400 并在 \"2020-08-03\" 收到了 $200 ，当前额度 (100 -400 +200) = -$100\n\nJonathan 在 \"2020-08-02\" 收到了 $500 并在 \"2020-08-08\" 支付了 $200 ，当前额度 (200 +500 -200) = $500\n\nWinston 在 \"2020-08-01\" 收到了 $400 并在 \"2020-08-03\" 支付了 $500 ，当前额度 (10000 +400 -500) = $9900\n\nLuis 未收到任何转账信息，额度 = $800\n\n','examDataFiles/auto_upload_1702_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1702_1637126775643.sql',2,1,0),(1712,'0','按月统计订单数与顾客数','表：Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| customer_id   | int     |\n| invoice       | int     |\n+---------------+---------+\n```\n\norder_id 是 Orders 表的主键。\n\n这张表包含顾客(customer_id)所下订单的信息。\n\n写一个查询语句来 按月 统计 金额大于 $20 的唯一 订单数 和唯一 顾客数 。\n\n查询结果无排序要求。\n\n查询结果格式如下面例子所示：\n\nOrders\n\n```\n+----------+------------+-------------+------------+\n| order_id | order_date | customer_id | invoice    |\n+----------+------------+-------------+------------+\n| 1        | 2020-09-15 | 1           | 30         |\n| 2        | 2020-09-17 | 2           | 90         |\n| 3        | 2020-10-06 | 3           | 20         |\n| 4        | 2020-10-20 | 3           | 21         |\n| 5        | 2020-11-10 | 1           | 10         |\n| 6        | 2020-11-21 | 2           | 15         |\n| 7        | 2020-12-01 | 4           | 55         |\n| 8        | 2020-12-03 | 4           | 77         |\n| 9        | 2021-01-07 | 3           | 31         |\n| 10       | 2021-01-15 | 2           | 20         |\n+----------+------------+-------------+------------+\n```\n\nResult 表：\n\n```\n+---------+-------------+----------------+\n| month   | order_count | customer_count |\n+---------+-------------+----------------+\n| 2020-09 | 2           | 2              |\n| 2020-10 | 1           | 1              |\n| 2020-12 | 2           | 1              |\n| 2021-01 | 1           | 1              |\n+---------+-------------+----------------+\n```\n\n在 2020 年 09 月，有 2 份来自 2 位不同顾客的金额大于 $20 的订单。\n\n在 2020 年 10 月，有 2 份来自 1 位顾客的订单，并且只有其中的 1 份订单金额大于 $20 。\n\n在 2020 年 11 月，有 2 份来自 2 位不同顾客的订单，但由于金额都小于 $20 ，所以我们的查询结果中不包含这个月的数据。\n\n在 2020 年 12 月，有 2 份来自 1 位顾客的订单，且 2 份订单金额都大于 $20 。\n\n在 2021 年 01 月，有 2 份来自 2 位不同顾客的订单，但只有其中一份订单金额大于 $20 。\n\n','examDataFiles/auto_upload_1712_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1712_1637126775643.sql',1,1,0),(1718,'0','仓库经理','表:Warehouse\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| name         | varchar |\n| product_id   | int     |\n| units        | int     |\n+--------------+---------+\n```\n\n(name, product_id) 是该表主键.\n\n该表的行包含了每个仓库的所有商品信息.\n\n表: Products\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| product_name  | varchar |\n| Width         | int     |\n| Length        | int     |\n| Height        | int     |\n+---------------+---------+\n```\n\nproduct_id 是该表主键.\n\n该表的行包含了每件商品以英尺为单位的尺寸(宽度, 长度和高度)信息.\n\n写一个 SQL查询来报告,每个仓库的存货量是多少立方英尺.\n\n仓库名\n\n存货量\n\n返回结果没有顺序要求.\n\n查询结果如下例所示.\n\nWarehouse 表:\n\n```\n+------------+--------------+-------------+\n| name       | product_id   | units       |\n+------------+--------------+-------------+\n| LCHouse1   | 1            | 1           |\n| LCHouse1   | 2            | 10          |\n| LCHouse1   | 3            | 5           |\n| LCHouse2   | 1            | 2           |\n| LCHouse2   | 2            | 2           |\n| LCHouse3   | 4            | 1           |\n+------------+--------------+-------------+\n```\n\nProducts 表:\n\n```\n+------------+--------------+------------+----------+-----------+\n| product_id | product_name | Width      | Length   | Height    |\n+------------+--------------+------------+----------+-----------+\n| 1          | LC-TV        | 5          | 50       | 40        |\n| 2          | LC-KeyChain  | 5          | 5        | 5         |\n| 3          | LC-Phone     | 2          | 10       | 10        |\n| 4          | LC-T-Shirt   | 4          | 10       | 20        |\n+------------+--------------+------------+----------+-----------+\n```\n\nResult 表:\n\n```\n+----------------+------------+\n| WAREHOUSE_NAME | VOLUME     | \n+----------------+------------+\n| LCHouse1       | 12250      | \n| LCHouse2       | 20250      |\n| LCHouse3       | 800        |\n+----------------+------------+\n```\n\nId为1的商品(LC-TV)的存货量为 5x50x40 = 10000\n\nId为2的商品(LC-KeyChain)的存货量为 5x5x5 = 125 \n\nId为3的商品(LC-Phone)的存货量为 2x10x10 = 200\n\nId为4的商品(LC-T-Shirt)的存货量为 4x10x20 = 800\n\n仓库LCHouse1: 1个单位的LC-TV + 10个单位的LC-KeyChain + 5个单位的LC-Phone.\n\n         总存货量为: 1*10000 + 10*125  + 5*200 = 12250 立方英尺\n\n仓库LCHouse2: 2个单位的LC-TV + 2个单位的LC-KeyChain.\n\n         总存货量为: 2*10000 + 2*125 = 20250 立方英尺\n\n仓库LCHouse3: 1个单位的LC-T-Shirt.\n\n          总存货量为: 1*800 = 800 立方英尺.\n\n','examDataFiles/auto_upload_1718_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1718_1637126775643.sql',1,1,0),(1724,'0','进店却未进行过交易的顾客','表：Visits\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| visit_id    | int     |\n| customer_id | int     |\n+-------------+---------+\n```\n\nvisit_id 是该表的主键。\n\n该表包含有关光临过购物中心的顾客的信息。\n\n表：Transactions\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| transaction_id | int     |\n| visit_id       | int     |\n| amount         | int     |\n+----------------+---------+\n```\n\ntransaction_id 是此表的主键。\n\n此表包含 visit_id 期间进行的交易的信息。\n\n有一些顾客可能光顾了购物中心但没有进行交易。请你编写一个 SQL 查询，来查找这些顾客的 ID ，以及他们只光顾不交易的次数。\n\n返回以任何顺序排序的结果表。\n\n查询结果格式如下例所示：\n\nVisits\n\n```\n+----------+-------------+\n| visit_id | customer_id |\n+----------+-------------+\n| 1        | 23          |\n| 2        | 9           |\n| 4        | 30          |\n| 5        | 54          |\n| 6        | 96          |\n| 7        | 54          |\n| 8        | 54          |\n+----------+-------------+\n```\n\nTransactions\n\n```\n+----------------+----------+--------+\n| transaction_id | visit_id | amount |\n+----------------+----------+--------+\n| 2              | 5        | 310    |\n| 3              | 5        | 300    |\n| 9              | 5        | 200    |\n| 12             | 1        | 910    |\n| 13             | 2        | 970    |\n+----------------+----------+--------+\n```\n\nResult 表：\n\n```\n+-------------+----------------+\n| customer_id | count_no_trans |\n+-------------+----------------+\n| 54          | 2              |\n| 30          | 1              |\n| 96          | 1              |\n+-------------+----------------+\n```\n\nID = 23 的顾客曾经逛过一次购物中心，并在 ID = 12 的访问期间进行了一笔交易。\n\nID = 9 的顾客曾经逛过一次购物中心，并在 ID = 13 的访问期间进行了一笔交易。\n\nID = 30 的顾客曾经去过购物中心，并且没有进行任何交易。\n\nID = 54 的顾客三度造访了购物中心。在 2 次访问中，他们没有进行任何交易，在 1 次访问中，他们进行了 3 次交易。\n\nID = 96 的顾客曾经去过购物中心，并且没有进行任何交易。\n\n如我们所见，ID 为 30 和 96 的顾客一次没有进行任何交易就去了购物中心。顾客 54 也两次访问了购物中心并且没有进行任何交易。\n\n','examDataFiles/auto_upload_1724_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1724_1637126775643.sql',1,1,0),(1734,'0','银行账户概要 II','表: Users\n\n```\n+--------------+---------+\n| Column Name  | Type    |\n+--------------+---------+\n| account      | int     |\n| name         | varchar |\n+--------------+---------+\n```\n\naccount 是该表的主键.\n\n表中的每一行包含银行里中每一个用户的账号.\n\n表: Transactions\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| trans_id      | int     |\n| account       | int     |\n| amount        | int     |\n| transacted_on | date    |\n+---------------+---------+\n```\n\ntrans_id 是该表主键.\n\n该表的每一行包含了所有账户的交易改变情况.\n\n如果用户收到了钱, 那么金额是正的; 如果用户转了钱, 那么金额是负的.\n\n所有账户的起始余额为 0.\n\n写一个 SQL,报告余额高于 10000 的所有用户的名字和余额.账户的余额等于包含该账户的所有交易的总和.\n\n返回结果表单没有顺序要求.\n\n查询结果格式如下例所示.\n\nUsers table:\n\n```\n+------------+--------------+\n| account    | name         |\n+------------+--------------+\n| 900001     | Alice        |\n| 900002     | Bob          |\n| 900003     | Charlie      |\n+------------+--------------+\n```\n\nTransactions table:\n\n```\n+------------+------------+------------+---------------+\n| trans_id   | account    | amount     | transacted_on |\n+------------+------------+------------+---------------+\n| 1          | 900001     | 7000       |  2020-08-01   |\n| 2          | 900001     | 7000       |  2020-09-01   |\n| 3          | 900001     | -3000      |  2020-09-02   |\n| 4          | 900002     | 1000       |  2020-09-12   |\n| 5          | 900003     | 6000       |  2020-08-07   |\n| 6          | 900003     | 6000       |  2020-09-07   |\n| 7          | 900003     | -4000      |  2020-09-11   |\n+------------+------------+------------+---------------+\n```\n\nResult table:\n\n```\n+------------+------------+\n| name       | balance    |\n+------------+------------+\n| Alice      | 11000      |\n+------------+------------+\n```\n\nAlice 的余额为(7000 + 7000 - 3000) = 11000.\n\nBob 的余额为1000.\n\nCharlie 的余额为(6000 + 6000 - 4000) = 8000.\n\n','examDataFiles/auto_upload_1734_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1734_1637126775643.sql',1,1,0),(1735,'0','每位顾客最经常订购的商品','表：Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| name          | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键\n\n该表包含所有顾客的信息\n\n表：Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| order_date    | date    |\n| customer_id   | int     |\n| product_id    | int     |\n+---------------+---------+\n```\n\norder_id 是该表主键\n\n该表包含顾客 customer_id 的订单信息\n\n没有顾客会在一天内订购相同的商品 多于一次\n\n表：Products\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| product_id    | int     |\n| product_name  | varchar |\n| price         | int     |\n+---------------+---------+\n```\n\nproduct_id 是该表主键\n\n该表包含了所有商品的信息\n\n写一个 SQL 语句，找到每一个顾客最经常订购的商品。\n\n结果表单应该有每一位至少下过一次单的顾客 customer_id,他最经常订购的商品的product_id和product_name。\n\n返回结果 没有顺序要求。\n\n查询结果格式如下例所示：\n\nCustomers\n\n```\n+-------------+-------+\n| customer_id | name  |\n+-------------+-------+\n| 1           | Alice |\n| 2           | Bob   |\n| 3           | Tom   |\n| 4           | Jerry |\n| 5           | John  |\n+-------------+-------+\n```\n\nOrders\n\n```\n+----------+------------+-------------+------------+\n| order_id | order_date | customer_id | product_id |\n+----------+------------+-------------+------------+\n| 1        | 2020-07-31 | 1           | 1          |\n| 2        | 2020-07-30 | 2           | 2          |\n| 3        | 2020-08-29 | 3           | 3          |\n| 4        | 2020-07-29 | 4           | 1          |\n| 5        | 2020-06-10 | 1           | 2          |\n| 6        | 2020-08-01 | 2           | 1          |\n| 7        | 2020-08-01 | 3           | 3          |\n| 8        | 2020-08-03 | 1           | 2          |\n| 9        | 2020-08-07 | 2           | 3          |\n| 10       | 2020-07-15 | 1           | 2          |\n+----------+------------+-------------+------------+\n```\n\nProducts\n\n```\n+------------+--------------+-------+\n| product_id | product_name | price |\n+------------+--------------+-------+\n| 1          | keyboard     | 120   |\n| 2          | mouse        | 80    |\n| 3          | screen       | 600   |\n| 4          | hard disk    | 450   |\n+------------+--------------+-------+\n```\n\nResult 表：\n\n```\n+-------------+------------+--------------+\n| customer_id | product_id | product_name |\n+-------------+------------+--------------+\n| 1           | 2          | mouse        |\n| 2           | 1          | keyboard     |\n| 2           | 2          | mouse        |\n| 2           | 3          | screen       |\n| 3           | 3          | screen       |\n| 4           | 1          | keyboard     |\n+-------------+------------+--------------+\n```\n\nAlice (customer 1) 三次订购鼠标, 一次订购键盘, 所以鼠标是 Alice 最经常订购的商品.\n\nBob (customer 2) 一次订购键盘, 一次订购鼠标, 一次订购显示器, 所以这些都是 Bob 最经常订购的商品.\n\nTom (customer 3) 只两次订购显示器, 所以显示器是 Tom 最经常订购的商品.\n\nJerry (customer 4) 只一次订购键盘, 所以键盘是 Jerry 最经常订购的商品.\n\nJohn (customer 5) 没有订购过商品, 所以我们并没有把 John 包含在结果表中.\n\n','examDataFiles/auto_upload_1735_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1735_1637126775643.sql',2,1,0),(1749,'0','没有卖出的卖家','表: Customer\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| customer_name | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键.\n\n该表的每行包含网上商城的每一位顾客的信息.\n\n表: Orders\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| order_id      | int     |\n| sale_date     | date    |\n| order_cost    | int     |\n| customer_id   | int     |\n| seller_id     | int     |\n+---------------+---------+\n```\n\norder_id 是该表主键.\n\n该表的每行包含网上商城的所有订单的信息.\n\nsale_date 是顾客customer_id和卖家seller_id之间交易的日期.\n\n表: Seller\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| seller_id     | int     |\n| seller_name   | varchar |\n+---------------+---------+\n```\n\nseller_id 是该表主键.\n\n该表的每行包含每一位卖家的信息.\n\n写一个SQL语句,报告所有在2020年度没有任何卖出的卖家的名字.\n\n返回结果按照seller_name升序排列.\n\n查询结果格式如下例所示.\n\nCustomer 表:\n\n```\n+--------------+---------------+\n| customer_id  | customer_name |\n+--------------+---------------+\n| 101          | Alice         |\n| 102          | Bob           |\n| 103          | Charlie       |\n+--------------+---------------+\n```\n\nOrders 表:\n\n```\n+-------------+------------+--------------+-------------+-------------+\n| order_id    | sale_date  | order_cost   | customer_id | seller_id   |\n+-------------+------------+--------------+-------------+-------------+\n| 1           | 2020-03-01 | 1500         | 101         | 1           |\n| 2           | 2020-05-25 | 2400         | 102         | 2           |\n| 3           | 2019-05-25 | 800          | 101         | 3           |\n| 4           | 2020-09-13 | 1000         | 103         | 2           |\n| 5           | 2019-02-11 | 700          | 101         | 2           |\n+-------------+------------+--------------+-------------+-------------+\n```\n\nSeller 表:\n\n```\n+-------------+-------------+\n| seller_id   | seller_name |\n+-------------+-------------+\n| 1           | Daniel      |\n| 2           | Elizabeth   |\n| 3           | Frank       |\n+-------------+-------------+\n```\n\nResult 表:\n\n```\n+-------------+\n| seller_name |\n+-------------+\n| Frank       |\n+-------------+\n```\n\nDaniel在2020年3月卖出1次.\n\nElizabeth在2020年卖出2次, 在2019年卖出1次.\n\nFrank在2019年卖出1次, 在2020年没有卖出.\n\n','examDataFiles/auto_upload_1749_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1749_1637126775643.sql',1,1,0),(1759,'0','找到遗失的ID','表: Customers\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| customer_id   | int     |\n| customer_name | varchar |\n+---------------+---------+\n```\n\ncustomer_id 是该表主键.\n\n该表第一行包含了顾客的名字和id.\n\n写一个 SQL 语句,找到所有遗失的顾客id.遗失的顾客id是指那些不在Customers表中,值却处于1和表中最大customer_id之间的id.\n\n注意:最大的customer_id值不会超过100.\n\n返回结果按ids 升序排列\n\n查询结果格式如下例所示.\n\nCustomers 表:\n\n```\n+-------------+---------------+\n| customer_id | customer_name |\n+-------------+---------------+\n| 1           | Alice         |\n| 4           | Bob           |\n| 5           | Charlie       |\n+-------------+---------------+\n```\n\nResult 表:\n\n```\n+-----+\n| ids |\n+-----+\n| 2   |\n| 3   |\n+-----+\n```\n\n表中最大的customer_id是5, 所以在范围[1,5]内, ID2和3从表中遗失.\n\n','examDataFiles/auto_upload_1759_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1759_1637126775643.sql',2,1,0),(1763,'0','三人国家代表队','表: SchoolA\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| student_id    | int     |\n| student_name  | varchar |\n+---------------+---------+\n```\n\nstudent_id 是表的主键\n\n表中的每一行包含了学校A中每一个学生的名字和ID\n\n所有student_name在表中都是独一无二的\n\n表: SchoolB\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| student_id    | int     |\n| student_name  | varchar |\n+---------------+---------+\n```\n\nstudent_id 是表的主键\n\n表中的每一行包含了学校B中每一个学生的名字和ID\n\n所有student_name在表中都是独一无二的\n\n表: SchoolC\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| student_id    | int     |\n| student_name  | varchar |\n+---------------+---------+\n```\n\nstudent_id 是表的主键\n\n表中的每一行包含了学校C中每一个学生的名字和ID\n\n所有student_name在表中都是独一无二的\n\n有一个国家只有三所学校，这个国家的每一个学生只会注册一所学校。\n\n这个国家正在参加一个竞赛，他们希望从这三所学校中各选出一个学生来组建一支三人的代表队。\n\n例如：\n\nmember_A是从 SchoolA中选出的\n\nmember_B是从 SchoolB中选出的\n\nmember_C是从 SchoolC中选出的\n\n被选中的学生具有不同的名字和ID（没有任何两个学生拥有相同的名字、没有任何两个学生拥有相同的ID）\n\n使用上述条件，编写SQL查询语句来找到所有可能的三人国家代表队组合。\n\n查询结果接受任何顺序。\n\n查询结果格式样例：\n\nSchoolA table:\n\n```\n+------------+--------------+\n| student_id | student_name |\n+------------+--------------+\n| 1          | Alice        |\n| 2          | Bob          |\n+------------+--------------+\n```\n\nSchoolB table:\n\n```\n+------------+--------------+\n| student_id | student_name |\n+------------+--------------+\n| 3          | Tom          |\n+------------+--------------+\n```\n\nSchoolC table:\n\n```\n+------------+--------------+\n| student_id | student_name |\n+------------+--------------+\n| 3          | Tom          |\n| 2          | Jerry        |\n| 10         | Alice        |\n+------------+--------------+\n```\n\n预期结果:\n\n```\n+----------+----------+----------+\n| member_A | member_B | member_C |\n+----------+----------+----------+\n| Alice    | Tom      | Jerry    |\n| Bob      | Tom      | Alice    |\n+----------+----------+----------+\n```\n\n让我们看看有哪些可能的组合：\n\n- (Alice, Tom, Tom) --> 不适用，因为member_B（Tom）和member_C（Tom）有相同的名字和ID\n\n- (Alice, Tom, Jerry) --> 可能的组合\n\n- (Alice, Tom, Alice) --> 不适用，因为member_A和member_C有相同的名字\n\n- (Bob, Tom, Tom) --> 不适用，因为member_B和member_C有相同的名字和ID\n\n- (Bob, Tom, Jerry) --> 不适用，因为member_A和member_C有相同的ID\n\n- (Bob, Tom, Alice) --> 可能的组合.\n\n','examDataFiles/auto_upload_1763_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1763_1637126775643.sql',1,1,0),(1773,'0','各赛事的用户注册率','用户表：Users\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| user_id     | int     |\n| user_name   | varchar |\n+-------------+---------+\n```\n\nuser_id 是该表的主键。\n\n该表中的每行包括用户 ID 和用户名。\n\n注册表：Register\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| contest_id  | int     |\n| user_id     | int     |\n+-------------+---------+\n```\n\n(contest_id, user_id) 是该表的主键。\n\n该表中的每行包含用户的 ID 和他们注册的赛事。\n\n写一条 SQL 语句，查询各赛事的用户注册百分率，保留两位小数。\n\n返回的结果表按percentage的降序排序，若相同则按contest_id的升序排序。\n\n查询结果如下示例所示：\n\nUsers 表：\n\n```\n+---------+-----------+\n| user_id | user_name |\n+---------+-----------+\n| 6       | Alice     |\n| 2       | Bob       |\n| 7       | Alex      |\n+---------+-----------+\n```\n\nRegister 表：\n\n```\n+------------+---------+\n| contest_id | user_id |\n+------------+---------+\n| 215        | 6       |\n| 209        | 2       |\n| 208        | 2       |\n| 210        | 6       |\n| 208        | 6       |\n| 209        | 7       |\n| 209        | 6       |\n| 215        | 7       |\n| 208        | 7       |\n| 210        | 2       |\n| 207        | 2       |\n| 210        | 7       |\n+------------+---------+\n```\n\n结果表：\n\n```\n+------------+------------+\n| contest_id | percentage |\n+------------+------------+\n| 208        | 100.0      |\n| 209        | 100.0      |\n| 210        | 100.0      |\n| 215        | 66.67      |\n| 207        | 33.33      |\n+------------+------------+\n```\n\n所有用户都注册了 208、209 和 210 赛事，因此这些赛事的注册率为 100% ，我们按 contest_id 的降序排序加入结果表中。\n\nAlice 和 Alex 注册了 215 赛事，注册率为 ((2/3) * 100) = 66.67%\n\nBob 注册了 207 赛事，注册率为 ((1/3) * 100) = 33.33%\n\n','examDataFiles/auto_upload_1773_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1773_1637126775643.sql',1,1,0),(1801,'0','每台机器的进程平均运行时间','表: Activity\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| machine_id     | int     |\n| process_id     | int     |\n| activity_type  | enum    |\n| timestamp      | float   |\n+----------------+---------+\n```\n\n该表展示了一家工厂网站的用户活动.\n\n(machine_id, process_id, activity_type) 是当前表的主键.\n\nmachine_id 是一台机器的ID号.\n\nprocess_id 是运行在各机器上的进程ID号.\n\nactivity_type 是枚举类型 (\'start\', \'end\').\n\ntimestamp 是浮点类型,代表当前时间(以秒为单位).\n\n\'start\' 代表该进程在这台机器上的开始运行时间戳 , \'end\' 代表该进程在这台机器上的终止运行时间戳.\n\n同一台机器，同一个进程都有一对开始时间戳和结束时间戳，而且开始时间戳永远在结束时间戳前面.\n\n现在有一个工厂网站由几台机器运行，每台机器上运行着相同数量的进程. 请写出一条SQL计算每台机器各自完成一个进程任务的平均耗时.\n\n完成一个进程任务的时间指进程的\'end\' 时间戳 减去\'start\' 时间戳. 平均耗时通过计算每台机器上所有进程任务的总耗费时间除以机器上的总进程数量获得.\n\n结果表必须包含machine_id（机器ID） 和对应的average time（平均耗时）别名processing_time, 且四舍五入保留3位小数.\n\n具体参考例子如下:\n\nActivity table:\n\n```\n+------------+------------+---------------+-----------+\n| machine_id | process_id | activity_type | timestamp |\n+------------+------------+---------------+-----------+\n| 0          | 0          | start         | 0.712     |\n| 0          | 0          | end           | 1.520     |\n| 0          | 1          | start         | 3.140     |\n| 0          | 1          | end           | 4.120     |\n| 1          | 0          | start         | 0.550     |\n| 1          | 0          | end           | 1.550     |\n| 1          | 1          | start         | 0.430     |\n| 1          | 1          | end           | 1.420     |\n| 2          | 0          | start         | 4.100     |\n| 2          | 0          | end           | 4.512     |\n| 2          | 1          | start         | 2.500     |\n| 2          | 1          | end           | 5.000     |\n+------------+------------+---------------+-----------+\n```\n\nResult table:\n\n```\n+------------+-----------------+\n| machine_id | processing_time |\n+------------+-----------------+\n| 0          | 0.894           |\n| 1          | 0.995           |\n| 2          | 1.456           |\n+------------+-----------------+\n```\n\n一共有3台机器,每台机器运行着两个进程.\n\n机器 0 的平均耗时: ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n\n机器 1 的平均耗时: ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n\n机器 2 的平均耗时: ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456\n\n','examDataFiles/auto_upload_1801_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1801_1637126775643.sql',1,1,0),(1811,'0','修复表中的名字','表： Users\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| user_id        | int     |\n| name           | varchar |\n+----------------+---------+\n```\n\nuser_id 是该表的主键。\n\n该表包含用户的 ID 和名字。名字仅由小写和大写字符组成。\n\n编写一个 SQL 查询来修复名字，使得只有第一个字符是大写的，其余都是小写的。\n\n返回按 user_id 排序的结果表。\n\n查询结果格式示例如下：\n\nUsers table:\n\n```\n+---------+-------+\n| user_id | name  |\n+---------+-------+\n| 1       | aLice |\n| 2       | bOB   |\n+---------+-------+\n```\n\nResult table:\n\n```\n+---------+-------+\n| user_id | name  |\n+---------+-------+\n| 1       | Alice |\n| 2       | Bob   |\n+---------+-------+\n```\n\n','examDataFiles/auto_upload_1811_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1811_1637126775643.sql',1,1,0),(1821,'0','发票中的产品金额','Product 表：\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| product_id  | int     |\n| name        | varchar |\n+-------------+---------+\n```\n\nproduct_id 是这张表的主键\n\n表中含有产品 id 、产品名称。产品名称都是小写的英文字母，产品名称都是唯一的\n\nInvoice 表：\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| invoice_id  | int  |\n| product_id  | int  |\n| rest        | int  |\n| paid        | int  |\n| canceled    | int  |\n| refunded    | int  |\n+-------------+------+\n```\n\ninvoice_id 发票 id ，是这张表的主键\n\nproduct_id 产品 id\n\nrest 应缴款项\n\npaid 已支付金额\n\ncanceled 已取消金额\n\nrefunded 已退款金额\n\n要求写一个SQL查询，对于所有产品，返回每个产品的产品名称，以及全部发票累计的总应缴款项、总已支付金额、总已取消金额、总已退款金额。\n\n查询结果按 product_name 排序\n\n示例：\n\nProduct 表：\n\n```\n+------------+-------+\n| product_id | name  |\n+------------+-------+\n| 0          | ham   |\n| 1          | bacon |\n+------------+-------+\n```\n\nInvoice table:\n\n```\n+------------+------------+------+------+----------+----------+\n| invoice_id | product_id | rest | paid | canceled | refunded |\n+------------+------------+------+------+----------+----------+\n| 23         | 0          | 2    | 0    | 5        | 0        |\n| 12         | 0          | 0    | 4    | 0        | 3        |\n| 1          | 1          | 1    | 1    | 0        | 1        |\n| 2          | 1          | 1    | 0    | 1        | 1        |\n| 3          | 1          | 0    | 1    | 1        | 1        |\n| 4          | 1          | 1    | 1    | 1        | 0        |\n+------------+------------+------+------+----------+----------+\n```\n\nResult 表：\n\n```\n+-------+------+------+----------+----------+\n| name  | rest | paid | canceled | refunded |\n+-------+------+------+----------+----------+\n| bacon | 3    | 3    | 3        | 3        |\n| ham   | 2    | 4    | 5        | 3        |\n+-------+------+------+----------+----------+\n```\n\n- bacon 的总应缴款项为 1 + 1 + 0 + 1 = 3\n\n- bacon 的总已支付金额为 1 + 0 + 1 + 1 = 3\n\n- bacon 的总已取消金额为 0 + 1 + 1 + 1 = 3\n\n- bacon 的总已退款金额为 1 + 1 + 1 + 0 = 3\n\n- ham 的总应缴款项为 2 + 0 = 2\n\n- ham 的总已支付金额为 0 + 4 = 4\n\n- ham 的总已取消金额为 5 + 0 = 5\n\n- ham 的总已退款金额为 0 + 3 = 3\n\n','examDataFiles/auto_upload_1821_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1821_1637126775643.sql',1,1,0),(1827,'0','无效的推文','表：Tweets\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| tweet_id       | int     |\n| content        | varchar |\n+----------------+---------+\n```\n\ntweet_id 是这个表的主键。\n\n这个表包含某社交媒体 App 中所有的推文。\n\n写一条SQL 语句，查询所有无效推文的编号（ID）。当推文内容中的字符数严格大于 15 时，该推文是无效的。\n\n以任意顺序返回结果表。\n\n查询结果格式如下示例所示：\n\nTweets 表：\n\n```\n+----------+----------------------------------+\n| tweet_id | content                          |\n+----------+----------------------------------+\n| 1        | Vote for Biden                   |\n| 2        | Let us make America great again! |\n+----------+----------------------------------+\n```\n\n结果表：\n\n```\n+----------+\n| tweet_id |\n+----------+\n| 2        |\n+----------+\n```\n\n推文 1 的长度 length = 14。该推文是有效的。\n\n推文 2 的长度 length = 32。该推文是无效的。\n\n','examDataFiles/auto_upload_1827_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1827_1637126775643.sql',1,1,0),(1837,'0','每天的领导和合伙人','表：DailySales\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| date_id     | date    |\n| make_name   | varchar |\n| lead_id     | int     |\n| partner_id  | int     |\n+-------------+---------+\n```\n\n该表没有主键。\n\n该表包含日期、产品的名称，以及售给的领导和合伙人的编号。\n\n名称只包含小写英文字母。\n\n写一条 SQL 语句，使得对于每一个date_id和make_name，返回不同的lead_id以及不同的partner_id的数量。\n\n按任意顺序返回结果表。\n\n查询结果格式如下示例所示：\n\nDailySales 表：\n\n```\n+-----------+-----------+---------+------------+\n| date_id   | make_name | lead_id | partner_id |\n+-----------+-----------+---------+------------+\n| 2020-12-8 | toyota    | 0       | 1          |\n| 2020-12-8 | toyota    | 1       | 0          |\n| 2020-12-8 | toyota    | 1       | 2          |\n| 2020-12-7 | toyota    | 0       | 2          |\n| 2020-12-7 | toyota    | 0       | 1          |\n| 2020-12-8 | honda     | 1       | 2          |\n| 2020-12-8 | honda     | 2       | 1          |\n| 2020-12-7 | honda     | 0       | 1          |\n| 2020-12-7 | honda     | 1       | 2          |\n| 2020-12-7 | honda     | 2       | 1          |\n+-----------+-----------+---------+------------+\n```\n\n结果表：\n\n```\n+-----------+-----------+--------------+-----------------+\n| date_id   | make_name | unique_leads | unique_partners |\n+-----------+-----------+--------------+-----------------+\n| 2020-12-8 | toyota    | 2            | 3               |\n| 2020-12-7 | toyota    | 1            | 2               |\n| 2020-12-8 | honda     | 2            | 2               |\n| 2020-12-7 | honda     | 3            | 2               |\n+-----------+-----------+--------------+-----------------+\n```\n\n在 2020-12-8，丰田（toyota）有领导者 = [0, 1] 和合伙人 = [0, 1, 2] ，同时本田（honda）有领导者 = [1, 2] 和合伙人 = [1, 2]。\n\n在 2020-12-7，丰田（toyota）有领导者 = [0] 和合伙人 = [1, 2] ，同时本田（honda）有领导者 = [0, 1, 2] 和合伙人 = [1, 2]。\n\n','examDataFiles/auto_upload_1837_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1837_1637126775643.sql',1,1,0),(1842,'0','两人之间的通话次数','表：Calls\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| from_id     | int     |\n| to_id       | int     |\n| duration    | int     |\n+-------------+---------+\n```\n\n该表没有主键，可能存在重复项。\n\n该表包含 from_id 与 to_id 间的一次电话的时长。\n\nfrom_id != to_id\n\n编写 SQL 语句，查询每一对用户(person1, person2)之间的通话次数和通话总时长，其中person1 < person2。\n\n以任意顺序返回结果表。\n\n查询结果格式如下示例所示：\n\nCalls 表：\n\n```\n+---------+-------+----------+\n| from_id | to_id | duration |\n+---------+-------+----------+\n| 1       | 2     | 59       |\n| 2       | 1     | 11       |\n| 1       | 3     | 20       |\n| 3       | 4     | 100      |\n| 3       | 4     | 200      |\n| 3       | 4     | 200      |\n| 4       | 3     | 499      |\n+---------+-------+----------+\n```\n\n结果表：\n\n```\n+---------+---------+------------+----------------+\n| person1 | person2 | call_count | total_duration |\n+---------+---------+------------+----------------+\n| 1       | 2       | 2          | 70             |\n| 1       | 3       | 1          | 20             |\n| 3       | 4       | 4          | 999            |\n+---------+---------+------------+----------------+\n```\n\n用户 1 和 2 打过 2 次电话，总时长为 70 (59 + 11)。\n\n用户 1 和 3 打过 1 次电话，总时长为 20。\n\n用户 3 和 4 打过 4 次电话，总时长为 999 (100 + 200 + 200 + 499)。\n\n','examDataFiles/auto_upload_1842_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1842_1637126775643.sql',2,1,0),(1852,'0','访问日期之间最大的空档期','表：UserVisits\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| user_id     | int  |\n| visit_date  | date |\n+-------------+------+\n```\n\n该表没有主键。\n\n该表包含用户访问某特定零售商的日期日志。\n\n假设今天的日期是\'2021-1-1\'。\n\n编写 SQL 语句，对于每个user_id，求出每次访问及其下一个访问（若该次访问是最后一次，则为今天）之间最大的空档期天数window。\n\n返回结果表，按用户编号user_id排序。\n\n查询格式如下示例所示：\n\nUserVisits 表：\n\n```\n+---------+------------+\n| user_id | visit_date |\n+---------+------------+\n| 1       | 2020-11-28 |\n| 1       | 2020-10-20 |\n| 1       | 2020-12-3  |\n| 2       | 2020-10-5  |\n| 2       | 2020-12-9  |\n| 3       | 2020-11-11 |\n+---------+------------+\n```\n\n结果表：\n\n```\n+---------+---------------+\n| user_id | biggest_window|\n+---------+---------------+\n| 1       | 39            |\n| 2       | 65            |\n| 3       | 51            |\n+---------+---------------+\n```\n\n对于第一个用户，问题中的空档期在以下日期之间：\n\n    - 2020-10-20 至 2020-11-28 ，共计 39 天。\n\n    - 2020-11-28 至 2020-12-3 ，共计 5 天。\n\n    - 2020-12-3 至 2021-1-1 ，共计 29 天。\n\n由此得出，最大的空档期为 39 天。\n\n对于第二个用户，问题中的空档期在以下日期之间：\n\n    - 2020-10-5 至 2020-12-9 ，共计 65 天。\n\n    - 2020-12-9 至 2021-1-1 ，共计 23 天。\n\n由此得出，最大的空档期为 65 天。\n\n对于第三个用户，问题中的唯一空档期在 2020-11-11 至 2021-1-1 之间，共计 51 天。\n\n','examDataFiles/auto_upload_1852_1637126775643.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1852_1637126775643.sql',2,1,0),(1862,'0','苹果和橘子的个数','表：Boxes\n\n```\n+--------------+------+\n| Column Name  | Type |\n+--------------+------+\n| box_id       | int  |\n| chest_id     | int  |\n| apple_count  | int  |\n| orange_count | int  |\n+--------------+------+\n```\n\nbox_id 是该表的主键。\n\nchest_id 是 chests 表的外键。\n\n该表包含大箱子 (box) 中包含的苹果和橘子的个数。每个大箱子中可能包含一个小盒子 (chest) ，小盒子中也包含若干苹果和橘子。\n\n表：Chests\n\n```\n+--------------+------+\n| Column Name  | Type |\n+--------------+------+\n| chest_id     | int  |\n| apple_count  | int  |\n| orange_count | int  |\n+--------------+------+\n```\n\nchest_id 是该表的主键。\n\n该表包含小盒子的信息，以及小盒子中包含的苹果和橘子的个数。\n\n编写 SQL 语句，查询每个大箱子中苹果和橘子的个数。如果大箱子中包含小盒子，还应当包含小盒子中苹果和橘子的个数。\n\n以任意顺序返回结果表。\n\n查询结果的格式如下示例所示：\n\nBoxes 表：\n\n```\n+--------+----------+-------------+--------------+\n| box_id | chest_id | apple_count | orange_count |\n+--------+----------+-------------+--------------+\n| 2      | null     | 6           | 15           |\n| 18     | 14       | 4           | 15           |\n| 19     | 3        | 8           | 4            |\n| 12     | 2        | 19          | 20           |\n| 20     | 6        | 12          | 9            |\n| 8      | 6        | 9           | 9            |\n| 3      | 14       | 16          | 7            |\n+--------+----------+-------------+--------------+\n```\n\nChests 表：\n\n```\n+----------+-------------+--------------+\n| chest_id | apple_count | orange_count |\n+----------+-------------+--------------+\n| 6        | 5           | 6            |\n| 14       | 20          | 10           |\n| 2        | 8           | 8            |\n| 3        | 19          | 4            |\n| 16       | 19          | 19           |\n+----------+-------------+--------------+\n```\n\n结果表：\n\n```\n+-------------+--------------+\n| apple_count | orange_count |\n+-------------+--------------+\n| 151         | 123          |\n+-------------+--------------+\n```\n\n大箱子 2 中有 6 个苹果和 15 个橘子。\n\n大箱子 18 中有 4 + 20 (在小盒子中) = 24 个苹果和 15 + 10 (在小盒子中) = 25 个橘子。\n\n大箱子 19 中有 8 + 19 (在小盒子中) = 27 个苹果和 4 + 4 (在小盒子中) = 8 个橘子。\n\n大箱子 12 中有 19 + 8 (在小盒子中) = 27 个苹果和 20 + 8 (在小盒子中) = 28 个橘子。\n\n大箱子 20 中有 12 + 5 (在小盒子中) = 17 个苹果和 9 + 6 (在小盒子中) = 15 个橘子。\n\n大箱子 8 中有 9 + 5 (在小盒子中) = 14 个苹果和 9 + 6 (在小盒子中) = 15 个橘子。\n\n大箱子 3 中有 16 + 20 (在小盒子中) = 36 个苹果和 7 + 10 (在小盒子中) = 17 个橘子。\n\n苹果的总个数 = 6 + 24 + 27 + 27 + 17 + 14 + 36 = 151\n\n橘子的总个数 = 15 + 25 + 8 + 28 + 15 + 15 + 17 = 123\n\n','examDataFiles/auto_upload_1862_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1862_1637126775646.sql',2,1,0),(1877,'0','求关注者的数量','表：Followers\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| user_id     | int  |\n| follower_id | int  |\n+-------------+------+\n```\n\n(user_id, follower_id) 是这个表的主键。\n\n该表包含一个关注关系中关注者和用户的编号，其中关注者关注用户。\n\n写出 SQL 语句，对于每一个用户，返回该用户的关注者数量。\n\n按user_id的顺序返回结果表。\n\n查询结果的格式如下示例所示：\n\nFollowers 表：\n\n```\n+---------+-------------+\n| user_id | follower_id |\n+---------+-------------+\n| 0       | 1           |\n| 1       | 0           |\n| 2       | 0           |\n| 2       | 1           |\n+---------+-------------+\n```\n\n结果表：\n\n```\n+---------+----------------+\n| user_id | followers_count|\n+---------+----------------+\n| 0       | 1              |\n| 1       | 1              |\n| 2       | 2              |\n+---------+----------------+\n```\n\n0 的关注者有 {1}\n\n1 的关注者有 {0}\n\n2 的关注者有 {0,1}\n\n','examDataFiles/auto_upload_1877_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1877_1637126775646.sql',1,1,0),(1882,'0','每位经理的下属员工数量','Table: Employees\n\n```\n+-------------+----------+\n| Column Name | Type     |\n+-------------+----------+\n| employee_id | int      |\n| name        | varchar  |\n| reports_to  | int      |\n| age         | int      |\n+-------------+----------+\n```\n\nemployee_id 是这个表的主键.\n\n该表包含员工以及需要听取他们汇报的上级经理的ID的信息。 有些员工不需要向任何人汇报（reports_to 为空）。\n\n对于此问题，我们将至少有一个其他员工需要向他汇报的员工，视为一个经理。\n\n编写SQL查询需要听取汇报的所有经理的ID、名称、直接向该经理汇报的员工人数，以及这些员工的平均年龄，其中该平均年龄需要四舍五入到最接近的整数。\n\n返回的结果集需要按照employee_id 进行排序。\n\n查询结果的格式如下：\n\nEmployees table:\n\n```\n+-------------+---------+------------+-----+\n| employee_id | name    | reports_to | age |\n+-------------+---------+------------+-----+\n| 9           | Hercy   | null       | 43  |\n| 6           | Alice   | 9          | 41  |\n| 4           | Bob     | 9          | 36  |\n| 2           | Winston | null       | 37  |\n+-------------+---------+------------+-----+\n```\n\nResult table:\n\n```\n+-------------+-------+---------------+-------------+\n| employee_id | name  | reports_count | average_age |\n+-------------+-------+---------------+-------------+\n| 9           | Hercy | 2             | 39          |\n+-------------+-------+---------------+-------------+\n```\n\nHercy 有两个需要向他汇报的员工, 他们是 Alice and Bob. 他们的平均年龄是 (41+36)/2 = 38.5, 四舍五入的结果是 39.\n\n','examDataFiles/auto_upload_1882_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1882_1637126775646.sql',1,1,0),(1892,'0','查找每个员工花费的总时间','表: Employees\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| emp_id      | int  |\n| event_day   | date |\n| in_time     | int  |\n| out_time    | int  |\n+-------------+------+\n```\n\n(emp_id, event_day, in_time) 是这个表的主键。\n\n该表显示了员工在办公室的出入情况。\n\nevent_day 是此事件发生的日期，in_time 是员工进入办公室的时间，而 out_time 是他们离开办公室的时间。\n\nin_time 和 out_time 的取值在1到1440之间。\n\n题目保证同一天没有两个事件在时间上是相交的，并且保证 in_time 小于 out_time。\n\n编写一个SQL查询以计算每位员工每天在办公室花费的总时间（以分钟为单位）。 请注意，在一天之内，同一员工是可以多次进入和离开办公室的。 在办公室里一次进出所花费的时间为out_time 减去 in_time。\n\n返回结果表单的顺序无要求。\n\n查询结果的格式如下：\n\nEmployees table:\n\n```\n+--------+------------+---------+----------+\n| emp_id | event_day  | in_time | out_time |\n+--------+------------+---------+----------+\n| 1      | 2020-11-28 | 4       | 32       |\n| 1      | 2020-11-28 | 55      | 200      |\n| 1      | 2020-12-03 | 1       | 42       |\n| 2      | 2020-11-28 | 3       | 33       |\n| 2      | 2020-12-09 | 47      | 74       |\n+--------+------------+---------+----------+\n```\n\nResult table:\n\n```\n+------------+--------+------------+\n| day        | emp_id | total_time |\n+------------+--------+------------+\n| 2020-11-28 | 1      | 173        |\n| 2020-11-28 | 2      | 30         |\n| 2020-12-03 | 1      | 41         |\n| 2020-12-09 | 2      | 27         |\n+------------+--------+------------+\n```\n\n雇员 1 有三次进出: 有两次发生在 2020-11-28 花费的时间为 (32 - 4) + (200 - 55) = 173, 有一次发生在 2020-12-03 花费的时间为 (42 - 1) = 41。\n\n雇员 2 有两次进出: 有一次发生在 2020-11-28 花费的时间为 (33 - 3) = 30,  有一次发生在 2020-12-09 花费的时间为 (74 - 47) = 27。\n\n','examDataFiles/auto_upload_1892_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1892_1637126775646.sql',1,1,0),(1898,'0','应该被禁止的Leetflex账户','表: LogInfo\n\n```\n+-------------+----------+\n| Column Name | Type     |\n+-------------+----------+\n| account_id  | int      |\n| ip_address  | int      |\n| login       | datetime |\n| logout      | datetime |\n+-------------+----------+\n```\n\n该表是没有主键的，它可能包含重复项。\n\n该表包含有关Leetflex帐户的登录和注销日期的信息。 它还包含了该账户用于登录和注销的网络地址的信息。\n\n题目确保每一个注销时间都在登录时间之后。\n\n编写一个SQL查询语句，查找那些应该被禁止的Leetflex帐户编号account_id。 如果某个帐户在某一时刻从两个不同的网络地址登录了，则这个帐户应该被禁止。\n\n可以以任何顺序返回结果。\n\n查询结果格式如下例所示:\n\nLogInfo table:\n\n```\n+------------+------------+---------------------+---------------------+\n| account_id | ip_address | login               | logout              |\n+------------+------------+---------------------+---------------------+\n| 1          | 1          | 2021-02-01 09:00:00 | 2021-02-01 09:30:00 |\n| 1          | 2          | 2021-02-01 08:00:00 | 2021-02-01 11:30:00 |\n| 2          | 6          | 2021-02-01 20:30:00 | 2021-02-01 22:00:00 |\n| 2          | 7          | 2021-02-02 20:30:00 | 2021-02-02 22:00:00 |\n| 3          | 9          | 2021-02-01 16:00:00 | 2021-02-01 16:59:59 |\n| 3          | 13         | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 |\n| 4          | 10         | 2021-02-01 16:00:00 | 2021-02-01 17:00:00 |\n| 4          | 11         | 2021-02-01 17:00:00 | 2021-02-01 17:59:59 |\n+------------+------------+---------------------+---------------------+\n```\n\nResult table:\n\n```\n+------------+\n| account_id |\n+------------+\n| 1          |\n| 4          |\n+------------+\n```\n\nAccount ID 1 --> 该账户从 \"2021-02-01 09:00:00\" 到 \"2021-02-01 09:30:00\" 在两个不同的网络地址(1 and 2)上激活了。它应该被禁止.\n\nAccount ID 2 --> 该账户在两个不同的网络地址 (6, 7) 激活了，但在不同的时间上.\n\nAccount ID 3 --> 该账户在两个不同的网络地址 (9, 13) 激活了，虽然是同一天，但时间上没有交集.\n\nAccount ID 4 --> 该账户从 \"2021-02-01 17:00:00\" 到 \"2021-02-01 17:00:00\" 在两个不同的网络地址 (10 and 11)上激活了。它应该被禁止.\n\n','examDataFiles/auto_upload_1898_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1898_1637126775646.sql',2,1,0),(1908,'0','可回收且低脂的产品','表：Products\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| product_id  | int     |\n| low_fats    | enum    |\n| recyclable  | enum    |\n+-------------+---------+\n```\n\nproduct_id 是这个表的主键。\n\nlow_fats 是枚举类型，取值为以下两种 (\'Y\', \'N\')，其中 \'Y\' 表示该产品是低脂产品，\'N\' 表示不是低脂产品。\n\nrecyclable 是枚举类型，取值为以下两种 (\'Y\', \'N\')，其中 \'Y\' 表示该产品可回收，而 \'N\' 表示不可回收。\n\n写出 SQL 语句，查找既是低脂又是可回收的产品编号。\n\n返回结果 无顺序要求 。\n\n查询结果格式如下例所示：\n\nProducts 表：\n\n```\n+-------------+----------+------------+\n| product_id  | low_fats | recyclable |\n+-------------+----------+------------+\n| 0           | Y        | N          |\n| 1           | Y        | Y          |\n| 2           | N        | Y          |\n| 3           | Y        | Y          |\n| 4           | N        | N          |\n+-------------+----------+------------+\n```\n\nResult 表：\n\n```\n+-------------+\n| product_id  |\n+-------------+\n| 1           |\n| 3           |\n+-------------+\n```\n\n只有产品 id 为 1 和 3 的产品，既是低脂又是可回收的产品。\n\n','examDataFiles/auto_upload_1908_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1908_1637126775646.sql',1,1,0),(1914,'0','寻找没有被执行的任务对','表：Tasks\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| task_id        | int     |\n| subtasks_count | int     |\n+----------------+---------+\n```\n\ntask_id 是这个表的主键。\n\ntask_id 表示的为主任务的id,每一个task_id被分为了多个子任务(subtasks)，subtasks_count表示为子任务的个数（n），它的值表示了子任务的索引从1到n。\n\n本表保证2 <=subtasks_count<= 20。\n\n表： Executed\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| task_id       | int     |\n| subtask_id    | int     |\n+---------------+---------+\n```\n\n(task_id, subtask_id) 是这个表的主键。\n\n每一行表示标记为task_id的主任务与标记为subtask_id的子任务被成功执行。\n\n本表保证，对于每一个task_id，subtask_id <= subtasks_count。\n\n请试写一个SQL查询语句报告没有被执行的（主任务，子任务）对，即没有被执行的（task_id, subtask_id）。\n\n以 任何顺序 返回即可。\n\n查询结果格式如下：\n\nTasks table:\n\n```\n+---------+----------------+\n| task_id | subtasks_count |\n+---------+----------------+\n| 1       | 3              |\n| 2       | 2              |\n| 3       | 4              |\n+---------+----------------+\n```\n\nExecuted table:\n\n```\n+---------+------------+\n| task_id | subtask_id |\n+---------+------------+\n| 1       | 2          |\n| 3       | 1          |\n| 3       | 2          |\n| 3       | 3          |\n| 3       | 4          |\n+---------+------------+\n```\n\nResult table:\n\n```\n+---------+------------+\n| task_id | subtask_id |\n+---------+------------+\n| 1       | 1          |\n| 1       | 3          |\n| 2       | 1          |\n| 2       | 2          |\n+---------+------------+\n```\n\nTask 1 被分成了 3 subtasks (1, 2, 3)。只有 subtask 2 被成功执行, 所以我们返回 (1, 1) 和 (1, 3) 这两个主任务子任务对。\n\nTask 2 被分成了 2 subtasks (1, 2)。没有一个subtask被成功执行, 因此我们返回(2, 1)和(2, 2)。\n\nTask 3 被分成了 4 subtasks (1, 2, 3, 4)。所有的subtask都被成功执行，因此对于Task 3,我们不返回任何值。\n\n','examDataFiles/auto_upload_1914_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1914_1637126775646.sql',3,1,0),(1932,'0','大满贯数量','表：Players\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| player_id      | int     |\n| player_name    | varchar |\n+----------------+---------+\n```\n\nplayer_id 是这个表的主键\n\n这个表的每一行给出一个网球运动员的 ID 和 姓名\n\n表：Championships\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| year          | int     |\n| Wimbledon     | int     |\n| Fr_open       | int     |\n| US_open       | int     |\n| Au_open       | int     |\n+---------------+---------+\n```\n\nyear 是这个表的主键\n\n该表的每一行都包含在每场大满贯网球比赛中赢得比赛的球员的 ID\n\n请写出查询语句，查询出每一个球员赢得大满贯比赛的次数。结果不包含没有赢得比赛的球员的ID 。\n\n结果集无顺序要求。\n\n查询结果的格式，如下所示：\n\nPlayers 表：\n\n```\n+-----------+-------------+\n| player_id | player_name |\n+-----------+-------------+\n| 1         | Nadal       |\n| 2         | Federer     |\n| 3         | Novak       |\n+-----------+-------------+\n```\n\nChampionships 表：\n\n```\n+------+-----------+---------+---------+---------+\n| year | Wimbledon | Fr_open | US_open | Au_open |\n+------+-----------+---------+---------+---------+\n| 2018 | 1         | 1       | 1       | 1       |\n| 2019 | 1         | 1       | 2       | 2       |\n| 2020 | 2         | 1       | 2       | 2       |\n+------+-----------+---------+---------+---------+\n```\n\nResult 表：\n\n```\n+-----------+-------------+-------------------+\n| player_id | player_name | grand_slams_count |\n+-----------+-------------+-------------------+\n| 2         | Federer     | 5                 |\n| 1         | Nadal       | 7                 |\n+-----------+-------------+-------------------+\n```\n\nPlayer 1 (Nadal) 获得了 7 次大满贯：其中温网 2 次(2018, 2019), 法国公开赛 3 次 (2018, 2019, 2020), 美国公开赛 1 次 (2018)以及澳网公开赛 1 次 (2018) 。\n\nPlayer 2 (Federer) 获得了 5 次大满贯：其中温网 1 次 (2020), 美国公开赛 2 次 (2019, 2020) 以及澳网公开赛 2 次 (2019, 2020) 。\n\nPlayer 3 (Novak)  没有赢得，因此不包含在结果集中。\n\n','examDataFiles/auto_upload_1932_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1932_1637126775646.sql',2,1,0),(1942,'0','员工的直属部门','Table: Employee\n\n```\n+---------------+---------+\n| Column Name   |  Type   |\n+---------------+---------+\n| employee_id   | int     |\n| department_id | int     |\n| primary_flag  | varchar |\n+---------------+---------+\n```\n\n这张表的主键为 employee_id, department_id\n\nemployee_id 是员工的ID\n\ndepartment_id 是部门的ID，表示员工与该部门有关系\n\nprimary_flag 是一个枚举类型，值分别为(\'Y\', \'N\'). 如果值为\'Y\',表示该部门是员工的直属部门。 如果值是\'N\',则否\n\n一个员工可以属于多个部门。\n\n当一个员工加入超过一个部门的时候，他需要决定哪个部门是他的直属部门。\n\n请注意，当员工只加入一个部门的时候，那这个部门将默认为他的直属部门，虽然表记录的值为\'N\'.\n\n请编写一段SQL，查出员工所属的直属部门。\n\n返回结果没有顺序要求。\n\n示例：\n\nEmployee table:\n\n```\n+-------------+---------------+--------------+\n| employee_id | department_id | primary_flag |\n+-------------+---------------+--------------+\n| 1           | 1             | N            |\n| 2           | 1             | Y            |\n| 2           | 2             | N            |\n| 3           | 3             | N            |\n| 4           | 2             | N            |\n| 4           | 3             | Y            |\n| 4           | 4             | N            |\n+-------------+---------------+--------------+\n```\n\nResult table:\n\n```\n+-------------+---------------+\n| employee_id | department_id |\n+-------------+---------------+\n| 1           | 1             |\n| 2           | 1             |\n| 3           | 3             |\n| 4           | 3             |\n+-------------+---------------+\n```\n\n- 员工1的直属部门是1\n\n- 员工2的直属部门是1\n\n- 员工3的直属部门是3\n\n- 员工4的直属部门是3\n\n','examDataFiles/auto_upload_1942_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1942_1637126775646.sql',1,1,0),(1948,'0','每个产品在不同商店的价格','表：Products\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| product_id  | int     |\n| store1      | int     |\n| store2      | int     |\n| store3      | int     |\n+-------------+---------+\n```\n\n这张表的主键是product_id（产品Id）。\n\n每行存储了这一产品在不同商店store1, store2, store3的价格。\n\n如果这一产品在商店里没有出售，则值将为null。\n\n请你重构 Products 表，查询每个产品在不同商店的价格，使得输出的格式变为(product_id, store, price) 。如果这一产品在商店里没有出售，则不输出这一行。\n\n输出结果表中的顺序不作要求。\n\n查询输出格式请参考下面示例。\n\nProducts table:\n\n```\n+------------+--------+--------+--------+\n| product_id | store1 | store2 | store3 |\n+------------+--------+--------+--------+\n| 0          | 95     | 100    | 105    |\n| 1          | 70     | null   | 80     |\n+------------+--------+--------+--------+\n```\n\nResult table:\n\n```\n+------------+--------+-------+\n| product_id | store  | price |\n+------------+--------+-------+\n| 0          | store1 | 95    |\n| 0          | store2 | 100   |\n| 0          | store3 | 105   |\n| 1          | store1 | 70    |\n| 1          | store3 | 80    |\n+------------+--------+-------+\n```\n\n产品0在store1，store2,store3的价格分别为95,100,105。\n\n产品1在store1，store3的价格分别为70,80。在store2无法买到。\n\n','examDataFiles/auto_upload_1948_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1948_1637126775646.sql',1,1,0),(1958,'0','没有广告的剧集','Table: Playback\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| session_id  | int  |\n| customer_id | int  |\n| start_time  | int  |\n| end_time    | int  |\n+-------------+------+\n```\n\n该表主键为：session_id （剧集id）\n\ncustomer_id 是观看该剧集的观众id\n\n剧集播放时间包含start_time（开始时间） 及 end_time（结束时间）\n\n可以保证的是，start_time（开始时间）<= end_time（结束时间），一个观众观看的两个剧集的时间不会出现重叠。\n\nTable: Ads\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| ad_id       | int  |\n| customer_id | int  |\n| timestamp   | int  |\n+-------------+------+\n```\n\n该表的主键为：ad_id（广告id）\n\ncustomer_id 为 观看广告的用户id\n\ntimestamp 表示广告出现的时间点\n\n请查出，所有没有广告出现过的剧集。\n\n如果观众观看了剧集，并且剧集里出现了广告，就一定会有观众观看广告的记录。\n\n返回结果没有顺序要求。\n\n示例：\n\nPlayback table:\n\n```\n+------------+-------------+------------+----------+\n| session_id | customer_id | start_time | end_time |\n+------------+-------------+------------+----------+\n| 1          | 1           | 1          | 5        |\n| 2          | 1           | 15         | 23       |\n| 3          | 2           | 10         | 12       |\n| 4          | 2           | 17         | 28       |\n| 5          | 2           | 2          | 8        |\n+------------+-------------+------------+----------+\n```\n\nAds table:\n\n```\n+-------+-------------+-----------+\n| ad_id | customer_id | timestamp |\n+-------+-------------+-----------+\n| 1     | 1           | 5         |\n| 2     | 2           | 17        |\n| 3     | 2           | 20        |\n+-------+-------------+-----------+\n```\n\nResult table:\n\n```\n+------------+\n| session_id |\n+------------+\n| 2          |\n| 3          |\n| 5          |\n+------------+\n```\n\n广告1出现在了剧集1的时间段，被观众1看到了。\n\n广告2出现在了剧集4的时间段，被观众2看到了。\n\n广告3出现在了剧集4的时间段，被观众2看到了。\n\n我们可以得出结论，剧集1 、4 内，起码有1处广告。 剧集2 、3 、5 没有广告。\n\n','examDataFiles/auto_upload_1958_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1958_1637126775646.sql',1,1,0),(1964,'0','寻找面试候选人','表: Contests\n\n```\n+--------------+------+\n| Column Name  | Type |\n+--------------+------+\n| contest_id   | int  |\n| gold_medal   | int  |\n| silver_medal | int  |\n| bronze_medal | int  |\n+--------------+------+\n```\n\ncontest_id 是该表的主键.\n\n该表包含LeetCode竞赛的ID和该场比赛中金牌、银牌、铜牌的用户id。\n\n可以保证，所有连续的比赛都有连续的ID，没有ID被跳过。\n\nTable: Users\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| user_id     | int     |\n| mail        | varchar |\n| name        | varchar |\n+-------------+---------+\n```\n\nuser_id 是该表的主键.\n\n该表包含用户信息。\n\n编写 SQL 语句来返回面试候选人的 姓名和邮件.当用户满足以下两个要求中的任意一条，其成为面试候选人:\n\n该用户在连续三场及更多比赛中赢得奖牌。\n\n该用户在三场及更多不同的比赛中赢得金牌（这些比赛可以不是连续的）\n\n可以以任何顺序返回结果。\n\n查询结果格式如下例所示：\n\nContests表:\n\n```\n+------------+------------+--------------+--------------+\n| contest_id | gold_medal | silver_medal | bronze_medal |\n+------------+------------+--------------+--------------+\n| 190        | 1          | 5            | 2            |\n| 191        | 2          | 3            | 5            |\n| 192        | 5          | 2            | 3            |\n| 193        | 1          | 3            | 5            |\n| 194        | 4          | 5            | 2            |\n| 195        | 4          | 2            | 1            |\n| 196        | 1          | 5            | 2            |\n+------------+------------+--------------+--------------+\n```\n\nUsers表:\n\n```\n+---------+--------------------+-------+\n| user_id | mail               | name  |\n+---------+--------------------+-------+\n| 1       | sarah@leetcode.com | Sarah |\n| 2       | bob@leetcode.com   | Bob   |\n| 3       | alice@leetcode.com | Alice |\n| 4       | hercy@leetcode.com | Hercy |\n| 5       | quarz@leetcode.com | Quarz |\n+---------+--------------------+-------+\n```\n\n结果表:\n\n```\n+-------+--------------------+\n| name  | mail               |\n+-------+--------------------+\n| Sarah | sarah@leetcode.com |\n| Bob   | bob@leetcode.com   |\n| Alice | alice@leetcode.com |\n| Quarz | quarz@leetcode.com |\n+-------+--------------------+\n```\n\nSarah 赢得了3块金牌 (190, 193, and 196),所以我们将她列入结果表。\n\nBob在连续3场竞赛中赢得了奖牌(190, 191, and 192), 所以我们将他列入结果表。\n\n    - 注意他在另外的连续3场竞赛中也赢得了奖牌(194, 195, and 196).\n\nAlice在连续3场竞赛中赢得了奖牌 (191, 192, and 193), 所以我们将她列入结果表。\n\nQuarz在连续5场竞赛中赢得了奖牌(190, 191, 192, 193, and 194), 所以我们将他列入结果表。\n\n进阶：\n\n如果第一个条件变成“该用户在连续n场及比赛中赢得任意奖牌。”呢？你如何更改你的解法，来选出面试候选人？可以把n想象成存储过程中的参数。\n\n有的用户可能没有参加每一场竞赛，但是在参加的每一场竞赛中都表现得不错。你如何更改你的解法，以达到只考虑那些用户参与了的比赛？可假设另一张表给出了每场比赛的注册用户信息。\n\n','examDataFiles/auto_upload_1964_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1964_1637126775646.sql',2,1,0),(1974,'0','寻找今年具有正收入的客户','表：Customers\n\n```\n+--------------+------+\n| Column Name  | Type |\n+--------------+------+\n| customer_id  | int  |\n| year         | int  |\n| revenue      | int  |\n+--------------+------+\n```\n\n(customer_id, year) 是这个表的主键。\n\n这个表包含客户 ID 和不同年份的客户收入。\n\n注意，这个收入可能是负数。\n\n写一个 SQL 查询来查询 2021 年具有 正收入 的客户。\n\n可以按 任意顺序 返回结果表。\n\n查询结果格式如下例。\n\nCustomers\n\n```\n+-------------+------+---------+\n| customer_id | year | revenue |\n+-------------+------+---------+\n| 1           | 2018 | 50      |\n| 1           | 2021 | 30      |\n| 1           | 2020 | 70      |\n| 2           | 2021 | -50     |\n| 3           | 2018 | 10      |\n| 3           | 2016 | 50      |\n| 4           | 2021 | 20      |\n+-------------+------+---------+\n```\n\nResult table:\n\n```\n+-------------+\n| customer_id |\n+-------------+\n| 1           |\n| 4           |\n+-------------+\n```\n\n客户 1 在 2021 年的收入等于 30 。\n\n客户 2 在 2021 年的收入等于 -50 。\n\n客户 3 在 2021 年没有收入。\n\n客户 4 在 2021 年的收入等于 20 。\n\n因此，只有客户 1 和 4 在 2021 年有正收入。\n\n','examDataFiles/auto_upload_1974_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1974_1637126775646.sql',1,1,0),(1981,'0','每天的最大交易','表: Transactions\n\n```\n+----------------+----------+\n| Column Name    | Type     |\n+----------------+----------+\n| transaction_id | int      |\n| day            | datetime |\n| amount         | int      |\n+----------------+----------+\n```\n\ntransaction_id 是此表的主键。\n\n每行包括了该次交易的信息。\n\n写一条 SQL返回每天交易金额 amount 最大的交易 ID 。如果某天有多个这样的交易，返回这些交易的 ID 。\n\n返回结果根据 transaction_id升序排列。\n\n查询结果样例如下：\n\nTransactions table:\n\n```\n+----------------+--------------------+--------+\n| transaction_id | day                | amount |\n+----------------+--------------------+--------+\n| 8              | 2021-4-3 15:57:28  | 57     |\n| 9              | 2021-4-28 08:47:25 | 21     |\n| 1              | 2021-4-29 13:28:30 | 58     |\n| 5              | 2021-4-28 16:39:59 | 40     |\n| 6              | 2021-4-29 23:39:28 | 58     |\n+----------------+--------------------+--------+\n```\n\nResult table:\n\n```\n+----------------+\n| transaction_id |\n+----------------+\n| 1              |\n| 5              |\n| 6              |\n| 8              |\n+----------------+\n```\n\n\"2021-4-3\"  --> 有一个 id 是 8 的交易，因此，把它加入结果表。 \n\n\"2021-4-28\" --> 有两个交易，id 是 5 和 9 ，交易 5 的金额是 40 ，而交易 9 的数量是 21 。只需要将交易 5 加入结果表，因为它是当天金额最大的交易。\n\n\"2021-4-29\" --> 有两个交易，id 是 1 和 6 ，这两个交易的金额都是 58 ，因此需要把它们都写入结果表。\n\n最后，把交易 id 按照升序排列。\n\n进阶：你可以不使用MAX()函数解决这道题目吗?\n\n','examDataFiles/auto_upload_1981_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1981_1637126775646.sql',2,1,0),(1991,'0','联赛信息统计','Table: Teams\n\n```\n+----------------+---------+\n| Column Name    | Type    |\n+----------------+---------+\n| team_id        | int     |\n| team_name      | varchar |\n+----------------+---------+\n```\n\nteam_id 是该表主键.\n\n每一行都包含了一个参加联赛的队伍信息.\n\nTable: Matches\n\n```\n+-----------------+---------+\n| Column Name     | Type    |\n+-----------------+---------+\n| home_team_id    | int     |\n| away_team_id    | int     |\n| home_team_goals | int     |\n| away_team_goals | int     |\n+-----------------+---------+\n```\n\n(home_team_id, away_team_id) 是该表主键.\n\n每一行包含了一次比赛信息.\n\nhome_team_goals 代表主场队得球数.\n\naway_team_goals 代表客场队得球数.\n\n获得球数较多的队伍为胜者队伍.\n\n写一段SQL，用来报告联赛信息. 统计数据应使用已进行的比赛来构建，其中获胜球队获得三分，而失败球队获得零分. 如果打平，两支球队都得一分.\n\nresult表的每行应包含以下信息:\n\nteam_name - Teams表中的队伍名字\n\nmatches_played - 主场与客场球队进行的比赛次数.\n\npoints - 球队获得的总分数.\n\ngoal_for - 球队在所有比赛中获取的总进球数\n\ngoal_against - 球队在所有比赛中，他的对手球队的所有进球数\n\ngoal_diff - goal_for - goal_against.\n\n按分数降序返回结果表。 如果两队或多队得分相同，则按goal_diff 降序排列。 如果仍然存在平局，则以team_name 按字典顺序排列它们。\n\n查询的结果格式如下例所示:\n\nTeams table:\n\n```\n+---------+-----------+\n| team_id | team_name |\n+---------+-----------+\n| 1       | Ajax      |\n| 4       | Dortmund  |\n| 6       | Arsenal   |\n+---------+-----------+\n```\n\nMatches table:\n\n```\n+--------------+--------------+-----------------+-----------------+\n| home_team_id | away_team_id | home_team_goals | away_team_goals |\n+--------------+--------------+-----------------+-----------------+\n| 1            | 4            | 0               | 1               |\n| 1            | 6            | 3               | 3               |\n| 4            | 1            | 5               | 2               |\n| 6            | 1            | 0               | 0               |\n+--------------+--------------+-----------------+-----------------+\n```\n\nResult table:\n\n```\n+-----------+----------------+--------+----------+--------------+-----------+\n| team_name | matches_played | points | goal_for | goal_against | goal_diff |\n+-----------+----------------+--------+----------+--------------+-----------+\n| Dortmund  | 2              | 6      | 6        | 2            | 4         |\n| Arsenal   | 2              | 2      | 3        | 3            | 0         |\n| Ajax      | 4              | 2      | 5        | 9            | -4        |\n+-----------+----------------+--------+----------+--------------+-----------+\n```\n\nAjax (team_id=1) 有4场比赛: 2败2平. 总分数 = 0 + 0 + 1 + 1 = 2.\n\nDortmund (team_id=4) 有2场比赛: 2胜. 总分数 = 3 + 3 = 6.\n\nArsenal (team_id=6) 有2场比赛: 2平. 总分数 = 1 + 1 = 2.\n\nDortmund 是积分榜上的第一支球队. Ajax和Arsenal 有同样的分数, 但Arsenal的goal_diff高于Ajax, 所以Arsenal在表中的顺序在Ajaxzhi\'qian.\n\n','examDataFiles/auto_upload_1991_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_1991_1637126775646.sql',2,1,0),(2004,'0','转换日期格式','表: Days\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| day         | date |\n+-------------+------+\n```\n\nday 是这个表的主键。\n\n给定一个Days表，请你编写SQL查询语句，将Days表中的每一个日期转化为\"day_name, month_name day, year\"格式的字符串。\n\n返回的结果表不计顺序。\n\n例如：\n\nDays table:\n\n```\n+------------+\n| day        |\n+------------+\n| 2022-04-12 |\n| 2021-08-09 |\n| 2020-06-26 |\n+------------+\n```\n\nResult table:\n\n```\n+-------------------------+\n| day                     |\n+-------------------------+\n| Tuesday, April 12, 2022 |\n| Monday, August 9, 2021  |\n| Friday, June 26, 2020   |\n+-------------------------+\n```\n\n请注意，输出对大小写敏感。\n\n','examDataFiles/auto_upload_2004_1637126775646.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2004_1637126775646.sql',1,1,0),(2024,'0','计算特殊奖金','表: Employees\n\n```\n+-------------+---------+\n| 列名        | 类型     |\n+-------------+---------+\n| employee_id | int     |\n| name        | varchar |\n| salary      | int     |\n+-------------+---------+\n```\n\nemployee_id 是这个表的主键。\n\n此表的每一行给出了雇员id ，名字和薪水。\n\n写出一个SQL 查询语句，计算每个雇员的奖金。如果一个雇员的id是奇数并且他的名字不是以\'M\'开头，那么他的奖金是他工资的100%，否则奖金为0。\n\nReturn the result table ordered by employee_id.\n\n返回的结果集请按照employee_id排序。\n\n查询结果格式如下面的例子所示：\n\nEmployees 表:\n\n```\n+-------------+---------+--------+\n| employee_id | name    | salary |\n+-------------+---------+--------+\n| 2           | Meir    | 3000   |\n| 3           | Michael | 3800   |\n| 7           | Addilyn | 7400   |\n| 8           | Juan    | 6100   |\n| 9           | Kannon  | 7700   |\n+-------------+---------+--------+\n```\n\n结果表:\n\n```\n+-------------+-------+\n| employee_id | bonus |\n+-------------+-------+\n| 2           | 0     |\n| 3           | 0     |\n| 7           | 7400  |\n| 8           | 0     |\n| 9           | 7700  |\n+-------------+-------+\n```\n\n因为雇员id是偶数，所以雇员id 是2和8的两个雇员得到的奖金是0。\n\n雇员id为3的因为他的名字以\'M\'开头，所以，奖金是0。\n\n其他的雇员得到了百分之百的奖金。\n\n','examDataFiles/auto_upload_2024_1637126775647.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2024_1637126775647.sql',1,1,0),(2041,'0','2020年最后一次登录','表: Logins\n\n```\n+----------------+----------+\n| 列名           | 类型      |\n+----------------+----------+\n| user_id        | int      |\n| time_stamp     | datetime |\n+----------------+----------+\n```\n\n(user_id, time_stamp) 是这个表的主键。\n\n每一行包含的信息是user_id 这个用户的登录时间。\n\n编写一个 SQL 查询，该查询可以获取在2020年登录过的所有用户的本年度最后一次登录时间。结果集不包含2020年没有登录过的用户。\n\n返回的结果集可以按任意顺序排列。\n\n查询结果格式如下例：\n\nLogins 表:\n\n```\n+---------+---------------------+\n| user_id | time_stamp          |\n+---------+---------------------+\n| 6       | 2020-06-30 15:06:07 |\n| 6       | 2021-04-21 14:06:06 |\n| 6       | 2019-03-07 00:18:15 |\n| 8       | 2020-02-01 05:10:53 |\n| 8       | 2020-12-30 00:46:50 |\n| 2       | 2020-01-16 02:49:50 |\n| 2       | 2019-08-25 07:59:08 |\n| 14      | 2019-07-14 09:00:00 |\n| 14      | 2021-01-06 11:59:59 |\n+---------+---------------------+\n```\n\nResult 表:\n\n```\n+---------+---------------------+\n| user_id | last_stamp          |\n+---------+---------------------+\n| 6       | 2020-06-30 15:06:07 |\n| 8       | 2020-12-30 00:46:50 |\n| 2       | 2020-01-16 02:49:50 |\n+---------+---------------------+\n```\n\n6号用户登录了3次，但是在2020年仅有一次，所以结果集应包含此次登录。\n\n8号用户在2020年登录了2次，一次在2月，一次在12月，所以，结果集应该包含12月的这次登录。\n\n2号用户登录了2次，但是在2020年仅有一次，所以结果集应包含此次登录。\n\n14号用户在2020年没有登录，所以结果集不应包含。\n\n','examDataFiles/auto_upload_2041_1637126775647.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2041_1637126775647.sql',1,1,0),(2057,'0','按分类统计薪水','表: Accounts\n\n```\n+-------------+------+\n| 列名        | 类型  |\n+-------------+------+\n| account_id  | int  |\n| income      | int  |\n+-------------+------+\n```\n\naccount_id是这个表的主键。\n\n每一行都包含一个银行帐户的月收入的信息。\n\n写出一个SQL查询，来报告每个工资类别的银行账户数量。工资类别如下：\n\n“低薪”：所有工资严格低于20000美元。\n\n“中等薪水”：包含范围内的所有工资[$20000,$50000]。\n\n“高薪”：所有工资严格大于50000美元。\n\n结果表必须包含所有三个类别。如果某个类别中没有帐户，则报告0。\n\n按任意顺序返回结果表。\n\n查询结果格式如下示例：\n\nAccounts 表:\n\n```\n+------------+--------+\n| account_id | income |\n+------------+--------+\n| 3          | 108939 |\n| 2          | 12747  |\n| 8          | 87709  |\n| 6          | 91796  |\n+------------+--------+\n```\n\nResult 表:\n\n```\n+----------------+----------------+\n| category       | accounts_count |\n+----------------+----------------+\n| Low Salary     | 1              |\n| Average Salary | 0              |\n| High Salary    | 3              |\n+----------------+----------------+\n```\n\n低薪: 数量为 2.\n\n中等薪水: 没有.\n\n高薪: 有三个账户，他们是 3, 6和 8.\n\n','examDataFiles/auto_upload_2057_1637126775647.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2057_1637126775647.sql',2,1,0),(2064,'0','兴趣相同的朋友','Table: Listens\n\n```\n+-------------+---------+\n| Column Name | Type    |\n+-------------+---------+\n| user_id     | int     |\n| song_id     | int     |\n| day         | date    |\n+-------------+---------+\n```\n\n该表没有主键，因此会存在重复的行。\n\n该表的每一行所代表的含义是：用户（user_id）在某天（day）听了某首歌曲（song_id）。\n\nTable: Friendship\n\n```\n+---------------+---------+\n| Column Name   | Type    |\n+---------------+---------+\n| user1_id      | int     |\n| user2_id      | int     |\n+---------------+---------+\n```\n\n(user1_id, user2_id) 是该表的主键。\n\n该表的每一行所代表的含义是，用户（user1_id, user2_id）是朋友。\n\n注意：user1_id < user2_id。\n\n请写一段SQL查询获取到兴趣相同的朋友。用户 x和 用户 y是兴趣相同的朋友，需满足下述条件：\n\n用户x和y是朋友，并且\n\n用户x and y在同一天内听过相同的歌曲，且数量大于等于三首.\n\n结果表无需排序。注意：返回的结果需要和源数据表的呈现方式相同（例如，需满足user1_id < user2_id）。\n\n结果表的格式如下例：\n\nListens table:\n\n```\n+---------+---------+------------+\n| user_id | song_id | day        |\n+---------+---------+------------+\n| 1       | 10      | 2021-03-15 |\n| 1       | 11      | 2021-03-15 |\n| 1       | 12      | 2021-03-15 |\n| 2       | 10      | 2021-03-15 |\n| 2       | 11      | 2021-03-15 |\n| 2       | 12      | 2021-03-15 |\n| 3       | 10      | 2021-03-15 |\n| 3       | 11      | 2021-03-15 |\n| 3       | 12      | 2021-03-15 |\n| 4       | 10      | 2021-03-15 |\n| 4       | 11      | 2021-03-15 |\n| 4       | 13      | 2021-03-15 |\n| 5       | 10      | 2021-03-16 |\n| 5       | 11      | 2021-03-16 |\n| 5       | 12      | 2021-03-16 |\n+---------+---------+------------+\n```\n\nFriendship table:\n\n```\n+----------+----------+\n| user1_id | user2_id |\n+----------+----------+\n| 1        | 2        |\n| 2        | 4        |\n| 2        | 5        |\n+----------+----------+\n```\n\nResult table:\n\n```\n+----------+----------+\n| user1_id | user2_id |\n+----------+----------+\n| 1        | 2        |\n+----------+----------+\n```\n\n用户 1 和 2 是朋友, 并且他们在同一天内都听了10、11、12的歌曲。所以，他们是兴趣相同的朋友。\n\n用户 1 和 3 在同一天内都听了10、11、12的歌曲，但他们不是朋友。\n\n用户 2 和 4 是朋友，但他们同一天内听过相同的歌曲的数量小于3。\n\n用户 2 和 5 是朋友，并且在都听了了10、11、12的歌曲，但不在同一天内。\n\n','examDataFiles/auto_upload_2064_1637126775647.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2064_1637126775647.sql',3,1,0),(2098,'0','查询具有最多共同关注者的所有两两结对组','表: Relations\n\n```\n+-------------+------+\n| Column Name | Type |\n+-------------+------+\n| user_id     | int  |\n| follower_id | int  |\n+-------------+------+\n```\n\n(user_id, follower_id) 是这个表的主键.\n\n这个表的每一行，表示这个user_id的用户和他的关注者，关注者的id 就是本表的 user_id.\n\n写出一个查询语句，找到具有最多共同关注者的所有两两结对组。换句话说，如果有两个用户的共同关注者是最大的，我们应该返回所有具有此最大值的两两结对组\n\nThe result table should contain the pairs user1_id and user2_id where user1_id < user2_id.\n\n结果返回表，每一行应该包含user1_id和user2_id，其中user1_id < user2_id.\n\n返回结果不要求顺序。\n\n查询结果格式如下例：\n\nRelations 表:\n\n```\n+---------+-------------+\n| user_id | follower_id |\n+---------+-------------+\n| 1       | 3           |\n| 2       | 3           |\n| 7       | 3           |\n| 1       | 4           |\n| 2       | 4           |\n| 7       | 4           |\n| 1       | 5           |\n| 2       | 6           |\n| 7       | 5           |\n+---------+-------------+\n```\n\nResult 表:\n\n```\n+----------+----------+\n| user1_id | user2_id |\n+----------+----------+\n| 1        | 7        |\n+----------+----------+\n```\n\n用户1 和用户 2 有2个共同的关注者（3和4）。\n\n用户1 和用户 7 有3个共同的关注者（3，4和5）。\n\n用户2 和用户7 有2个共同的关注者（3和4）。\n\n既然两两结对的所有组队的最大共同关注者的数值是3，所以，我们应该返回所有拥有3个共同关注者的两两组队，这就是仅有的一对(1, 7).\n\n我们返回的是(1, 7).，而不是(7, 1).\n\n注意，我们没有关于用户3，4，5的任何关注者信息，我们认为他们有0个关注者。\n\n','examDataFiles/auto_upload_2098_1637126775647.sql','2021-11-17 13:26:15','2021-11-17 13:26:15','auto_upload_2098_1637126775647.sql',2,1,0);
/*!40000 ALTER TABLE main_question ENABLE KEYS */;
-- UNLOCK TABLES;

--
-- Table structure for table `pass_record`
--

DROP TABLE IF EXISTS `pass_record`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `pass_record` (
  `student_id` varchar(255) NOT NULL,
  `exam_id` varchar(255) NOT NULL,
  `main_id` int(11) NOT NULL,
  `sub_id` int(11) NOT NULL,
  `point` int(11) NOT NULL,
  `batch_id` varchar(255) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`student_id`,`exam_id`,`sub_id`),
  KEY `pass_record_student_exam` (`student_id`,`exam_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `pass_record`
--

LOCK TABLES `pass_record` WRITE;
/*!40000 ALTER TABLE `pass_record` DISABLE KEYS */;
INSERT INTO `pass_record` VALUES ('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2b53c435-d7fa-42f9-adfb-03d1b244b367',175,881,10,'287801ba-268c-44b7-815c-cf42398ebaaf','2022-04-01 15:26:26','2022-04-01 15:26:26'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','2b53c435-d7fa-42f9-adfb-03d1b244b367',176,882,10,'d02924f5-5002-446d-bb59-fcb25ec5ffe9','2022-04-01 15:31:37','2022-04-01 15:31:37'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882,10,'cc4aadd5-8646-433a-89d3-1da68eefae6b','2022-04-06 20:06:19','2022-04-06 20:06:19'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','7f578d03-d1a4-4a1d-8ce5-82d3071805a2',175,881,10,'e09dc0f1-2adc-4df4-a232-768cb2f61a7d','2022-04-01 14:58:45','2022-04-01 14:58:45'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','b653e85b-c263-42cd-ba3e-fe1804a819db',175,881,10,'f8d50fc4-2388-461d-ba98-c9a87d7be4e0','2022-04-01 20:31:07','2022-04-01 20:31:07'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','b653e85b-c263-42cd-ba3e-fe1804a819db',176,882,10,'ea7398b7-4873-4424-97ee-ef501254e36a','2022-04-01 19:15:57','2022-04-01 19:15:57'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','c270f300-b9d9-4585-9d25-d20065c22ab5',175,881,10,'8af9048a-7489-46bd-b28a-4fb305d37779','2022-04-02 14:54:19','2022-04-02 14:54:19'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','c270f300-b9d9-4585-9d25-d20065c22ab5',176,882,10,'9c849c72-4ac2-4ae5-a05c-2a9b1a2710d7','2022-04-02 14:55:28','2022-04-02 14:55:28');
/*!40000 ALTER TABLE `pass_record` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `question_tags`
--

DROP TABLE IF EXISTS `question_tags`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `question_tags` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `question_id` int(11) NOT NULL,
  `tag` int(11) NOT NULL,
  `weight` double NOT NULL,
  `manual` tinyint(1) NOT NULL DEFAULT '0',
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  `state` tinyint(4) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `question_tags`
--

LOCK TABLES `question_tags` WRITE;
/*!40000 ALTER TABLE `question_tags` DISABLE KEYS */;
/*!40000 ALTER TABLE `question_tags` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `schema_version`
--

DROP TABLE IF EXISTS `schema_version`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `schema_version` (
  `name` varchar(255) COLLATE utf8_unicode_ci NOT NULL,
  PRIMARY KEY (`name`),
  UNIQUE KEY `name` (`name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `schema_version`
--

LOCK TABLES `schema_version` WRITE;
/*!40000 ALTER TABLE `schema_version` DISABLE KEYS */;
INSERT INTO `schema_version` VALUES ('04-00200-nedb-sqlite-tables.js'),('04-00300-batch.js'),('05-00100-sessions.js'),('06-00110-exams.js'),('06-00130-pass-record.js'),('06-00200-main-question.js'),('06-00201-sub-question.js'),('06-00226-students.js'),('06-00227-exams-status.js'),('06-00230-courses.js'),('06-00231-courses-students.js'),('06-00232-user-add-phone-index.js'),('07-00100-batches-add-columns.js'),('07-00110-question-tags.js'),('07-00200-change-sub-questions.js'),('07-00300-add-question-state.js');
/*!40000 ALTER TABLE `schema_version` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `score_record`
--

DROP TABLE IF EXISTS `score_record`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `score_record` (
  `student_id` varchar(255) NOT NULL,
  `exam_id` varchar(255) NOT NULL,
  `main_id` int(11) NOT NULL,
  `sub_id` int(11) NOT NULL,
  `score` float DEFAULT NULL,
  `created_at` datetime DEFAULT NULL,
  `updated_at` datetime DEFAULT NULL,
  PRIMARY KEY (`student_id`,`exam_id`,`main_id`,`sub_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `score_record`
--

LOCK TABLES `score_record` WRITE;
/*!40000 ALTER TABLE `score_record` DISABLE KEYS */;
INSERT INTO `score_record` VALUES ('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','67fa9751-c0aa-49a9-b0fd-54fc4431c2bd',176,882,10,'2022-04-04 16:02:40','2022-04-12 23:02:10'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','c270f300-b9d9-4585-9d25-d20065c22ab5',175,881,10,'2022-04-02 14:53:44','2022-04-02 14:54:20'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','c270f300-b9d9-4585-9d25-d20065c22ab5',176,882,10,'2022-04-02 14:51:42','2022-04-02 14:55:30');
/*!40000 ALTER TABLE `score_record` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `sessions`
--

DROP TABLE IF EXISTS `sessions`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `sessions` (
  `sid` varchar(36) NOT NULL,
  `expires` datetime DEFAULT NULL,
  `data` text,
  `created_at` datetime DEFAULT NULL,
  `updated_at` datetime DEFAULT NULL,
  PRIMARY KEY (`sid`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `sessions`
--

LOCK TABLES `sessions` WRITE;
/*!40000 ALTER TABLE `sessions` DISABLE KEYS */;
INSERT INTO `sessions` VALUES ('39nF-UNXnNgAnhWJjcrA0nVKwqj7Yhyu','2022-09-23 16:01:42','{\"cookie\":{\"originalMaxAge\":3600000,\"expires\":\"2022-09-23T07:59:01.274Z\",\"httpOnly\":true,\"path\":\"/\"},\"user\":{\"id\":\"0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18\",\"email\":\"181250122@smail.nju.edu.cn\",\"role\":\"teacher\",\"name\":\"teacher\",\"phone\":\"11111111111\",\"disabled\":false,\"passhash\":\"$2a$10$HSNZRL4sJkXZ1Jy9Y8iIaOjfDA/LB1g2zPcqP6WjZePk0VH1ia6MG\",\"passwordResetId\":null,\"data\":null,\"signupAt\":\"2021-11-14T11:18:06.000Z\",\"createdAt\":\"2021-11-14T11:18:06.000Z\",\"updatedAt\":\"2021-11-14T11:18:06.000Z\"},\"student\":{\"id\":\"0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18\",\"studentsNum\":\"181250122\",\"email\":\"181250122@smail.nju.edu.cn\",\"phone\":\"11111111111\",\"name\":\"teacher\",\"createdAt\":\"2021-11-14T11:18:06.000Z\",\"updatedAt\":\"2021-11-14T11:18:06.000Z\"},\"passport\":{\"user\":\"0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18\"}}','2022-09-23 14:59:01','2022-09-23 15:01:42');
/*!40000 ALTER TABLE `sessions` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `students`
--

DROP TABLE IF EXISTS `students`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `students` (
  `id` varchar(255) NOT NULL,
  `students_num` varchar(255) DEFAULT NULL,
  `email` varchar(255) DEFAULT NULL,
  `phone` varchar(255) NOT NULL,
  `name` varchar(255) NOT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  CONSTRAINT `students_id_key` FOREIGN KEY (`id`) REFERENCES `users` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `students`
--

LOCK TABLES `students` WRITE;
/*!40000 ALTER TABLE `students` DISABLE KEYS */;
INSERT INTO `students` VALUES ('0607f08a-e61e-4012-872e-1892de8b754d','181250122','181250132@smail.nju.edu.cn','13235210595','admin','2021-11-10 12:57:27','2021-11-10 12:57:27'),('0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18','181250122','181250122@smail.nju.edu.cn','11111111111','teacher','2021-11-14 19:18:06','2021-11-14 19:18:06'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','181250036','181250036@smail.nju.edu.cn','18839040927','s','2021-11-11 22:07:58','2021-11-11 22:07:58');
/*!40000 ALTER TABLE `students` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `sub_questions`
--
--
-- DROP TABLE IF EXISTS `sub_questions`;
-- /*!40101 SET @saved_cs_client     = @@character_set_client */;
-- /*!40101 SET character_set_client = utf8 */;
-- CREATE TABLE `sub_questions` (
--   `id` int(11) NOT NULL AUTO_INCREMENT,
--   `main_id` int(11) NOT NULL,
--   `desc` text NOT NULL,
--   `answer` text NOT NULL,
--   `created_at` datetime NOT NULL,
--   `updated_at` datetime NOT NULL,
--   `difficulty` int(11) NOT NULL,
--   `ordered` tinyint(1) NOT NULL DEFAULT '1',
--   `state` tinyint(4) NOT NULL DEFAULT '0',
--   PRIMARY KEY (`id`),
--   KEY `sub_questions_main_id_key` (`main_id`),
--   CONSTRAINT `sub_questions_main_id_key` FOREIGN KEY (`main_id`) REFERENCES `main_questions` (`id`) ON DELETE CASCADE ON UPDATE CASCADE
-- ) ENGINE=InnoDB AUTO_INCREMENT=883 DEFAULT CHARSET=utf8;
-- /*!40101 SET character_set_client = @saved_cs_client */;
--
-- --
-- -- Dumping data for table `sub_questions`
-- --
--
-- LOCK TABLES `sub_questions` WRITE;
-- /*!40000 ALTER TABLE `sub_questions` DISABLE KEYS */;
-- INSERT INTO `sub_questions` VALUES (4,125,'查询Tom和Jerry的存款','select `name`,`amount` from blank_data where name=\'Tom\' or name=\'Jerry\';','2020-11-16 07:17:06','2020-12-28 17:33:56',1,0,0),(5,125,'查询Tom和Jerry的地址','select `name`,`address` from address_data where name=\'Tom\' or name=\'Jerry\';','2020-11-16 07:18:08','2020-12-30 10:40:34',1,0,0),(10,1,'编写一个sql语句，查询累计工作时间超过1000的职工，结果返回职工工号eno。','select w.eno \nfrom works w\ngroup by w.eno\nhaving sum(hours) > 1000;','2020-11-25 12:49:46','2022-04-21 20:11:22',1,0,0),(11,1,'编写一个sql语句，查询没有登记家属的职工，结果返回职工工号eno。','select e.eno\nfrom employees e\nwhere not exists (\n	select *\n	from relations r\n	where r.eno = e.eno\n);','2020-11-25 12:50:18','2021-04-10 20:10:36',1,0,0),(12,1,'编写一个sql语句，查询所有职工都参与的项目，结果返回项目编号pno。','select p.pno\nfrom projects p\nwhere not exists (\n    select * \n    from employees e\n    where not exists(\n        select *\n        from works w\n        where w.eno = e.eno and w.pno = p.pno\n    )\n)','2020-11-25 12:51:08','2021-03-30 21:59:30',1,0,0),(13,1,'编写一个sql语句，查询每一个部门中薪水最高的职工，结果返回部门编号dno，薪水最高的职工工号eno和薪水salary，以dno升序排列。','select e1.dno,e1.eno, e1.salary\nfrom employees e1\nwhere e1.salary in (\n	select MAX(salary)\n	from employees e2\n	where e1.dno = e2.dno\n	group by dno\n)\norder by dno;','2020-11-25 12:53:41','2021-03-30 22:01:33',2,1,0),(14,2,'编写一个sql语句，找出年龄在35以上的并且在2020-09-01至2020-09-30期间没有预定红色（RED）船只的水手，结果返回水手姓名sname。','select s.sname from sailors s\nwhere s.age > 35 and not exists (\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid \n	where  \n	r.sid = s.sid and \n	b.color = \'RED\' and\n	(r.reserve_date between \'2020-09-01\' and \'2020-09-30\')\n);','2020-11-25 14:42:26','2021-04-07 11:13:59',1,0,0),(15,3,'编写一个sql语句，查询每件商品都购买过的用户，结果返回用户编号customer_id。','select c.customer_id\nfrom customers c\nwhere not exists (\n    select * \n    from products p\n    where not exists (\n        select * \n        from orders o\n        where o.customer_id = c.customer_id and o.product_id = p.product_id\n    )\n);','2020-11-25 14:59:19','2021-03-30 22:11:51',1,0,0),(16,3,'编写一个sql语句，找出2020-08-01至2020-08-31期间订单数量最多的客户，数量相同时选择customer_id较小的用户，结果返回用户编号customer_id和购买数量order_num。','select o.customer_id, count(distinct order_id) as order_num\nfrom orders o\nwhere o.order_date BETWEEN \'2020-08-01\' and \'2020-08-31\'\nGROUP BY o.customer_id\norder by order_num DESC, customer_id asc\nlimit 1;','2020-11-25 15:01:38','2021-04-06 23:58:13',2,0,0),(17,3,'编写一个sql语句，找出每件商品的最新订单(可能有多个)，结果返回商品名称product_name，订单号order_id和订单日期order_date，以product_name升序排列。','SELECT\n	p.product_name AS product_name,\n	o.order_id,\n	o.order_date\nFROM\n	orders o,\n	customers c,\n	products p\nWHERE\n	o.customer_id = c.customer_id\nAND o.product_id = p.product_id\nAND (o.product_id, o.order_date) IN (\n	SELECT\n		product_id,\n		MAX(order_date)\n	FROM\n		orders\n	GROUP BY\n		product_id\n)\nORDER BY product_name;\n','2020-11-25 15:10:49','2021-03-30 22:07:24',2,1,0),(18,3,'编写一个sql语句，找到每个用户最近三笔订单。若用户订单少于3笔，则返回该用户的全部订单，结果返回用户名customer_name，订单编号order_id和订单日期order_date，以custromer_name升序，order_date降序排列。','SELECT c.name customer_name,o2.order_id,o2.order_date\nFROM orders o1,orders o2,customers c\nWHERE o1.customer_id=o2.customer_id AND c.customer_id=o2.customer_id\nGROUP BY c.name,o2.order_id,o2.customer_id,o2.order_date\nHAVING SUM(o1.order_date>=o2.order_date)<=3\nORDER BY c.name,o2.order_date desc;','2020-11-25 15:14:53','2021-03-30 22:11:35',2,1,0),(19,4,'编写一个sql语句，查询参加比赛场次最多的选手，若参与比赛场次相同，选择用户编号player_id较小的选手，结果返回用户编号player_id和参与的比赛数量match_num。','select player_id, count(*) as match_num from \n(\n	select p.player_id \n	from players p join matches m\n	on p.player_id = m.first_player or p.player_id = m.second_player\n) tot_player\ngroup by player_id\nORDER BY match_num DESC,player_id asc\nlimit 1;','2020-11-25 15:28:48','2021-03-30 22:13:15',2,0,0),(20,4,'编写一个sql语句，查询各组进行的比赛场次，结果返回组号group_id及各组的场次数match_num。','select group_id, count(match_id) as match_num\nfrom matches\ngroup by group_id;','2020-11-25 15:31:30','2021-03-30 22:13:39',1,0,0),(21,4,'编写一个sql语句，查询分差最大的一场比赛，若分差相同，选择编号match_id较小的比赛，结果返回比赛编号match_id和分差sub（大于0）。','select match_id, ABS(first_score - second_score) as sub\nfrom matches\norder by ABS(first_score - second_score) desc, match_id asc\nlimit 1;','2020-11-25 15:37:23','2021-03-30 22:14:39',2,0,0),(22,4,'编写一个sql语句，查找每组中的获胜者。每组的获胜者是在组内累积得分最高的选手。如果有得分相同的情况，则认为player_id 最小的选手获胜，结果返回组号group_id和选手编号player_id，以group_id升序排列。','select group_id,min(player_id) as player_id\nfrom\n    (select player,sum(score) as score\n    from\n        ((select first_player player,first_score score from matches)\n        union all\n        (select second_player player,second_score score from matches)) t\n    group by player) a\n    right join players p on a.player=p.player_id\nwhere (group_id,score) in\n(select group_id,max(score) as mx\nfrom \n    (select player,sum(score) as score\n    from\n        ((select first_player player,first_score score from matches)\n        union all\n        (select second_player player,second_score score from matches)) t\n    group by player) a\n    right join players p on a.player=p.player_id\ngroup by group_id)\ngroup by group_id\norder by group_id;','2020-11-25 15:39:59','2021-03-30 22:29:39',3,1,0),(23,5,'编写一个sql查询，查找订单数量最多的一天以及当天的订单数量，订单数相同时选择日期最小的一天，结果返回日期order_date和订单数量num。','select order_date,count(*) as num\nfrom orders \ngroup by order_date\norder by num DESC,order_date asc\nlimit 1;','2020-11-25 15:46:15','2021-03-30 22:30:34',1,0,0),(24,5,'编写一个sql语句，查找买到过自己最喜欢的商品的用户，结果返回用户编号user_id。','select u.user_id \nfrom users u\nwhere exists (\n	select * \n	from orders o LEFT JOIN items i\n	on o.item_id = i.item_id\n	where o.buyer_id = u.user_id and u.favorite_brand = i.item_brand\n);','2020-11-25 15:47:57','2021-03-30 22:30:59',2,0,0),(25,5,'编写一个sql语句，查询每个用户的注册日期以及在2019年作为买家的订单总数，结果返回用户编号user_id，注册日期join_date和订单数量orders_in_2019，以user_id升序排列。','select user_id, join_date, count(order_id) orders_in_2019\nfrom users left join orders\non user_id = buyer_id and year(order_date)=\'2019\'\ngroup by user_id\norder by user_id;','2020-11-25 15:50:21','2021-04-07 11:54:25',2,1,0),(26,5,'编写一个sql语句，查询每一个用户按顺序卖出的第二件商品是否是他们最喜爱的品牌。结果返回卖家编号seller_id和是否是最喜爱品牌的情况if_fav_brand（取值为\'yes\'，\'no\'，售出小于2件时返回 ‘no’），以seller_id升序排列。','select user_id seller_id, if(favorite_brand = item_brand, \'yes\', \'no\') if_fav_brand\nfrom users left join (\n    select seller_id, item_brand\n    from (\n        select o1.seller_id, o1.item_id\n        from orders o1 join orders o2\n        on o1.seller_id = o2.seller_id\n        group by o1.order_id\n        having sum(o1.order_date > o2.order_date) = 1\n    ) o join items i\n    on o.item_id = i.item_id\n) tmp\non user_id = seller_id\norder by seller_id;','2020-11-25 16:15:32','2021-04-14 00:12:51',3,1,0),(27,6,'编写一个sql语句，求出好友申请的总通过率accept_rate，用2位小数表示。通过率计算公式为接受好友申请的数目除以申请总数（申请和接收可能会有重复，此时均视作一次）。','select round(\n    ifnull(\n    (select count(distinct requester_id ,accepter_id) from accepted_requests) / \n    (select count(distinct sender_id ,send_to_id) from friend_requests)\n    ,0)\n    ,2) as accept_rate ;','2020-11-25 16:29:45','2021-04-10 21:29:14',2,0,0),(28,6,'编写一个sql语句，查询发出过申请，但所有申请都未通过的用户，结果返回用户编号user_id。','select distinct fr.sender_id user_id\nfrom friend_requests fr \nwhere exists (\n	select * from friend_requests fr2\n	where fr2.sender_id = fr.sender_id\n) and not exists (\n	select * from accepted_requests \n	where fr.sender_id = requester_id\n);','2020-11-25 16:30:33','2021-03-30 22:47:34',2,0,0),(29,6,'编写一个sql语句，查询每个月的通过率，结果返回月份mon及通过率accept_rate（不包括通过率为0的月份），以mon升序排列。','select t1.m1 as mon, t1.accept/t2.alla accept_rate from\n(select month(accept_date) m1, count(distinct concat(requester_id, accepter_id)) accept\nfrom accepted_requests \ngroup by month(accept_date)) t1\ninner join\n(select month(request_date) m2, count(distinct concat(sender_id, send_to_id)) alla\nfrom friend_requests \ngroup by month(request_date)) t2\non t1.m1=t2.m2\norder by mon;','2020-11-25 16:34:38','2021-03-30 22:48:20',2,1,0),(30,6,'编写一个sql语句，找出拥有最多的好友的用户以及他拥有的好友数目，好友数相同时选择user_id较小的用户，结果返回用户编号user_id和好友数目friend_num。','select user_id, count(*) friend_num\nfrom \n((select requester_id user_id\nfrom accepted_requests\n)\nunion all\n(select accepter_id user_id\nfrom accepted_requests)) t3\ngroup by user_id\norder by friend_num desc,user_id asc\nlimit 1;','2020-11-25 16:36:42','2021-03-30 22:48:56',2,0,0),(31,7,'编写一个sql语句，查询所有浏览过自己文章的作者，结果返回用户编号id，以id升序排列。','SELECT distinct author_id as id\nFROM views\nWHERE author_id = viewer_id\nORDER BY author_id;','2020-11-25 16:44:02','2021-03-30 22:52:20',1,1,0),(32,7,'编写一个sql语句，找出曾在一天内阅读至少两篇文章的人，结果返回用户编号viewer_id，以viewer_id升序排列。','select  distinct viewer_id from views \ngroup by viewer_id,view_date\nhaving count(distinct article_id) >= 2\norder by viewer_id;','2020-11-25 16:45:09','2021-03-30 22:53:20',2,1,0),(33,7,'编写一个sql语句，找出阅读文章总数最多的用户，阅读数量一样时选择view_id较小的用户，结果返回用户编号viewer_id和阅读文章数量article_num。','select viewer_id , count(*) as article_num  from views \ngroup by viewer_id \norder by article_num desc, viewer_id asc\nlimit 1;','2020-11-25 16:47:33','2021-04-07 00:20:29',2,0,0),(34,7,'编写一个sql语句，找出2020-08-01至2020-08-31期间阅读过3号作者文章的人，结果返回用户编号id，以id升序排列。','select distinct viewer_id as id\nfrom views v1  \nwhere exists(\n	select *\n	from views v2\n	where v2.viewer_id = v1.viewer_id and v2.author_id = 3\n				and (v2.view_date BETWEEN \'2020-08-01\' and \'2020-08-31\')\n)\norder by id;','2020-11-25 16:48:57','2021-04-07 11:16:15',2,1,0),(35,8,'编写一个sql语句，查询每个用户最近一天登录的日子，结果返回用户编号user_id和登录日期date，以user_id升序排列。','SELECT user_id, MAX(login_date) as date FROM logins\nGROUP BY user_id\nORDER BY user_id;','2020-11-25 18:08:13','2021-03-30 22:54:43',1,1,0),(36,8,'编写一个sql语句，查询新登录用户的留存率，即新用户第1天登陆之后，第2天再次登陆的概率，结果返回留存率rate。','select \ncount(distinct user_id)*1.0/(select count(distinct user_id) from logins) as rate\nfrom logins\nwhere (user_id,login_date)\nin (select user_id,DATE_ADD(min(login_date),INTERVAL 1 DAY) from logins group by user_id);','2020-11-25 18:09:23','2021-04-12 11:04:12',3,0,0),(37,8,'编写一个sql语句，查询登录新用户个数不少于2个的日期，结果返回日期login_date和登录新用户个数new_user_num，以login_date升序排序。','select l.mdate as login_date,count(user_id) as new_user_num\nfrom (\n    select user_id,min(login_date) as mdate\n    from logins\n    group by user_id) as l\ngroup by l.mdate \nhaving new_user_num >= 2\norder by login_date;','2020-11-25 18:11:07','2021-03-30 22:55:57',2,1,0),(38,8,'编写一个sql语句，查询每个日期新用户次日留存率（包括留存率为0的日期），即该日登录的新用户第二日仍然登录的概率，返回日期date和留存率rate，保留小数点后3位，以date升序排列。','SELECT a.date, ROUND(COUNT(b.user_id) * 1.0/COUNT(a.user_id), 3) AS rate\nFROM (\n    SELECT user_id, MIN(login_date) AS date\n    FROM logins\n    GROUP BY user_id) a\nLEFT JOIN logins b\nON a.user_id = b.user_id\nAND b.login_date = DATE_ADD(a.date,INTERVAL 1 day)\nGROUP BY a.date\nUNION\nSELECT login_date date, 0.000 AS rate\nFROM logins\nWHERE login_date NOT IN (\n    SELECT MIN(login_date)\n    FROM logins\n    GROUP BY user_id)\nORDER BY date;','2020-11-25 18:16:53','2021-03-30 22:56:49',3,1,0),(39,9,'编写一个sql语句，查询各个岗位分数的平均数，结果返回岗位名称job以及平均成绩avg，保留小数点后3位，以avg降序排序。','select job,round(sum(score)*1.0/count(user_id),3) as avg from grades\ngroup by job order by avg desc;','2020-11-25 18:51:53','2021-03-30 22:57:28',1,1,0),(40,9,'编写一个sql语句，查询分数大于其所在岗位平均分的用户，结果返回用户编号user_id，岗位名称job和该用户分数score，以user_id升序排序。','select grades.* from grades join \n(select job,round(sum(score)*1.0/count(user_id),3) as avg from grades\ngroup by job) as t\non grades.job=t.job\nwhere grades.score > t.avg\norder by user_id;','2020-11-25 18:52:57','2021-03-30 22:58:35',2,1,0),(41,9,'编写一个sql语句，查询各个岗位分数升序排列之后的中位数所在的位置start，end（范围从1开始，一个岗位参与人数为单数时 start = end，为偶数时 end = start + 1），以job升序排序。','SELECT job,FLOOR((COUNT(*)+1)/2) AS `start`,FLOOR((COUNT(*)+1)/2)+if(COUNT(*) % 2=1,0,1) AS `end` \nfrom grades\nGROUP BY job \norder by job;','2020-11-25 18:55:23','2021-04-07 00:07:37',1,1,0),(42,9,'编写一个sql语句，查询分数位于各个岗位中位数范围内的用户信息，结果返回用户编号user_id，岗位名称job，用户分数score和排名t_rank，以user_id升序排列。','select B.* from\n(SELECT job,FLOOR((COUNT(*)+1)/2) AS `start`,FLOOR((COUNT(*)+1)/2)+if(COUNT(*) % 2=1,0,1) AS `end` \nFROM grades  GROUP BY job) A\nJOIN\n(select g1.*, (\n    select count(distinct g2.score) \n    from grades g2 \n    where g2.score>=g1.score and g1.job=g2.job) as t_rank\nfrom grades g1 ) B\non (A.job=B.job  and B.t_rank between A.start and A.end)\norder by B.user_id;','2020-11-25 18:56:14','2021-03-30 23:04:04',3,1,0),(43,10,'编写一个sql语句，查找Technology部门工资的平均值，结果返回部门名称department和平均工资avg_salary。','select d.department_name as department, AVG(e.salary) as avg_salary\nfrom employees e LEFT JOIN departments d\non e.department_id = d.department_id\nwhere d.department_name = \'Technology\'\ngroup by e.department_id;','2020-11-25 19:11:07','2021-03-30 23:04:25',1,0,0),(44,10,'编写一个sql语句，查找各部门最高工资与最低工资的差值，结果返回部门名称department和差值sub。','select d.department_name department, MAX(salary)-MIN(salary) as sub\nfrom employees e LEFT JOIN departments d \non e.department_id = d.department_id\ngroup by e.department_id;','2020-11-25 19:12:40','2021-03-30 23:07:16',2,0,0),(45,10,'编写一个sql语句，获取各个部门第二高的薪水，结果返回部门名称department，员工姓名name和工资salary，以department升序排列。','select d.department_name as department,t.name,t.salary from \ndepartments d join \n(select name,salary,department_id from employees e1 where 1 = \n(select count(distinct(salary)) from employees e2 \nwhere e1.department_id = e2.department_id \nand e1.salary < e2.salary)) t\non d.department_id = t.department_id\norder by department;','2020-11-25 19:17:46','2021-03-30 23:04:59',3,1,0),(46,10,'编写一个sql语句，找出每个部门获得前三高工资的所有员工，结果返回部门名称department，员工姓名name和工资salary，以department升序，salary降序排列。','select d.department_name as department,e.name ,e.salary as salary\nfrom employees as e left join departments as d \non e.department_id = d.department_id\nwhere e.id in\n(\n    select e1.id\n    from employees as e1 left join employees as e2\n    on e1.department_id = e2.department_id and e1.salary < e2.salary\n    group by e1.id\n    having count(distinct e2.salary) <= 2\n)\nand e.department_id in (select department_id from departments)\norder by d.department_name asc,e.salary desc;','2020-11-25 19:20:08','2021-03-30 23:07:09',3,1,0),(47,2,'编写一个sql语句，找出预定了所有船的水手，结果返回水手姓名sname。','select s.sname from sailors s\nwhere not exists (\n	select * from boats b \n	where not exists (\n		select * from reserves r\n		where r.sid = s.sid and r.bid = b.bid\n	)\n);','2020-11-25 20:03:45','2021-03-30 22:02:23',1,0,0),(48,2,'编写一个sql语句，找出2020-05-01至2020-05-31期间预定过绿色船（GREEN）的等级最高的水手，结果返回水手姓名sname。','select s.sname\nfrom sailors s\nwhere exists(\n	select *\n	from reserves r join boats b\n	on r.bid = b.bid\n	where b.color = \'GREEN\' and r.sid = s.sid and r.reserve_date between \'2020-05-01\' and \'2020-05-31\'\n)\norder by rating DESC\nlimit 1;','2020-11-25 20:04:04','2021-04-07 11:18:28',2,0,0),(49,2,'编写一个sql语句，找出年龄在35岁以上，并且在2020-08-01至2020-08-31期间同时预定了红色船（RED）和绿色船（GREEN）的水手，结果返回水手姓名sname。','select s.sname\nfrom sailors s\nwhere s.age > 35 and exists(\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid\n	where r.sid = s.sid and b.color = \'GREEN\' and r.reserve_date between \'2020-08-01\' and \'2020-08-31\'\n) and exists (\n	select * \n	from reserves r join boats b\n	on r.bid = b.bid\n	where r.sid = s.sid and b.color = \'RED\' and r.reserve_date between \'2020-08-01\' and \'2020-08-31\'\n);','2020-11-25 20:10:28','2021-04-10 20:16:19',2,0,0),(52,11,'查询那些既没有最多，也没有最少参与者的活动的名字，可以以任何顺序返回结果，activities 表的每项活动的参与者都来自friends 表。结果字段:activity ','select activity\nfrom friends\ngroup by activity\nhaving count(*)>any(\n    select count(*) from friends group by activity\n) and count(*)<any(\n    select count(*) from friends group by activity\n)','2020-11-26 11:28:29','2021-04-13 21:34:13',3,0,0),(53,11,'查询在2月20~2月28之间能进行的活动及参加该活动的朋友名字。结果字段包含name，activity。','select name, friends.activity\nfrom activities,friends\nwhere activities.activity=friends.activity and (startDate between \'2020-02-20\' and \'2020-02-28\') and (endDate between \'2020-02-20\' and \'2020-02-28\')','2020-11-26 11:29:13','2020-12-30 11:01:55',2,0,0),(55,11,'查询进行eating的用户有哪些。结果字段：name','select friends.name \nfrom friends,activities\nwhere friends.activity=activities.activity and friends.activity=\'eating\'','2020-11-26 11:30:52','2021-04-13 21:36:47',1,0,0),(56,12,'查找在 2020 年 2 月 平均评分最高 的电影名称。 如果有相同的，返回字典序较小的电影名称。结果字段：title','select title from \n(select m.title,avg(mr.rating) as rt from movie_rating mr\ninner join movies m\non m.movie_id = mr.movie_id \ninner join users u \non u.user_id = mr.user_id \nwhere mr.created_at between \'2020-02-01\' and \'2020-02-29\'\ngroup by m.movie_id\norder by rt desc,m.title asc\nlimit 1) b','2020-11-26 11:33:33','2021-04-10 21:21:42',3,1,0),(57,12,'查找评论电影数量最多的用户名。 如果出现平局，返回字典序较小的用户名。结果字段：name','(SELECT name\nFROM users AS U\nINNER JOIN movie_rating AS MR\nON U.user_id = MR.user_id\nGROUP BY U.user_id\nORDER BY COUNT(*) DESC, name\nLIMIT 1)\n','2020-11-26 11:34:06','2021-04-10 12:05:40',3,1,0),(58,12,'求每部电影的最高分，最低分以及平均分。结果字段包含movie_id, title, avg_rating, max_rating, min_rating。','select movies.movie_id,title, avg(rating)as avg_rating, max(rating) as max_rating, min(rating) as min_rating\nfrom movies, movie_rating\nwhere movies.movie_id=movie_rating.movie_id\ngroup by movies.movie_id','2020-11-26 11:34:36','2021-04-12 10:35:12',2,0,0),(59,12,'查询一月份评论过电影的用户。结果集包含，name , title, created_at。','select name, title,created_at\nfrom movie_rating,users,movies\nwhere movie_rating.created_at between \'2020-01-01\' and \'2020-01-31\' and movie_rating.movie_id=movies.movie_id and movie_rating.user_id=users.user_id','2020-11-26 11:35:06','2020-12-30 11:03:00',2,0,0),(60,12,'查找用户id为1的用户看过的电影以及所给的评分。结果字段包含user_id，name，title，rating。','select movie_rating.user_id,name,title,rating\nfrom users,movie_rating,movies\nwhere movies.movie_id=movie_rating.movie_id and movie_rating.user_id=users.user_id and movie_rating.user_id=1','2020-11-26 11:35:30','2021-04-10 20:55:55',1,0,0),(61,13,'查询金额最大的发票所对应的发票号，用户ID，用户姓名。结果字段：invoice_id，price, user_id，customer_name','select invoice_id,price,invoices.user_id,customer_name\nfrom invoices,customers\nwhere invoices.user_id=customers.customer_id and price=(select max(price) from invoices)','2020-11-26 11:50:08','2021-04-10 21:09:40',2,0,0),(62,13,'求拥有发票数大于1的用户的联系人名字及电子邮件。结果字段：user_id，contact_name，contact_email','select t.user_id,contact_name,contact_email\nfrom\n(\n    SELECT user_id,count(*) count_temp\n    FROM invoices\n    GROUP BY user_id  \n    HAVING count_temp>1\n)t, customers,contacts \nwhere t.user_id=customers.customer_id and customers.customer_id=contacts.user_id','2020-11-26 11:50:58','2021-04-10 21:09:52',2,0,0),(63,13,'求拥有一张发票的顾客及其电子邮箱。结果字段包含：user_id，customer_name，email','select t.user_id,customer_name,email\nfrom\n(\n    SELECT user_id,count(*) count_temp\n    FROM invoices\n    GROUP BY user_id  \n    HAVING count_temp=1\n)t, customers\nwhere t.user_id=customers.customer_id','2020-11-26 11:51:26','2021-04-10 21:10:06',2,0,0),(64,13,'求拥有联系人的顾客的id和姓名以及联系人姓名。结果字段customer_id，customer_name，contact_name','select customer_id,customer_name,contact_name\nfrom customers,contacts\nwhere customer_id=user_id','2020-11-26 11:52:08','2021-04-10 21:23:18',1,0,0),(65,14,'每组的获胜者是在组内累积得分最高的选手。若平局player_id 最小选手获胜。查询每组中的获胜者。结果字段包含group_id,player_id。','SELECT t.group_id, t.player_id\n\nFROM\n(SELECT p1.group_id, t4.scores, MIN(t4.player_id) AS player_id\nFROM\n(SELECT t3.player_id, SUM(t3.score) AS scores\nFROM\n((SELECT first_player AS player_id, SUM(first_score) AS score\nFROM matches\nGROUP BY first_player)\nUNION ALL\n(SELECT second_player AS player_id, SUM(second_score) AS score\nFROM matches\nGROUP BY second_player)) AS t3\n\nGROUP BY t3.player_id) AS t4\nINNER JOIN players AS p1\nON t4.player_id=p1.player_id\nGROUP BY p1.group_id, t4.scores) AS t\n\nWHERE (t.group_id, t.scores) IN\n(\nSELECT p.group_id, MAX(t2.scores)\nFROM\n(SELECT player_id, SUM(score) AS scores\nFROM\n((SELECT first_player AS player_id, SUM(first_score) AS score\nFROM matches\nGROUP BY first_player)\nUNION ALL\n(SELECT second_player AS player_id, SUM(second_score) AS score\nFROM matches\nGROUP BY second_player)) AS t1\nGROUP BY player_id) AS t2\nINNER JOIN\nplayers AS p\nON t2.player_id=p.player_id\nGROUP BY p.group_id\n)\n','2020-11-26 11:56:17','2020-12-30 23:40:34',3,0,0),(66,14,'查询姓名为Aron的参赛者参加过的训练赛赛事分数。结果字段包含player_name ,match_id, score（不能为0）。 ','select player_name, match_id, t.score\nfrom\n(\nselect player_name, match_id,second_score as score\nfrom players, matches\nwhere (players.player_id=matches.first_player or players.player_id=matches.second_player) and players.player_name=\'Aron\' \n\nunion\n\nselect player_name, match_id,first_score as score\nfrom players, matches\nwhere (players.player_id=matches.first_player or players.player_id=matches.second_player) and players.player_name=\'Aron\'\n) t\nwhere t.score<>0','2020-11-26 11:57:32','2020-12-30 23:33:13',2,0,0),(67,14,'根据Scores表查询性别为‘F’在每一天的总分，并按性别和日期对结果排序。结果字段包含gender, day, total。','select s1.gender,s1.day,sum(s2.score_points) as total from scores s1\ninner join scores s2\non s1.gender = s2.gender \nand s1.day >= s2.day \nand s1.gender=\'F\'\ngroup by s1.gender,s1.day  \norder by s1.gender,s1.day','2020-11-26 11:58:53','2020-12-30 23:33:27',2,1,0),(68,14,'查询在1月进行训练赛的参赛者姓名，性别，分数。结果字段包含player_name ,gender, score_points。','select player_name,gender,score_points\nfrom scores\nwhere day between \'2020-01-01\' and \'2020-01-31\'','2020-11-26 11:59:21','2020-12-30 23:33:32',1,0,0),(69,14,'查找在scores表中获得最低分数的球员的姓名以及他的id。结果字段包含player_name, player_id，score_points.','select players.player_name, player_id, score_points as score_points\nfrom scores,players\nwhere scores.player_name=players.player_name and score_points=(select min(score_points) from scores)','2020-11-26 11:59:43','2020-12-31 00:16:14',2,0,0),(70,15,'查询顾客ID为1 的最近三笔订单。如果该用户订单少于 3 笔则返回其全部订单。结果按order_date 降序排列。结果字段：customer_name,customer_id,order_id,order_date','SELECT c.name as customer_name,o2.customer_id,o2.order_id,o2.order_date\nFROM orders o1,orders o2,customers c\nWHERE\n	o1.customer_id = o2.customer_id  and o2.customer_id = 1 and c.customer_id = o2.customer_id\nGROUP BY\n	c.name,\n	o2.order_id,\n	o2.customer_id,\n	o2.order_date\nHAVING\n	SUM(o1.order_date >= o2.order_date) <= 3\nORDER BY\n	c.name,\n	o2.customer_id,\n	o2.customer_id,\n	o2.order_date desc','2020-11-26 14:14:53','2021-04-10 12:03:32',3,1,0),(71,15,'找到每一个顾客最经常订购的商品。结果表单：每一位至少下过一次单的顾客id和他最经常订购的商品的ID和名字,按customer_id,product_id升序排列。结果字段：customer_id,product_id,p.product_name','select t2.customer_id,t3.product_id,p.product_name\nfrom\n(select t1.customer_id,max(t1.cnt) freq\nfrom\n(select customer_id,product_id,count(order_id) cnt\nfrom orders\ngroup by customer_id,product_id) t1\ngroup by t1.customer_id) t2 join (\nselect customer_id,product_id,count(order_id) cnt\nfrom orders\ngroup by customer_id,product_id\n) t3 on t2.freq=t3.cnt and t2.customer_id=t3.customer_id\njoin products p on p.product_id=t3.product_id\norder by customer_id, product_id\n','2020-11-26 14:16:57','2021-04-08 23:53:08',3,1,0),(72,15,'找到每件商品的最新订单(可能多个). 结果以商品名字升序排列。若相同则按商品id升序，再同以订单id 升序. 结果字段：product_name, product_id, order_id, order_date','select product_name, o.product_id, order_id, order_date\nfrom orders o left join products p\nusing(product_id)\nwhere (product_id, order_date) in\n(\n    select product_id, max(order_date) order_date\n    from orders\n    group by product_id\n)\norder by product_name, product_id, order_id','2020-11-26 14:20:11','2021-04-08 23:53:30',2,1,0),(73,15,'查询在 2020 年 8 月份被卖出的产品名字。结果字段： product_name','SELECT product_name\nFROM products JOIN orders USING (product_id)\nWHERE order_date LIKE \"2020-08%\"\nGROUP BY product_name','2020-11-26 14:20:57','2021-04-08 23:53:39',1,0,0),(74,15,'查询购买了产品ID 为1和产品 ID为2却没有购买产品ID为3的顾客的 ID 和姓名。结果字段： customer_id, name','SELECT\n    customer_id, name\nFROM\n    customers\nWHERE\n    customer_id NOT IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =3\n    ) AND customer_id IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =2\n    ) AND customer_id IN (\n        SELECT customer_id\n        FROM orders\n        WHERE product_id =1\n    )\nORDER BY customer_id','2020-11-26 14:21:30','2021-04-08 23:53:51',2,0,0),(75,16,'找出与”赵正义”在同一天借书的读者姓名、所在单位及借书日期 。结果字段： name,company','SELECT name,company,\n      (SELECT borrow_date FROM borrows WHERE reader_id =\n      (SELECT reader_id FROM readers WHERE name=\'赵正义\') )   \n                  borrow_date\nFROM readers WHERE reader_id = (\n    SELECT reader_id FROM borrows WHERE  borrow_date = \n        (SELECT borrow_date FROM borrows WHERE reader_id =\n        (SELECT reader_id FROM readers WHERE name=\'赵正义\') ) \n    AND reader_id != (SELECT reader_id FROM readers \n                                   WHERE name=\'赵正义\') );','2020-11-26 14:24:24','2021-04-08 23:54:25',3,0,0),(76,16,'查询财会系2006年7月以后没有借书的读者借书证号、姓名及单位。结果字段：reader_id,name,company','SELECT reader_id,name,company FROM readers \n    WHERE company=\'财会系\' and reader_id NOT IN\n            (SELECT reader_id FROM borrows \n             WHERE borrow_date>=\'2006-08-01\');','2020-11-26 14:24:45','2021-04-08 23:54:38',1,0,0),(77,16,'找出当前至少借阅了2本图书(大于等于2本)的读者姓名及其所在单位。结果字段：name,company','SELECT name,company FROM readers WHERE reader_id in\n       (SELECT distinct reader_id FROM borrows \n         GROUP BY reader_id having count(book_id)>=2);','2020-11-26 14:26:19','2021-04-08 23:54:51',2,0,0),(78,16,'题目：找出作者为李某的书籍的被借阅情况。结果字段：writer, book_name, borrow_date。','SELECT writer,book_name,\n   (SELECT borrow_date FROM borrows WHERE book_id in\n      (SELECT book_id from books WHERE writer LIKE \'李%\')) as borrow_date\nFROM books WHERE writer LIKE \'李%\';','2020-11-26 14:26:37','2021-04-10 12:02:58',2,0,0),(79,16,'查找“高等教育出版社”的所有图书名称(BOOK_NAME)及单价(PRICE)，结果按单价降序排序。结果字段：book_name,price','SELECT DISTINCT(book_name),price FROM books\n    WHERE output=\'高等教育出版社\' \n    ORDER BY price DESC;','2020-11-26 14:26:56','2021-04-08 23:55:17',1,1,0),(80,17,'查询2019-01-01到2019-12-31期间任务连续同状态的起止日期。如果任务失败/成功就是失败/成功状态的起止日期。结果按照起始日期排序。结果字段：period_state，start_date，end_date','select period_state,min(date) start_date,max(date) end_date from (\nselect \n\"failed\" period_state,\nfail_date as date,\nif(datediff(@pre_date,@pre_date:=fail_date)=-1,@id,@id:=@id+1) id\nfrom failed,(select @id:=0,@pre_date:=NULL)tmp1\nunion\nselect \n\"succeeded\" period_state,\nsuccess_date as date,\nif(datediff(@pre_date,@pre_date:=success_date)=-1,@id,@id:=@id+1) id\nfrom succeeded,(select @id:=0,@pre_date:=NULL)tmp2\n) tmp\nwhere date BETWEEN \"2019-01-01\" AND \"2019-12-31\"\ngroup by id,period_state\nORDER BY start_date ASC\n','2020-11-26 14:30:44','2021-04-13 21:43:01',3,1,0),(81,17,'查询所有活跃的业务。结果字段只包含business_id。','SELECT business_id\nFROM events AS e\nJOIN (\n    SELECT event_type, AVG(occurences) AS eventAvg\n    FROM events\n    GROUP BY event_type\n) AS e1 \nON e.event_type = e1.event_type\nWHERE e.occurences > e1.eventAvg\nGROUP BY business_id\nHAVING COUNT(*) >= 2','2020-11-26 14:33:08','2021-03-05 10:37:36',3,0,0),(82,17,'分别求出每个event事件的成功天数与失败天数。结果字段包含：event_type，success_count，fail_count。','Select x.event_type as event_type , IFNULL(x.success_count, 0) as success_count, IFNULL(y.fail_count, 0) as fail_count \nfrom events e\nleft join \n(select count(success_date) as success_count, event_type from succeeded group by event_type) as x on e. event_type= x. event_type\nLeft join\n(select count(fail_date) as fail_count, event_type from failed group by event_type) as y on y. event_type= e. event_type\ngroup by event_type,success_count,fail_count','2020-11-26 14:34:14','2021-04-13 21:55:20',3,0,0),(83,17,' 求出reviews事件在18年12月份系统里的最小的失败次数。结果字段：occurences，event_type，fail_count','Select min(occurences) as occurences, e.event_type, IFNULL(t.fail_cnt, 0) as fail_count\nfrom events e \nleft join\n(select count(fail_date) as fail_cnt, event_type from failed \nwhere fail_date between  \'2018-12-01\' and \'2018-12-31\' and event_type=\'reviews\') as t\non t. event_type= e. event_type \nwhere t.event_type=\'reviews\'','2020-11-26 14:37:17','2021-04-13 21:55:33',2,0,0),(84,17,'求一下事件类型发生次数最多的商业ID。结果字段仅包含business_id。','select business_id\nfrom events\nwhere occurences=(select max(occurences)\n                   from events)\n','2020-11-26 14:37:50','2020-12-30 11:10:23',1,0,0),(85,18,'查询没有学全所有课程的同学的信息。结果字段包含s_id, s_name, s_sex, s_birthday。','select s.* from \n    students s where s.s_id in(\n        select s_id from scores where s_id not in(\n            select a.s_id from scores a \n                join scores b on a.s_id = b.s_id and b.c_id=2\n                join scores c on a.s_id = c.s_id and c.c_id=3\n            where a.c_id=1))','2020-11-26 14:55:25','2021-04-08 23:57:26',1,0,0),(89,19,'查询每个部门工资最高的员工，结果字段包含：department_name,employee,salary','SELECT\n	department.NAME AS department_name,\n	employee.NAME AS employee,\n	salary \nFROM\n	employee,\n	department \nWHERE\n	employee.DepartmentId = department.Id \n	AND ( employee.DepartmentId, Salary ) \n    IN (SELECT DepartmentId, max( Salary ) \n        FROM employee \n        GROUP BY DepartmentId )','2020-11-26 15:21:26','2021-04-09 00:03:08',2,0,0),(90,19,'查询收入超过他们经理的员工的姓名。结果字段:employee','SELECT\n    a.Name AS \'employee\'\nFROM\n    employee AS a,\n    employee AS b\nWHERE\n    a.ManagerId = b.Id\n        AND a.Salary > b.Salary\n;','2020-11-26 15:21:56','2021-04-09 00:03:23',1,0,0),(91,19,'查询职员表中第二高的薪水（注：若AB薪资都是3000，C薪资2000，则第二高指的是C的2000）。结果字段：SecondHighestSalary','SELECT\n    (SELECT DISTINCT\n            salary\n        FROM\n            employee\n        ORDER BY Salary DESC\n        LIMIT 1 OFFSET 1) AS SecondHighestSalary\n;','2020-11-26 15:22:50','2021-04-09 00:03:51',2,0,0),(92,20,'查询工资高于部门号为30的所有员工工资水平的员工信息。 结果字段：empno，ename，job，mgr，hiredate，sal，comm，deptno。','select * from emp \nwhere sal > ( select max(sal) from emp where deptno = 30);  ','2020-11-26 15:25:04','2021-04-13 22:01:29',2,0,0),(93,20,'返回工资处于第四级别的员工的姓名。结果字段包含：ename，sal。','select ename,sal from emp e ,salgrade s \nwhere e.sal >= s.losal and e.sal <= s.hisal \nand s.grade = 4; ','2020-11-26 15:25:24','2021-04-13 22:04:54',1,0,0),(94,20,'返回工资为二等级的职员名字、部门名称、工资和二等级的最低工资和最高工资 。结果字段： ename，dname，sal，losal，hisal。','select ename ,dname ,sal ,losal,hisal from emp,dept,salgrade \nwhere emp.deptno = dept.deptno and grade = 2 \nand sal >= losal and sal < hisal; ','2020-11-26 15:25:42','2021-04-13 22:12:56',2,0,0),(95,20,'返回工资等级高于smith且直属领导编号为7298的员工信息。结果字段：empno，ename，job，mgr，hiredate，sal，comm，deptno。','select e.* from emp e, salgrade s \nwhere e.mgr=7698 and s.hisal < e.sal and s.grade = \n  ( select grade from salgrade s ,emp e \nwhere s.losal < e.sal and s.hisal > e.sal and e.ename = \'smith\'); ','2020-11-26 15:25:57','2021-04-13 22:03:03',2,0,0),(96,20,'计算出部门号为20的员工的年薪，并且对年薪进行升序排序。结果字段包含ename，deptno，ySalary。','select ename, deptno,sal * 12 as ySalary \nfrom emp \nwhere deptno=20\norder by ySalary; ','2020-11-26 15:26:24','2021-04-13 22:05:08',2,1,0),(98,18,'查询课程号为1和2的成绩在第2名到第3名的学生信息及该课程成绩。结果字段包含：s_id, s_name, s_birthday, s_sex, rank, s_score, c_id','  select d.*,c.排名,c.s_score,c.c_id from (\n                select a.s_id,a.s_score,a.c_id,@i:=@i+1 as 排名 from scores a,(select @i:=0)s where a.c_id=1    \n            )c\n            left join students d on c.s_id=d.s_id\n            where 排名 BETWEEN 2 AND 3\n            UNION\n            select d.*,c.排名,c.s_score,c.c_id from (\n                select a.s_id,a.s_score,a.c_id,@j:=@j+1 as 排名 from scores a,(select @j:=0)s where a.c_id=2   \n            )c\n            left join students d on c.s_id=d.s_id\n            where 排名 BETWEEN 2 AND 3','2020-11-26 19:15:55','2020-12-30 11:11:19',3,0,0),(99,18,'查询各科成绩最高分，最低分，不及格率，中等率和优秀率。结果字段包含：c_id，c_name，max_score，min_score，\'不及格率\'，\'中等率\'和\'优秀率\'（及格率、中等率和优秀率结果在0到1之间，保留两位小数）。注：不及格<60，中等>=60且<90，优秀>=90。','select a.c_id,b.c_name,MAX(s_score)as max_score,MIN(s_score) as min_score,\n    ROUND(SUM(case when a.s_score<60 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'不及格率\',\n    ROUND(SUM(case when a.s_score>=60 and a.s_score<90 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'中等率\',\n    ROUND(SUM(case when a.s_score>=90 then 1 else 0 end)/SUM(case when a.s_score then 1 else 0 end),2) as \'优秀率\'\n    from scores a left join courses b on a.c_id = b.c_id GROUP BY a.c_id,b.c_name','2020-11-26 19:18:06','2021-04-14 11:16:16',3,0,0),(100,18,'统计各科成绩各分数段人数：课程编号,课程名称,[100-85],[85-70],[70-60],[0-60]及所占百分比。结果字段：c_name, c_id，85-100, percent, 70-80, percent, 60-70, percent, 0-60, percent。',' select distinct f.c_name,a.c_id,b.`85-100`,b.percent,c.`70-85`,c.percent,d.`60-70`,d.percent,e.`0-60`,e.percent from scores a\n                left join (select c_id,SUM(case when s_score >85 and s_score <=100 then 1 else 0 end) as `85-100`,\n                                            ROUND(100*(SUM(case when s_score >85 and s_score <=100 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)b on a.c_id=b.c_id\n                left join (select c_id,SUM(case when s_score >70 and s_score <=85 then 1 else 0 end) as `70-85`,\n                                            ROUND(100*(SUM(case when s_score >70 and s_score <=85 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)c on a.c_id=c.c_id\n                left join (select c_id,SUM(case when s_score >60 and s_score <=70 then 1 else 0 end) as `60-70`,\n                                            ROUND(100*(SUM(case when s_score >60 and s_score <=70 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)d on a.c_id=d.c_id\n                left join (select c_id,SUM(case when s_score >=0 and s_score <=60 then 1 else 0 end) as `0-60`,\n                                            ROUND(100*(SUM(case when s_score >=0 and s_score <=60 then 1 else 0 end)/count(*)),2) as percent\n                                from scores GROUP BY c_id)e on a.c_id=e.c_id\n                left join courses f on a.c_id = f.c_id','2020-11-26 19:18:45','2020-12-30 11:11:34',3,0,0),(101,18,'查询没学过张三老师讲授的任一门课程的学生姓名。结果字段：s_name。','select a.s_name from students a where a.s_id not in (\n    select s_id from scores where c_id = \n                (select c_id from courses where t_id =(\n                    select t_id from teachers where t_name = \'张三\')) \n                group by s_id);\n','2020-11-26 19:22:51','2021-04-08 23:58:39',1,0,0),(103,13,'为每张发票编写一个SQL查询，结果字段包含：invoice_id，customer_name，price，contacts_cnt（该顾客的联系人数量），trusted_contacts_cnt（可信联系人的数量）。查询的结果按照 invoice_id 排序。','select i.invoice_id, c1.customer_name, i.price, \n    count(ct.contact_name) contacts_cnt ,\n    count(c2.customer_name) trusted_contacts_cnt \nfrom invoices i join customers c1 on i.user_id=c1.customer_id\n    left join contacts ct on i.user_id=ct.user_id\n    left join customers c2 on ct.contact_email=c2.email\ngroup by i.invoice_id\norder by i.invoice_id','2020-12-30 23:16:36','2021-04-12 10:56:02',3,1,0),(104,19,'编写SQL查询来查找每个部门的薪水中位数。若某一部门薪水情况是：1000,2000,3000,4000，则中位数为2000及3000.结果字段：departmentId, salary','select b.departmentId,b.salary\nfrom (\n    select DepartmentId,salary,\n    case @com when DepartmentId then @rk:=@rk+1 else @rk:=1 end rk,\n    @com:=DepartmentId\n    from employee,(select @rk:=0, @com:=\'\') a\n    order by DepartmentId,salary) b\nleft join \n    (\n    select DepartmentId,count(1)/2 cnt from employee group by DepartmentId) c\non b.DepartmentId=c.DepartmentId\nwhere b.rk in (cnt+0.5,cnt+1,cnt);','2021-01-02 16:06:41','2021-04-09 00:04:39',3,0,0),(105,11,'编写sql语句查询进行相同活动的用户的数量，要求结果字段有cnt（cnt表示用户的数量，依据题意至少为2），activity。结果字段：cnt，activity','select count(activity) as cnt, activity\nfrom friends\nGROUP BY activity\nhaving cnt > 1\n','2021-01-02 16:51:29','2021-04-13 21:37:40',1,0,0),(881,175,'编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供person 的以下信息：  FirstName, LastName, City, State','select p.FirstName,p.LastName,a.City,a.State\nfrom\nperson p left join address a\non\np.personid=a.personid','2021-11-17 16:20:43','2021-11-30 20:41:48',1,1,0),(882,176,'编写一个 SQL 查询，获取 Employee表中第二高的薪水（Salary）。','select max(Salary) SecondHighestSalary\nfrom employee\nwhere\nsalary<(select max(salary) from employee)','2021-11-17 16:20:43','2021-11-30 21:04:15',2,1,0);
/*!40000 ALTER TABLE sub_question ENABLE KEYS */;
-- UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `id` varchar(255) NOT NULL,
  `email` varchar(255) NOT NULL,
  `phone` varchar(255) NOT NULL,
  `role` varchar(255) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  `passhash` varchar(255) DEFAULT NULL,
  `password_reset_id` char(36) CHARACTER SET latin1 COLLATE latin1_bin DEFAULT NULL,
  `data` json DEFAULT NULL,
  `disabled` tinyint(1) DEFAULT '0',
  `signup_at` datetime DEFAULT NULL,
  `created_at` datetime NOT NULL,
  `updated_at` datetime NOT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `users_phone` (`phone`),
  UNIQUE KEY `users_phone_index` (`phone`),
  UNIQUE KEY `users_password_reset_id` (`password_reset_id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES ('0607f08a-e61e-4012-872e-1892de8b754d','181250132@smail.nju.edu.cn','13235210595','admin','admin','$2a$10$1L0bMJXS5pNSFGaeUmJ0Gu6l7x7TR.c/uZPqTTrZEJPKnyT3MOM/C',NULL,NULL,0,'2021-11-10 12:57:26','2021-11-10 12:57:26','2021-11-10 12:57:26'),('0f51268e-a3d3-4977-9b2c-f7f5cc4bdc18','181250122@smail.nju.edu.cn','11111111111','teacher','teacher','$2a$10$HSNZRL4sJkXZ1Jy9Y8iIaOjfDA/LB1g2zPcqP6WjZePk0VH1ia6MG',NULL,NULL,0,'2021-11-14 19:18:06','2021-11-14 19:18:06','2021-11-14 19:18:06'),('3506e26a-10b7-48e3-b8ba-8e6dc1a2bb92','181250036@smail.nju.edu.cn','18839040927','student','student','$2a$10$NiPvJRjQityYhlyjY.xKW.XsxVVax.tXndT6.BC8xnThNgrAawsrq',NULL,NULL,0,'2021-11-11 22:07:58','2021-11-11 22:07:58','2021-11-13 19:05:38');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2022-12-07 23:10:10
